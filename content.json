{"meta":{"title":"aFightz","subtitle":null,"description":null,"author":"aFightz","url":"http://yoursite.com"},"pages":[{"title":"categories","date":"2018-11-09T15:19:50.000Z","updated":"2020-01-07T08:21:41.542Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-11-09T15:19:50.000Z","updated":"2020-01-07T08:21:41.543Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"15 | 原子变量与非阻塞同步机制","slug":"Java并发编程实战_15_原子变量与非阻塞同步机制","date":"2020-02-01T13:19:23.000Z","updated":"2020-03-16T12:32:21.385Z","comments":true,"path":"2020/02/01/Java并发编程实战_15_原子变量与非阻塞同步机制/","link":"","permalink":"http://yoursite.com/2020/02/01/Java并发编程实战_15_原子变量与非阻塞同步机制/","excerpt":"","text":"✎CAS1、CAS的含义“我”认为V的值应该为A，如果是，那么将V的值更新为B，否则不修改并告诉V的值实际为多少。 ✎✎volatile 如果不加volatile，那么会写入变量更新到主内存吗？更新的规则会是什么？ 1、volatile的可见性假设有以下逻辑：1234567A线程A段逻辑写入volatile VB线程读取volatile VB段逻辑 假设时间上的执行顺序是A-&gt;B，那么A段逻辑对于B段逻辑是可见的吗？ DCL标准实现 public class DoubleCheckLocking{ private static volatile Resource resource; public static Resource getInstance(){ if(resource == null){ synchronized (DoubleCheckLocking.class){ if(resource == null){ resource = new Resource(); } } } } } 初始化过程中，对于可以通过某个final城到达的任意变量（例如某个final数组中的元素，或者由一个final域引用的HashMap的内客）将同样对于其他线程是可见（即不会被重排序）的。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"14 | 构建自定义的同步工具","slug":"Java并发编程实战_14_构建自定义的同步工具","date":"2020-02-01T12:06:44.000Z","updated":"2020-03-16T12:32:21.380Z","comments":true,"path":"2020/02/01/Java并发编程实战_14_构建自定义的同步工具/","link":"","permalink":"http://yoursite.com/2020/02/01/Java并发编程实战_14_构建自定义的同步工具/","excerpt":"","text":"✎阻塞队列的实现 用wait()、notifyAll()实现阻塞put、take方法的标准格式123456789101112131415//阻塞并直到：not-full public synchronized void put(V v) throws InterruptedException&#123; while(isFull()) wait(); doPut(v); notifyAll();&#125;//阻塞并直到：not-empty public synchronized V take() throws InterruptedException&#123; while(isEmpty()) wait(); V v = doTake(); notifyAll(); return v;&#125; 可对上面的进行优化：仅当缓存从空变为非空，或者从满转为非满时，才需要去通知（其他状态不会有线程阻塞）12345678public synchronized void put(V v) throws InterruptedException&#123; while(isFull()) wait(); boolean wasEmpty = isEmpty(); doPut(v); if(wasEmpty) notifyAll();&#125; ✎✎Lock的Condition对象每个Lock，可以有任意数量的Condition对象。Condition对象继承了相关的Lock对象的公平性。 1、对应关系 Object.wait：Lock.await Object.notify：Lock.signal Object.notifyAll：Lock.signalAll 2、唤醒特定对象Demo1234567891011121314151617181920212223242526272829303132333435363738@ThreadSafepublic class ConditionBoundedBuffer &lt;T&gt; &#123; protected final Lock lock = new ReentrantLock(); private final Condition notFull = lock.newCondition(); private final Condition notEmpty = lock.newCondition(); public void put(T x) throws InterruptedException &#123; lock.lock(); try &#123; while (count == items.length) notFull.await(); items[tail] = x; if (++tail == items.length) tail = 0; ++count; notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public T take() throws InterruptedException &#123; lock.lock(); try &#123; while (count == 0) notEmpty.await(); T x = items[head]; items[head] = null; if (++head == items.length) head = 0; --count; notFull.signal(); return x; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; UnSafe类中的park()与unPark()实际上就是相当于wait与notify。 这两者有什么不同？ Java的多数安全的方法类都有一个共同的基类：AbstractQueueSynchronizer(AQS)，它实际上上用UnSafe类中的park()与unPark()来实现等待与唤醒。涉及到变量的累加修改则用CAS实现。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"11 | 性能与可伸缩性","slug":"Java并发编程实战_11_性能与可伸缩性","date":"2020-01-19T16:59:58.000Z","updated":"2020-01-20T06:27:51.517Z","comments":true,"path":"2020/01/20/Java并发编程实战_11_性能与可伸缩性/","link":"","permalink":"http://yoursite.com/2020/01/20/Java并发编程实战_11_性能与可伸缩性/","excerpt":"","text":"✎Amdahl定律 12加速比 &lt;= 1 / (F + (1-F)/N )加速比/CPU的数量=CPU的利用率 F为串行部分占的比重，N为CPU数量。当N趋于无穷大时，加速比趋近于1/F。 某个线程中的同步可能会影响其他线程的性能。因为同步会增加共享内存总线上的通信量，总线的带宽是有限的，并且所有的处理器都将共享这条总线。 ✎✎竞争 JVM对“竞争”的实现 如果等待时间较短，则适合采用自旋等待方式。 如果等待时间较长，则适合采用线程挂起方式。 有些JVM将根据对历史等待时间的分析数据在这两者之间进行选择，但是大多数JVM在等待锁时都只是将线程挂起。 当线程无法获取某个锁或者由于在某个条件等待或在I/O操作上阻塞时，需要被挂起，在这个过程中将包含两次额外的上下文切换，以及所有必要的操作系统操作和缓存操作：被阻塞的线程在其执行时间片还未用完之前就被交换出去，而在随后当要获取的锁或者其他资源可用时，又再次被切换回来。 ✎✎✎锁分段在ConcurrentHashMap的实现中使用了一个包含16个锁的数组，每个锁保护所有散列桶的1/16，其中第N个散列桶由第（N mod 16）个锁来保护。ConcurrentHashMap对size()的实现ConcurrentHashMap中的size将对每个分段进行枚举并将每个分段中的元素数量相加，而不是维护一个全局计数。为了避免枚举每个元素，ConcurrentHashMap为每个分段都维护了一个独立的计数，并通过每个分段的锁来维护这个值。 ✎✎✎✎Java对象分配 Java的分配操作比C语言的malloc调用更快。对象分配操作的开销比同步的开销更低。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"13 | 显示锁","slug":"Java并发编程实战_13_显示锁","date":"2020-01-19T16:59:58.000Z","updated":"2020-03-16T12:32:21.373Z","comments":true,"path":"2020/01/20/Java并发编程实战_13_显示锁/","link":"","permalink":"http://yoursite.com/2020/01/20/Java并发编程实战_13_显示锁/","excerpt":"","text":"✎公平锁与非公平锁 在ReentrantLock、Semaphore的构造函数中提供了两种公平性选择：创建一个非公平的锁（默认）或者一个公平的锁。 1、定义 公平锁：线程将按照它们发出请求的顺序来获得锁。如果有另一个线程持有这个锁或者有其他线程在队列中等待这个锁，那么新发出请求的线程将被放入队列中。 非公平的锁：允许“插队”。当一个线程请求非公平的锁时，如果锁被某个线程持有时，新发出请求的线程才会被放入队列中。但如果在发出请求的同时该锁的状态变为可用，那么这个线程将跳过队列中所有的等待线程并获得这个锁。 是不是意味在在队列中的锁依旧会排队？ 即使对于公平锁而言，可轮询的tryLock仍然会“插队”。（什么意思）。 2、性能非公平锁的性能会比公平锁的性能高，尤其是在竞争激烈的时候。 3、Lock与SynchronizedReentrantLock的非块结构特性仍然意味着，获取锁的操作不能与特定的栈帧关联起来，而内置锁却可以。 ✎读写锁一个资源可以被多个读操作访问，或者被一个写操作访问，但两者不能同时进行。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"10 | 活跃性、性能与测试","slug":"Java并发编程实战_10_活跃性、性能与测试","date":"2020-01-19T09:03:37.000Z","updated":"2020-01-20T06:18:10.449Z","comments":true,"path":"2020/01/19/Java并发编程实战_10_活跃性、性能与测试/","link":"","permalink":"http://yoursite.com/2020/01/19/Java并发编程实战_10_活跃性、性能与测试/","excerpt":"","text":"✎死锁 数据库在检测到事务发生死锁时，将选择一个牺牲者并放弃这个事务。 若所有线程以固定的顺序来获得锁，那么在程序中就不会出现顺序死锁问题。 解决顺序死锁的加锁方式1234synchronized(锁A)&#123; synchronized(锁B)&#123; &#125;&#125; 尽量别再持有锁的时候调用加锁方法，容易造成死锁。 ✎✎Thread.yield与Thread.sleep(0) 在JVM中Thread.yield（以及Thread.sleep(0)）的语义都是未定义的。JVM既可以将它们实现为空操作，也可以将它们视为线程调度的参考。 有些JVM实现yield方法的方式就是sleep(0)。 UNIX系统中sleep(0)的语义：将当前线程放在与该优先级对应的运行队列末尾，并将执行权交给拥有相同优先级的其他线程。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"08 | 线程池的使用","slug":"Java并发编程实战_08_线程池的使用","date":"2020-01-19T04:23:59.000Z","updated":"2020-01-20T06:11:03.906Z","comments":true,"path":"2020/01/19/Java并发编程实战_08_线程池的使用/","link":"","permalink":"http://yoursite.com/2020/01/19/Java并发编程实战_08_线程池的使用/","excerpt":"","text":"在线程池的线程中不应该使用ThreadLocal在任务之间传递值。 在线程池中，如果任务依赖于其他任务，那么可能产生饥饿死锁。除非线程池足够大。 ✎线程池数量对于计算密集型的任务，在拥有N个处理器的系统上，当线程池的大小为N+1时，通常能实现最优的利用率。（即使当计算密集型的线程偶尔由于页缺失故障或者其他原因而暂停时，这个“额外”的线程也能确保CPU的时钟周期不会被浪费。）而大多数的任务是计算与IO并存的，所以1最佳线程池数量 = CPU数量 * CPU利用率 * (1 + W/C)W为线程等待时间，C为线程计算时间。W+C即是一个线程任务实际运行时间。Java中获得CPU数量1int N_CPUS=Runtime.getRuntime().availableProcessors(); ✎✎线程池原理 1、线程池构造方法123456789public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; ...&#125; 2、线程池工作原理 keepAliveTime：线程存活时间。 core Pool Size：线程池的基本大小，在没有任务执行时线程池的大小，并且只有在工作队列满了的情况下才会创建超出这个数量的线程。 maximum Pool Size：最大大小。表示可同时活动的线程数量的上限。如果某个线程的空闲时间超过了存活时间，那么将被标记为可回收的，并且当线程池的当前大小超过了基本大小时，这个线程将被终止。 newFixedThreadPool工厂方法将线程池的基本大小和最大大小设置为参数中指定的值，而且创建的线程池不会超时。newCachedThreadPool工厂方法将线程池的最大大小设置为Integer.MAX_VALUE，而将基本大小设置为零，并将超时设置为1分钟，这种方法创建出来的线程池可以被无限扩展，并且当需求降低时会自动收缩。 如果线程池中的线程数量等于线程池的基本大小，那么仅当在工作队列已满的情况下ThreadPoolExecutor才会创建新的线程。 3、线程池其他知识点默认的线程池饱和策略是“中止”：即抛出RejectedExecutionException。 可用Executors的unconfigurableExecutorService工厂方法包装ExecutorService，避免其被修改。 可继承ThreadPoolExecutor的beforeExecute、afterExecute和terminated以实现一些日志统计等功能。 ✎✎等待任务集返回 1234//提交任务exec.shutdown();exec.awaitTermination(Long.MAX_VALUE, TimeUnit.SECONDS);//返回任务结果 ✎✎✎树与并发可用并发实现树的广度优先搜索。 深度优先搜索的搜索过程将受限于栈的大小。 广度优先搜索不会受到栈大小的限制（但如果待搜索的或者已搜索的位置集合大小超过了可用的内存总量，那么仍可能耗尽内存）。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"07 | 取消与关闭","slug":"Java并发编程实战_07_取消与关闭","date":"2020-01-19T02:54:46.000Z","updated":"2020-01-20T03:38:47.688Z","comments":true,"path":"2020/01/19/Java并发编程实战_07_取消与关闭/","link":"","permalink":"http://yoursite.com/2020/01/19/Java并发编程实战_07_取消与关闭/","excerpt":"","text":"✎中断与阻塞 1、Thread中的中断方法12345public class Thread&#123; public void interrupt()&#123;...&#125; public boolean isInterrupted)&#123;...&#125; public static boolean interrupted()&#123;...&#125; &#125; interrupt：中断目标线程。 isInterrupted：能返回目标线程的中断状态。 静态的interrupted：清除当前线程的中断状态，并返回它之前的值。 这也是清除中断状态的唯一方法。 2、阻塞库方法例如Thread.sleep和Object.wait等，都会检查线程何时中断，并且在发现中断时提前返回。它们在响应中断时执行的操作包括： 清除中断状态。 抛出InterruptedException。 用中断来取消任务并不是可靠的，如果任务内不响应中断，那么中断也没有用。 3、join的缺陷无法知道执行控制是因为线程正常退出而返回还是因为join超时而返回。 4、通过Future.cancel()取消任务 此方法很重要，可避免不必要的资源浪费。 12345678910111213public static void timedRun(Runnable r，long timeout，TimeUnit unit) throws InterruptedException&#123; Future&lt;?&gt; task = taskExec.submit(x); try&#123; task.get(timeout , unit); &#125;catch()TimeoutException e)&#123; //接下来任务将被取消 &#125;catch(ExecutionException e)&#123; //如果在任务中抛出了异常，那么重新抛出该异常throw launderThrowable(e.getCause())； &#125;finally&#123; //如果任务已经结来，那么执行取消操作也不会带来任何影响 task.cancel(true);//如果任务正在运行，那么将被中断 &#125;&#125; ✎线程异常 当一个线程由于未捕获异常而退出时，JVM会把这个事件报告给应用程序提供的UncaughtExceptionHandler异常处理器。如果没有提供任何异常处理器，那么默认的行为是将栈追踪信息输出到System.err。 只有通过execute提交的任务，才能将它抛出的异常交给未捕获异常处理器，而通过submit提交的任务，无论是抛出的未检查异常还是已检查异常，都将被认为是任务返回状态的一部分。如果一个由submit提交的任务由于抛出了异常而结束，那么这个异常将被Future.get封装在ExecutionException中重新抛出。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"06 | 任务执行","slug":"Java并发编程实战_06_任务执行","date":"2020-01-17T04:45:58.000Z","updated":"2020-01-20T03:24:47.753Z","comments":true,"path":"2020/01/17/Java并发编程实战_06_任务执行/","link":"","permalink":"http://yoursite.com/2020/01/17/Java并发编程实战_06_任务执行/","excerpt":"","text":"✎ExecutorService 1、ExecutorService有三种状态： 运行。 关闭。 终止。 2、ExecutorService的关闭方式： shutdown：平缓的关闭。 shutdownNow：暴力关闭。 可用awaitTermination来等待ExecutorService到达终止状态，或者调用isTerminated来轮询ExecutorService是否终止。 3、ExecutorService等待一组提交任务 先完成的先返回1234executorService.submit(一组任务)循环&#123; executorService.take()//哪个任务优先完成则先返回。&#125; 等待任务全部结束或中断、超时才返回 List&lt;Future&lt;TravelQuote&gt;&gt; futures = executorService.invokeAll(tasks, time, unit); ✎TimerTimer的缺陷：例如某个周期TimerTask需要每l0ms执行一次，而另一个TimerTask需要执行40ms，那么这个周期任务或者在40ms任务执行完成后快速连续地调用4次，或者彻底“丢失”4次调用（取决于它是基于固定速率来调度还是基于固定延时来调度）。Timer不会捕获异常，如果任务抛出异常时，Timer不会恢复线程的运行，此时将导致整个定时任务不可用。可用ScheduledThreadPoolExecutor代替Timer。 DelayQueue实现了BlockingQueue，并为ScheduledThreadPoolExecutor提供了调度功能。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"13 | 线程安全与锁优化","slug":"深入理解Java虚拟机_13_线程安全与锁优化","date":"2020-01-02T14:54:11.000Z","updated":"2020-01-13T03:32:14.640Z","comments":true,"path":"2020/01/02/深入理解Java虚拟机_13_线程安全与锁优化/","link":"","permalink":"http://yoursite.com/2020/01/02/深入理解Java虚拟机_13_线程安全与锁优化/","excerpt":"","text":"Thread类的suspend()与resume()方法会产生死锁，已废弃。 Java的线程是映射到操作系统的原生线程之上的，所说要阻塞或唤醒一个线程，需要从用户态转换到核心态中，非常耗费时间。Java在通知操作系统阻塞线程之前加入一段自旋等待 过程，避免频繁地切入到核心态之中。 ✎互斥同步 相比于synchronized，ReentrantLock有以下三个优点： 等待可中断。 可实现公平锁。 公平锁：公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。，。 非公平锁：与公平锁相反，是随机获取锁的。在锁被释放时，任何一个等待锁的线程都有机会获得锁。 synchronized中的锁是非公平的。ReentrantLock默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。 锁可以绑定多个条件。 1.6后synchronized与ReentrantLock的性能就基本持平了。 ✎✎非阻塞同步 互斥同步属于悲观并发策略，非阻塞同步属于乐观并发策略。乐观并发策略只能靠硬件来完成（CAS指令）。 1、CAS操作过程：CAS指令需要有3个操作数，分别是内存位置（用v表示）、旧的预期值（用A表示）和新值（用B表示）。CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值；否则它就不执行更新。无论是否更新了V的值，都会返回V的旧值。 CAS操作由sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供。 2、Atomic的incrementAndGet方法源码12345678public final int incrementAndGet()&#123; for(;;)&#123; int current = get(); int next=current +1; if (compareAndSet(current,next)) return next; &#125;&#125; 3、ABA问题CAS存在ABA问题，即一个值修改的顺序为A-&gt;B-&gt;A时，当前赋值无法检测到，仍然认为是正确的赋值。但是一般情况下这种情况都可以忽略，若确实有场景不允许这样的情况，也可以使用AtomicStampedReference实现，它通过控制版本号来实现CAS。 ✎✎锁 1、自旋锁挂起线程和恢复线程的操作都需要转入内核态中完成，如果共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环（自旋）。自旋锁默认是开启的。 2、自适应自旋锁若虚拟机会判断如果此线程的此次自旋很有可能会成功，则会让自旋循环更多次，否则就会循环更少次。 3、锁消除锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。 4、锁粗化如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部。 5、轻量级锁轻量级锁是默认开启的。传统的锁机制称为重量级锁。重量级锁需要申请系统的互斥量（系统调用）。 当同步对象没有被锁定时，锁标志位为01。当线程尝试去锁定同步对象时： 若判断同步对象未锁定，会使用CAS尝试将MarkWord更新为指向Lock Record的指针，（Lock Record是线程在栈空间中建立的锁记录，其实就是Mark Word的副本）并将锁标志位置为00。 若发现锁标志位为00（轻量级锁定），或者说CAS更新同步对象失败，则判断是不是本线程持有锁（通过判断MarkWord的指针是否指向本线程的Lock Record即可知），如果不是，则将MarkWord存储为指向重量级锁（互斥量）的指针，将锁标志置为10，此线程以及后面的线程要进入阻塞状态。 当持有锁对象执行完，需要释放锁时，使用CAS将Lock Record替换对象的MarkWord指针，如果替换不成功（说明有其他线程尝试获取此锁，MarkWord指针已被改变），则要释放锁的同时，还要唤醒其他等待的线程。 互斥锁还需要唤醒？ 如果在绝大部分不存在竞争的情况下，轻量级锁是更好的，但是如有频繁的有竞争，轻量级锁会比重量级锁更慢，因为此时轻量级锁不仅有互斥量的开销，还有CAS操作的开销。 6、偏向锁当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设为01，即偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中，如果CAS操作成功，持有偏向锁的线程以后每次进人这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作。 当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。撤销偏向（Revoke Bias）后恢复到未锁定（标志位为01）或轻量级锁定（标志位为00）的状态，后续的同步操作就如上面介绍的轻量级锁那样执行。 对于大多数锁都是被同一线程获取的情况，使用偏向锁更好。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解Java虚拟机","slug":"学习笔记/JVM/深入理解Java虚拟机","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解Java虚拟机/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"01 | 简介","slug":"Java并发编程实战_01_简介","date":"2019-12-31T04:15:21.000Z","updated":"2020-01-13T04:36:17.615Z","comments":true,"path":"2019/12/31/Java并发编程实战_01_简介/","link":"","permalink":"http://yoursite.com/2019/12/31/Java并发编程实战_01_简介/","excerpt":"","text":"在大多数现代操作系统中，都是以线程为基本的调度单位。同一个进程中的所有线程都将共享进程的内存地址空间。 ✎线程注解 @NotThreadSafe @ThreadSafe @Immutable @GuardedBy","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"12 | java内存模型与线程","slug":"深入理解Java虚拟机_12_java内存模型与线程","date":"2019-12-23T16:09:34.000Z","updated":"2020-01-07T11:22:36.751Z","comments":true,"path":"2019/12/24/深入理解Java虚拟机_12_java内存模型与线程/","link":"","permalink":"http://yoursite.com/2019/12/24/深入理解Java虚拟机_12_java内存模型与线程/","excerpt":"","text":"✎内存间交互操作 1、jvm保证下面8种操作是原子的： lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放人主内存的变量中。 2、执行上述8种操作时必须满足下面的规则： read-&gt;load，assign-&gt;store-&gt;write这两组操作是固定的，不会少，顺序也不会变。 在use的前面一定会有初始化（load或assign）的操作。 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定住的变量。 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）。 假设线程中访问一个10MB的对象，也会把这10MB的内存复制二份拷出来吗？答：事实上并不会如此，这个对象的引用、对象中某个在线程访问到的字段是存可能存在拷的，但不会有虚拟机实现成把整个对象拷一次。 ✎✎volatile 在JDK1.5之前，volatile的不能完全避免重排序，所以不能安全地使用DDL（双锁检测）来实现单例模式。 在对volatile变量进入赋值操作时，紧跟在后面会插入一条内存屏障指令（从汇编代码上体现的是一条lock前缀的指令）。 这个指令会使本cpu的cache写入主内存，这个写入动作会导致其他cpu相应的cache无效化。 无效化意思就是说会重新从主内存读相应的cache？那么volatile的读又起到什么作用？ 同时这个lock前缀的屏障也会使后续的指令不会重排序到内存屏障前。 每对volatile写一次就会产生一条内存屏障指令。 读写volatile变量要满足以下规则： read-&gt;load-&gt;use（读）、assign-&gt;store-&gt;write(写)一定会是连续一起出现的。 假设有volatile类型变量A与B，从代码角度上来看先对A进行读/写，再对B进行读/写，那么这两者不会被重排序。 如果对读取两个volatile变量，那么这两次读取会被重排序吗？ ✎✎✎synchronized synchronized编译成字节码就是monitorenter与monitorexit。 ✎✎✎✎happens-before 程序次序规则。在一个线程中，按照控制流的顺序，书写在前面的操作先行发生于书写在后面的操作。 管程锁定规则。一个unlock操作先行发生于后面对同一个锁的lock操作。这里所说的“后面”是指时间上的后面。 volatile变量规则。对一个volatile变量的写操作先行发生于后面对这个变量的读操作。这里所说的“后面”是指时间上的后面。 线程启动规则。Thread的start()方法先行发生于此线程的每一个动作。 线程终止规则。线程中的所有操作都先行发生于对此线程的终止检测。（可以通过Thread.join()、Thread.isAlive()检测线程是否终止）。 线程中断规则。对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断时间的发生(通过Thread.interrupted()等方法检测到是否有中断发生)。 对象终结规则。一个对象的初始化完成(构造函数执行结束)先行发生于它的finalize()方法。 传递性。如果A先于B、B先于C，那么A先于C。 先行发生的意思通俗点来说就是：如果A先行发生于B，那么A对B可见。即A的操作能被B“观察”到。 ✎✎✎✎✎线程的实现线程是比进程更轻量级的调度执行单位。线程是CPU调度的基本单位。 1、线程的种类 内核线程：即由操作系统内核来完成线程切换与线程调度。 轻量级进程：作为内核线程的高级接口，轻量级进程与内核线程是1:1的关系，轻量级进程是基于内核线程实现的，所以对线程的操作都要进行系统调用（需要再用户态和内核态相互切换）。 用户线程：线程的创建、切换、调度等操作都由用户程序来管理，可以不需要进行系统调用（切换到内核态），所以线程操作是非常快速且低消耗的，可以支持规模更大的线程数量。与进程的关系是1：N。但是无法使用内核的一些功能（如处理器映射等） 2、线程的实现实现线程主要有3种方式： 内核线程实现。但是一般不会直接使用线程，而是通过轻量级线程去访问内核线程。 其实也可以说是1:1的轻量级线程实现。 用户线程实现。 用户线程加轻量级进程混合实现。 2、java线程实现目前java线程是使用一对一线程模型实现的，即一条java线程映射为一条轻量级进程。 3、java线程调度主要调度方式有两种： 协同式线程调度：线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上。 好处：切换操作对线程自己是可知的，所以没有线程同步的问题。 坏处：线程执行时间不可控制，容易造成系统阻塞。 抢占式线程调度：每个线程将由系统来分配执行时间，线程的切换由系统决定。 好处：线程的执行时间是系统可控的,不容易造成阻塞。 Java使用的线程调度方式就是抢占式调度。 4、线程优先级 java本身有10个优先级。但实际上并不是太靠谱，因为原生系统可能并没有那么多优先级。那么在做优先级映射的时候，有可能系统的一个优先级对应java的多个优先级。某些系统在特定情况下也不是完全按照线程优先级来执行线程调用的。 5、状态装换java语言定义了5种状态：新建（New）。运行（Runnable）。无限期等待（Waiting）。以下方法会导致线程陷入无限期的等待状态： 没有设置Timeout参数的Object.wait()方法。 没有设置Timeout参数的Thread.join()方法。 LockSupport.park()方法。 限期等待（Timed Waiting）。以下方法会导致线程陷入限期等待状态： Thread.sleep()方法。 设置了Timeout参数的Object.wait()方法。设置了Timeout参数的Thread.join()方法。 LockSupport.parkNanos()方法。 LockSupport.parkUntil()方法。 阻塞（Blocked）。“阻塞状态”与“等待状态”的区别是：“阻塞状态”在等待着获取到一个排他锁，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状态”则是在等待一段时间，或者唤醒动作的发生。 结束（Terminated）。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解Java虚拟机","slug":"学习笔记/JVM/深入理解Java虚拟机","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解Java虚拟机/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"07 | 虚拟机类加载机制","slug":"深入理解Java虚拟机_07_虚拟机类加载机制","date":"2019-12-15T15:16:45.000Z","updated":"2020-01-07T08:21:41.503Z","comments":true,"path":"2019/12/15/深入理解Java虚拟机_07_虚拟机类加载机制/","link":"","permalink":"http://yoursite.com/2019/12/15/深入理解Java虚拟机_07_虚拟机类加载机制/","excerpt":"","text":"✎类的生命周期 加载。 连接。 验证。 准备。 解析。 初始化。 使用。 卸载。 解析阶段有时会在初始化后面。加载阶段与连接阶段是交叉进行的。 对static int a = 1;这样的语句，在准备阶段为把a赋值为0，而在初始化阶段才会赋值为1。但是如果是这样的语句final static int a = 1;，在准备阶段就会直接赋值为1。 ✎✎解析 1、符号引用的解析对于符号引用的解析，会对第一次解析的结果进行缓存。（除了invokedynamic这条指令） 2、字段的解析假设解析成功后，字段所属的类是C。 先看C是否含有与目标相匹配的字段，有则返回此字段引用。 否则，递归往上查找C实现的接口，有则返回此字段引用。 否则，递归往上查找C的父类，有则返回此字段引用。 否则，报错。 实际上虚拟机限制的会比较严格，如果继承的类与实现的接口，都有同样的字段，会编译不通过，如下：123456789101112131415161718192021public class Test &#123; public static void main(String[] args) throws InterruptedException &#123; Hehe hehe = new Hehe(); System.out.println(hehe.a); //Reference to 'a' is ambiguous, both 'TestClass.a' and \"TestInterface.a' match &#125; public static class Hehe extends TestClass implements TestInterface&#123; &#125; public static class TestClass&#123; int a = 2; &#125; public interface TestInterface&#123; int a = 1; &#125;&#125; 3、类方法解析假设解析成功后，方法所属的类是C。 如果在C中有匹配的方法，则直接返回。 否则递归在父类中查找相匹配的方法。 否则就会报错。 4、接口方法解析假设解析成功后，方法所属的接口是C。 如果在C中有匹配的方法，则直接返回。 否则递归在父接口中查找相匹配的方法。 否则就会报错。 ✎✎✎初始化编译器可以为接口生成&lt;clinit&gt;()类构造器。其实初始化阶段就是执行&lt;clinit&gt;()方法的过程。&gt; &lt;init&gt;()是实例构造器。静态块语句只能访问到定义在静态块语句之前的变量，但是可以给之前的变量赋值。如下：1234567public class Test &#123; static&#123; i = 0; //赋值可以编译通过 System.out.println(i); //访问则编译不通过 illegal forward reference &#125; static int i = 1;&#125;&lt;clinit&gt;()在多线程情况下只会被调用一次。bootstrap classloader只会加载虚拟机识别的文件，若随便放个自定义的jar文件到对应目录下，bootstrap classloader也不会去加载。 ✎✎✎双亲委托模型 破坏双亲委托模型的办法： 重写loadClass()方法。（不建议使用） loadClass()的大致逻辑就是：若父类加载器加载失败，则调用findClass()方法。所以我们自定义类加载器的时候，都是重写findClass()方法以符合双亲委托模型。 指定线程上下文类加载器。 OSGI实现的模块化热部署。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解Java虚拟机","slug":"学习笔记/JVM/深入理解Java虚拟机","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解Java虚拟机/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"03 | 垃圾收集器与内存分配策略","slug":"深入理解Java虚拟机_03_垃圾收集器与内存分配策略","date":"2019-11-25T16:11:49.000Z","updated":"2020-01-07T08:21:41.503Z","comments":true,"path":"2019/11/26/深入理解Java虚拟机_03_垃圾收集器与内存分配策略/","link":"","permalink":"http://yoursite.com/2019/11/26/深入理解Java虚拟机_03_垃圾收集器与内存分配策略/","excerpt":"","text":"✎对象的死亡1、引用计数法给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1，引用失效时，计数器值就减1。任何时刻计数器为0的对象就是不可能再被使用的。但是引用计数法解决不了相互循环引用的问题。 2、可达性分析算法这个算法就是以一系列的GC Root为起点，从这些节点向下搜索，当一个对象不可达时，则认为这个对象“已死”。 GC Root包括以下4种对象： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对象。 3、引用的分类引用由强到若可以分为4种引用： 强引用。这个就是我们平常代码里面new的引用类型。 软引用。可用SoftReference类实现软引用。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存才会抛出内存溢出异常。 弱引用。可用WeakReference类实现弱引用。被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。 看起来不可达（死亡）对象和弱引用的生存时间是一样的？ 虚引用。可用PhantomReference实现虚引用。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 4、对象被回收的过程 可达性分析算法标志这个对象不可达（第一次标记）。 若对象覆盖了finalize()方法并且之前没有执行过这个方法，那么将这个对象放到F-Queue队列中，让Finalizer线程去执行它的finalize()方法。否则直接被回收。（对象的finalize()只可能被调用一次） 稍后GC会对F-Queue队列的对象进行筛选，若依旧不可达，则将会被回收。 可在finalize()方法中对这个对象进行“拯救”，即重新关联这个对象，让这个对象可达。 5、Class的回收可用-Xnoclassgc控制JVM是否对Class对象进行回收。 ✎✎HotSpot的算法实现1、枚举根节点 HotSpot使用的是准确GC，使用一组称为OopMap的数据结构存储使用到的引用以及引用的有效范围。在枚举根节点时，只需要关注OopMap的信息即可。 2、安全点 程序执行过程中只有处于安全点时才会停下来进行GC。所以安全点与安全点之间如果存在了非常多的指令变化内容，JVM不必为这些指令都生成oopMap，只需要在第二个安全点之前，生成一个oopMap即可。 另外，让程序在到达安全点时“停下来”等待GC有两种方案： 抢先式中断。GC直接让所有线程都中断，如果线程不在安全点上，则恢复它让它跑到安全点上再中断。 主动式中断。线程到达一个安全点时，轮询一个标志，看是否需要GC，如果需要，就主动中断挂起。 现在的JVM基本上都是使用主动式中断策略。 从上面的信息可知，程序每到一个安全点必然会经过GC。（因为到了安全点就需要轮询）但是这样的话效率不会很低吗？ 3、安全区域 如果线程处于“不执行”的状态时，比如说处于Sleep、Blocked状态。那么就永远也跑不到安全点上了。JVM不可能为了等待这些线程跑到安全点上而不进行GC。所以就需要安全区域来解决。安全区域是指在一段代码片段之中，引用不会发生任何变化。 当程序执行到安全区域时，会标识自己已经进入了安全区域，若此时JVM要发起GC时，就会忽略这个线程。当线程要离开安全区域时，要检查JVM是否完成了根节点枚举，如果没有完成，则要接收到“可以离开安全区域”的信号后，程序才会往下执行。 ✎✎✎垃圾收集器| 名称 | 算法 | 是否并发 | 是否并行 | 是否需要STW | 作用区域 || :—————: | :——-: | :——: | :——: | :———: | :——: || Serial | 复制 | 否 | 否 | 是 | 新生代 || Serial Old | 标记-整理 | 否 | 否 | 是 | 老年代 || ParNew | 复制 | 是 | 否 | 是 | 新生代 || Parallel Scavenge | 复制 | 是 | 否 | 是 | 新生代 || Parallel Old | 标记-整理 | 是 | 否 | 是 | 老年代 || CMS | 标记-清除 | 是 | 不完全是 | 是 | 老年代 | 1、Serial收集器虚拟机在Client模式下的默认新生代收集器。 2、ParNew收集器Serial收集器的多线程版本。 3、Serial Old收集器CMS收集器的后备预案。可与Parallel Scavenge收集器组合。（已经比较少用） 4、Parallel Scavenge收集器关注点在总的吞吐量。适用不需要太多交互的用户。一般来说GC的频率较低，所以每次GC导致的用户停顿时间会变长（频率低的话每次GC时新生代的内存空间就会比较大）。 5、Parallel Old收集器Parallel Scavenge收集器的老年代版本。 6、CMS只有ParNew/Serial收集器可以与CMS收集器配合工作。Serial Old收集器可作为CMS收集器的后备预案。 收集过程： 初始标记。标记GC Roots能直接关联到的对象。需要STW。 并发标记。进行GC Roots Tracing的过程。 重新标记。修正并发标记期间由于用户程序继续运行而导致标记产生变化的那一部分对象的标记记录。 并发清除。 缺点 需要大量CPU资源。 无法处理浮动垃圾。在并发清除阶段，产生的新的垃圾称为浮动垃圾，这部分垃圾只能等待下次GC清除。同时，因为并发手机时，用户程序还能继续运行，所以老年代要预留空间（预留空间的阈值是可以设置的）给用户程序，如果预留的空间不足以供用户程序运行，那么就会导致“Concurrent Mode Failure”失败。这时虚拟机就会启动后备方案：临时启用Serial Old收集器来对老年代进行垃圾回收。 由标记-清除算法带来的问题：内存碎片。也可以设置执行了多少次不进行压缩的full gc后，进行一次压缩。 7、G1收集器特点： 并行与并发。 分代收集。 空间整合。整体上来看是使用标记-整理算法，局部上来说其实是使用了复制算法。 可预测的停顿。指定在M毫秒的时间段内，消耗的垃圾回收时间不会超过N毫秒。 G1会优先回收价值最大的Region。 老年代与新生代不再是物理隔离的。整个堆被分为N个Region。每个Region都有一个Remembered Set，记录其对其他Region的引用。 收集过程： 初始标记。 并发标记。 最终标记。 筛选回收。 8、java默认垃圾回收器 jdk1.7 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代）。 jdk1.8 默认垃圾收集器Parallel Scavenge（新生代）+Parallel Old（老年代）。 jdk1.9 默认垃圾收集器G1。 jdk10 默认垃圾收集器G1。 jdk11 默认垃圾收集器G1。 ✎✎✎✎内存分配一般来说，Full GC前都会经过Minor GC，但并非绝对，在Parallel Scavenge收集策略里就有直接进行Full GC的策略。Full GC的速度一般会比Minor GC慢10倍以上。 1、直接进入老年代的大对象设置-XX:PretenureSizeThreshold这个参数在分配内存空间时可令大于它的对象直接进入老年代。 这个参数只对Serial和ParNew两款收集器有效。 2、新生代对象何时进入老年代 存活年龄达到阈值。 在Sirvivor空间中相同年龄所有对象大小的总和大与Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。 3、空间分配担保JDK 6 Update 24后，当新生代将要进行Minor GC时，JVM会对老年代进行以下检查： 老年代的连续空间是否大于新生代对象总大小。 老年代的连续空间是否大于历次晋升的平均大小。 如果满足上述其中一条，就会走正常的对象转移流程。（Minor GC - &gt; Full GC）如果都不满足，则会先Full GC再进行Minor GC后再Full GC。 需要注意的是第一个流程有可能不需要进行Full GC（在To 空间有足够内存存放新生代存活对象的时候）不明白为什么要改成这样子，如果走第二种流程的话感觉先Full GC没有什么意义。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解Java虚拟机","slug":"学习笔记/JVM/深入理解Java虚拟机","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解Java虚拟机/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"02 | Java内存区域与内存溢出异常","slug":"深入理解Java虚拟机_02_Java内存区域与内存溢出异常","date":"2019-11-24T13:58:59.000Z","updated":"2020-01-07T08:21:41.502Z","comments":true,"path":"2019/11/24/深入理解Java虚拟机_02_Java内存区域与内存溢出异常/","link":"","permalink":"http://yoursite.com/2019/11/24/深入理解Java虚拟机_02_Java内存区域与内存溢出异常/","excerpt":"","text":"✎程序计数器程序计数器是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 每一个线程都会有一个独立的程序计数器。 ✎✎栈每个方法在执行的同时都会创立一个栈帧。 在oom时存储快照的参数：-XX:+HeapDumpOnOutOfMemoryError。 指定栈内存大小参数：-Xss(默认为512k) 抛出StackOverflowError 是因为栈内存不够，而不是栈深度到了指定的深度。 同一个类，如果被不同的类加载器加载两次，那么在栈中也就会存在两份Class对象。 ✎✎✎常量池jdk1.6中，String的intern()方法会把“首次遇到”的字符串实例复制到常量池中，并返回这个实例引用。而在jdk1.7中，不再复制实例，而是记录这个实例的引用。(也就是说把实例放到了堆中) demo1234567891011public class Test &#123; public static void main(String[] args) throws InterruptedException &#123; String str = new StringBuilder(\"A\").toString(); System.out.println(str.intern() == str); //false 非常量池的对象 String str2 = new StringBuilder(\"B\").append(\"C\").toString(); System.out.println(str4.intern() == str4);//true 为常量池对象 &#125;&#125; 上面的例子有点意思，在编译期间A、B、C就已经放入常量池了，所以新建值为A的实例与常量池值为A的实例肯定不同。而常量池没有值为BC的实例，所以当执行itern()方法时，自然就会把新建的“BC”实例给“放入”常量池，所以两只的引用指向的是同一个实例。 str.itern()与str = “”这种方式赋值的区别是？如果大量使用intern或者 str = “”这种写法，是不是会容易造成OOM？常量是否也会被回收？ ✎✎✎✎堆1、创建对象时，分配内存的方式有如下两种： 如果内存是绝对规整的，就直接使用“指针碰撞”。（如果使用复制或带有压缩功能的算法，那么内存就是绝对规整的） 否则就使用“空闲列表”的方式，在一个列表中维护各个可用的内存块。需要时则直接在列表找到符合条件的内存块。 2、在并发的情况下对分配内存的正确结果的保证有如下两种方式： 采用CAS配上失败重试的方式。 给每个线程分配一小块内存（TLAB），若这小块内存不够用时，再同步申请新的TLAB。（是否使用这种方式可以由 -XX:+/-UseTLAB） 3、内存中的实例对象包含以下3种数据 对象头。 实例数据。 对齐填充。 ✎✎✎✎✎对象的访问定位对象的访问定位有以下两种方式 直接访问。优点是访问速度快。 使用句柄间接访问。优点是对象被移动时，只需要移动句柄，不需要动原来对象。 ✎✎✎✎✎✎直接内存Nio直接请求分配了堆外内存（也就是直接内存），避免了在Java堆和Native堆中来回复制数据。直接内存容量可通过-XX:MaxDirectMemorySize指定，如果不指定，则默认与Java堆最大值（-Xmx指定）一样。可通过反射获取UnSafe实例分配直接内存。 Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例。所以只能用反射的方式去使用Unsafe。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解Java虚拟机","slug":"学习笔记/JVM/深入理解Java虚拟机","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解Java虚拟机/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"动态代理剖析","slug":"动态代理剖析","date":"2019-11-22T13:54:43.000Z","updated":"2020-01-07T08:21:41.450Z","comments":true,"path":"2019/11/22/动态代理剖析/","link":"","permalink":"http://yoursite.com/2019/11/22/动态代理剖析/","excerpt":"","text":"sun.misc.ProxyGenerator.saveGeneratedFiles 设置这个参数为true可让java动态代理类生成.class文件 Object的方法中，除了hashCode,equals,tosString这三个方法会被代理，其他方法都不会被代理。","categories":[{"name":"个人分享","slug":"个人分享","permalink":"http://yoursite.com/categories/个人分享/"},{"name":"Java","slug":"个人分享/Java","permalink":"http://yoursite.com/categories/个人分享/Java/"},{"name":"动态代理","slug":"个人分享/Java/动态代理","permalink":"http://yoursite.com/categories/个人分享/Java/动态代理/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"09 | Java字节码","slug":"深入理解JVM[课程]_09_Java字节码","date":"2019-11-12T04:22:00.000Z","updated":"2020-03-16T12:32:21.403Z","comments":true,"path":"2019/11/12/深入理解JVM[课程]_09_Java字节码/","link":"","permalink":"http://yoursite.com/2019/11/12/深入理解JVM[课程]_09_Java字节码/","excerpt":"","text":"✎字节码文件结构 名称 所占空间(字节) Magic Number 4 Version 4 Constant Pool 2+n Access Flags 2 This Class Name 2 Super Class Name 2 Interfaces 2+n Fields 2+n Methods 2+n Attributes 2+n 每个类的常量池都有许多值相同的常量，那么这些常量是共享的吗？类的常量池和我们平常所说的常量池有什么区别？ ✎✎方法对于Java类中的每一个实例方法（非static方法），其在编译后所生成的字节码当中，方法参数的数量总是会比源代码中方法参数的数量多一个（this），它位于方法的第一个参数位置处。 入参一定会存放到局部变量表中。 ✎✎✎异常假设方法中有try catch的语法，那么在运行时局部变量表会多一个记录异常的变量。 1、JVM对异常的处理方式 采用异常表的方式来对异常进行处理。 当异常处理存在finally语句块时，现代化的JVM采取的处理方式是将finally语句块的字节码拼接到每一个catch块后面，换句话说，程序中存在多少个catch块，就会在每一个catch块后面重复多少个finally语句块的字节码。 ✎✎✎✎栈帧（stack frame）栈帧是一种用于帮助虚拟机执行方法调用与方法执行的数据结构,封装了方法的局部变量表、动态链接信息、方法的返回地址以及操作数栈等信息。 有些符号引用是在类加载阶段或是第一次使用时就会转换为直接引用，这种转换叫做静态解析；另外一些符号引用则是在每次运行期转换为直接引用，这种转换叫做动态链接，这体现为Java的多态性。 ✎✎✎✎✎方法调用 invokeinterface：调用接口中的方法，实际上是在运行期决定的，决定到底调用实现该接口的哪个对象的特定方法。 invokestatic：调用静态方法。 invokespecial：调用自己的私有方法、构造方法以及父类的方法。 invokevirtual：调用虚方法，运行期动态查找的过程。 invokedynamic：动态调用方法。 ✎✎✎✎✎静态解析与动态链接1、静态解析的4种情形 静态方法 父类方法 构造方法 私有方法（无法被重写） 以上4类方法称作非虚方法，他们是在类加载阶段就可以将符号引用转换为直接引用的。 公有方法有可能被重写，所以不能被静态解析。 2、方法的静态分派Demo123456789101112131415161718192021222324252627282930313233public class Test6 &#123; public void test(Grandpa grandpa)&#123; System.out.println(\"Grandpa\"); &#125; public void test(Father father)&#123; System.out.println(\"Father\"); &#125; public void test(Son son)&#123; System.out.println(\"Son\"); &#125; public static void main(String[] args) &#123; Grandpa g1 = new Father(); Grandpa g2 = new Son(); Test6 test6 = new Test6(); test6.test(g1); //输出Grandpa test6.test(g2); //输出Grandpa &#125;&#125;class Grandpa&#123;&#125;class Father extends Grandpa&#123;&#125;class Son extends Father&#123;&#125; 以上代码，g1的静态类型是Grandpa，而g1的实际类型（真正指向的类型）是Father。变量的静态类型是不会发生变化的，而变量的实际类型则是可以发生变化的（多态的一种体现），实际类型是在运行期方可确定。方法重载，是一种静态的行为，编译期就可以完全确定。 3、方法动态分派Demo123456789101112131415161718192021222324252627public class Test &#123; public static void main(String[] args) &#123; Fruit f1 = new Apple(); Fruit f2 = new Banana(); f1.test(); //输出Apple f2.test(); //输出Banana &#125;&#125;class Fruit&#123; public void test()&#123; System.out.println(\"Fruit\"); &#125;&#125;class Apple extends Fruit&#123; public void test()&#123; System.out.println(\"Apple\"); &#125;&#125;class Banana extends Fruit&#123; public void test()&#123; System.out.println(\"Banana\"); &#125;&#125; 方法重写是一种动态的行为，在运行期才可以决定。 总的来说就是：调用哪个方法（重载导致有多个同名方法），是由所传入的引用类型决定的。确定完调用方法之后，再去寻找调用这个方法的实例，这是由实际类型所决定的。 ✎✎✎✎✎✎操作数栈123456789public class Test &#123; public static void main(String[] args) &#123; int a = 1; int b = 2; int c = 3; int max = a+b+c; &#125;&#125; 如上代码显示了一个很简单的相加运算，用jclasslib打开它的.class文件，展示的字节码逻辑如下： 123456789101112130 iconst_11 istore_12 iconst_23 istore_24 iconst_35 istore_36 iload_17 iload_28 iadd9 iload_310 iadd11 istore 413 return iconst_1表示将1入栈，istore_1表示将栈顶元素存储到局部变量表index为1的地方，以此类推。iload_1表示读取局部变量表index为1的变量，压入栈。iadd表示连续两次将栈顶弹出，并将弹出的元素相加，得出的结果压入栈。istore 4表示将栈顶元素赋值给局部变量表中index为4的变量。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解JVM[课程]","slug":"学习笔记/JVM/深入理解JVM-课程","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解JVM-课程/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"06 | 可靠的数据传输","slug":"Kafka权威指南_06_可靠的数据传输","date":"2019-11-05T11:56:24.000Z","updated":"2020-01-07T08:21:41.410Z","comments":true,"path":"2019/11/05/Kafka权威指南_06_可靠的数据传输/","link":"","permalink":"http://yoursite.com/2019/11/05/Kafka权威指南_06_可靠的数据传输/","excerpt":"","text":"✎broker层面的保证 kafka可以保证分区内消息的一致性。 消费者接收到的消息，一定是已经被写入分区的所有同步副本的。 设置副本进行数据备份，防止数据丢失。 ✎生产者层面的保证","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"Kafka权威指南","slug":"学习笔记/Kafka/Kafka权威指南","permalink":"http://yoursite.com/categories/学习笔记/Kafka/Kafka权威指南/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"08 | 类的卸载","slug":"深入理解JVM[课程]_08_类的卸载","date":"2019-10-31T15:32:04.000Z","updated":"2020-01-07T08:21:41.501Z","comments":true,"path":"2019/10/31/深入理解JVM[课程]_08_类的卸载/","link":"","permalink":"http://yoursite.com/2019/10/31/深入理解JVM[课程]_08_类的卸载/","excerpt":"","text":"✎相关概念与定义当T类被加载、连接和初始化后，它的生命周期就开始了。当代表T类的Class对象不再被引用，即不可触及时，Class对象就会结束生命周期，T类在方法区内的数据也会被卸载，从而结束T类的生命周期。 ✎✎Class对象被引用的地方 类加载器与它所加载的类是双向关联的关系。 一个类的实例总是会引用代表这个类的Class对象。 问题1双向关联的话，不就一直都不会被垃圾回收了吗？ 从上可知，要使一个class对象结束生命周期，它的类加载器实例与它的对象实例均要被垃圾回收。 由Java虚拟机自带的类加载器（根类加载器、扩展类加载器和系统类加载器）所加载的类，在虚拟机的生命周期中，始终不会被卸载。因为Java虚拟机本身会始终引用这些类加载器。 ✎✎✎观察类的卸载信息 通过jvisualvm弹出可视化的窗口，在“监视”栏可看到类的卸载总数与加载总数。 使用-XX:+TraceClassLoading参数打印类的加载信息。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解JVM[课程]","slug":"学习笔记/JVM/深入理解JVM-课程","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解JVM-课程/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"07 | 类的实例化","slug":"深入理解JVM[课程]_07_类的实例化","date":"2019-10-26T05:19:55.000Z","updated":"2020-01-07T08:21:41.500Z","comments":true,"path":"2019/10/26/深入理解JVM[课程]_07_类的实例化/","link":"","permalink":"http://yoursite.com/2019/10/26/深入理解JVM[课程]_07_类的实例化/","excerpt":"","text":"✎实例化的步骤 为新的对象分配内存。 为实例变量赋默认值。 为实例变量赋正确的初始值。 通过字节码得出，为实例变量赋初始值是在构造方法中完成的。在调用父类构造方法之后，在执行构造方法代码逻辑之前。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解JVM[课程]","slug":"学习笔记/JVM/深入理解JVM-课程","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解JVM-课程/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"06 | 接口","slug":"深入理解JVM[课程]_06_接口","date":"2019-10-23T15:32:45.000Z","updated":"2020-01-07T08:21:41.499Z","comments":true,"path":"2019/10/23/深入理解JVM[课程]_06_接口/","link":"","permalink":"http://yoursite.com/2019/10/23/深入理解JVM[课程]_06_接口/","excerpt":"","text":"interface中的变量默认就是public static final,其实它的初始化过程与class是大体上一样的。 一个父接口并不会因为它的子接口或者实现类的初始化而初始化。 通过JDK1.8代码验证得出:子接口初始化了，父接口会被加载但是不会被初始化。实现类初始化了，接口会被加载但是不会被初始化。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解JVM[课程]","slug":"学习笔记/JVM/深入理解JVM-课程","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解JVM-课程/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"05 | 深入Kafka","slug":"Kafka权威指南_05_深入Kafka","date":"2019-10-22T11:42:45.000Z","updated":"2020-01-07T08:21:41.406Z","comments":true,"path":"2019/10/22/Kafka权威指南_05_深入Kafka/","link":"","permalink":"http://yoursite.com/2019/10/22/Kafka权威指南_05_深入Kafka/","excerpt":"","text":"✎集群成员关系broker启动的时候会在创建一个临时节点，把自己的id注册到zk上（/brokers/ids/#这样的形式）。Kafka组件会监听/brokers/ids这个路径，当集群中有broker退出或新增时，组件都会知悉。将一个broker完全关闭之后，启动另外一个拥有相同id的broker，那么它会拥有与旧broker相同的分区与主题。 ✎✎控制器集群中的broker在加入集群时，都会尝试创建临时节点/controller，但是只有一个可以创建成功，那么它将成为控制器。其他竞争失败的broker将会监听这个临时节点，以便当节点变更时（比如说控制器挂了），它们可以知悉。当控制器挂了，剩余的broker又会开始竞争流程。新的broker在成为控制器后，通过zk的递增操作获得数值更大的epoch。其他broker会忽略掉比当前epoch小的消息（这些消息也就是从旧的控制器发出的），从而避免了“脑裂”。 如果控制器在断开后重连，当发现创建/controller失败后，它应该就知道自己不是控制器了，那么之前比较小的epoch又是怎么发出的呢？ 当控制器发现若一个broker离开后(通过监听/brokers/ids这个节点可知)，若这个broker又是分区leader，那么控制器就会在剩余的分区副本列表里面选出一个leader，并通知副本列表。 ✎✎✎复制如果Follower在一定时间内（这个时间由replica.Lag.time.max.ms配置，默认为10S）没有向Leader请求同步数据，或者在一定时间内（默认是6S）没有向zk发送心跳消息，那么这个Follower就被认为是不同步的，当分区Leader失去连接触发重新选举时，未同步的Follower将不会被选举。 每一个分区都有一个首选Leader，它由以下两种方式指定： 创建主题时选定的Leader分区就是首选Leader。 手动进行副本分配，第一个指定的副本就是首选Leader。 当auto.leader.rebalance.enable设为true时，它会去检查首选Leader是不是当前Leader，如果不是，且首选Leader是同步的那么就会触发选举，让首选Leader成为当前Leader。 在复制还未完成的时候，如果此时leader崩溃，那么就会导致数据丢失。 若一个同步副本滞后，会使生产者与消费者变慢。副本滞后则意味着副本肯定不会同步最新的消息，因为同步也是按消息顺序来的。若生产者若设置了ack = all，那么它会一直等待此消息被副本同步，而生产者也只会消费被同步了的消息。滞后的原因会有两个： 副本崩溃且没有重启，在经过指定时间后，leader就不会再等待它同步了。 副本崩溃在一定时间后重启了，此时若崩溃的时间过长，有大量的数据没有被同步，此时生产者与消费者在此副本同步完之前皆会被“卡”住。 临时增加分区应该也有同步副本滞后的效果。这个要怎么解决？ ✎✎✎✎请求1、Kafka处理请求的内部流程broker会在它所监听的每一个端口上运行一个Acceptor线程，这个线程会创建一个连接，并把它交给Processor线程去处理。Processor线程的数量是可配置的。Processor线程把客户端请求的消息放进请求队列，然后从响应队列获取响应消息，把它们发送给客户端。 2、客户端获取分区leader所在的broker的过程客户端对任意broker（因为每个broker都缓存了这部分数据）发送元数据请求，然后将返回的数据（包括表明分区leader在哪个broker的信息）缓存起来，之后需要间隔一定的时间去重新缓存这部分数据（时间间隔可以由metadata.max.age.ms来配置）。 当客户端将数据发送到一个不是分区leader的broker的时候，会接收到一个“非分区首领”的错误，然后客户端会重新缓存元数据，再重新发送数据到相应的Borker。 3、生产请求如果acks=0，那么生产者在把消息发出去之后，完全不需要等待broker的响应。在消息被写入分区的首领之后，broker开始检查acks配置参数 如果acks被设为0或1，那么broker立即返回响应。 如果acks被设为all，那么请求会被保存在一个叫作炼狱的缓冲区里，直到首领发现所有跟随者副本都复制了消息，响应才会被返回给客户端。 4、获取请求Kafka使用零复制技术向客户端发送消息。零复制技术的意思就是直接把消息从文件（或者更确切地说是Linux文件系统缓存）里发送到网络通道，而不需要经过任何中间缓冲区。这项技术避免了字节复制，也不需要管理内存缓冲区，从而获得更好的性能。 ✎✎✎✎✎物理存储1、集群中分区的分配规则假设有5个broker（broker0 ~ broker4），5个分区（分区0 ~ 分区4），每个分区有3个副本。 若没有配置机架信息。首先会随机选择一个broker，假设选择了broker3，那么分区0首领副本会被分在broker3，分区1首领副本会被分在broker4，依次类推。首领副本分完之后，再分配跟随者副本，分区1的第一个跟随者副本会被分配在broker4上，第二个跟随者副本会被分配在broker0。以此类推。 若配置了机架的信息，那么broker就根据机架信息分组。选择的顺序会是机架A、机架B……以此类推。 2、broker内分区的分配规则log.dirs指定了分区目录（可多个）计算每个目录的分区数量，新的分区总是被添加到数量最小的那个目录里。 3、文件管理broker会为分区里的每个片段打开一个文件句柄，哪怕片段是不活跃的。这样会导致打开过多的文件句柄，所以操作系统必须根据实际情况做一些调优。 4、文件格式保存在磁盘上的数据格式与从生产者发送过来或者发送给消费者的消息格式是一样的。使用了压缩算法后，同一批次的消息会被压缩到一起。DumpLogSegment工具可以查看片段内容。 5、索引为了帮助broker更快地定位到指定的偏移量，Kafka为每个分区维护了一个索引。删除索引后，kafka会自动重新生成索引。 6、清理重复的消息假设有这样一个场景，对于key相同的消息，kafka内部只需要保存最新的一条。对于这种场景，可以为主题设置compact策略来实现。如果设置log.cleaner.enabled为true，那么kafka就会启用清理功能来实现上述场景。 如果不启用清理功能，那么设置了compact策略似乎也没意义？ 每个Broker会启动一个清理管理器线程和多个清理线程。线程会选择污浊率较高的分区进行清理。 污浊消息表示的是还未被清理的。污浊率 = 污浊消息大小/分区大小 线程会新建一个map，然后将污浊消息的key存入这个map中，其实也就是去重操作。清理完后就会用这个map替换原来的片段。 如果需要删除某个key的所有消息，则需要push一个key -&gt; null 这样的形式的消息（墓碑消息），清理线程会保留墓碑消息一段时间（这个时间可配置），消费者在监听到value为null时，作忽略处理即可。 但是也有隐患，如果在保留的这段时间内，刚好消费者离线，那么消费者就有可能检测不到这个墓碑消息。 compact策略也不会去清理仍在活跃的片段。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"Kafka权威指南","slug":"学习笔记/Kafka/Kafka权威指南","permalink":"http://yoursite.com/categories/学习笔记/Kafka/Kafka权威指南/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"05 | 静态常量","slug":"深入理解JVM[课程]_05_静态常量","date":"2019-10-22T04:33:17.000Z","updated":"2020-01-07T08:21:41.498Z","comments":true,"path":"2019/10/22/深入理解JVM[课程]_05_静态常量/","link":"","permalink":"http://yoursite.com/2019/10/22/深入理解JVM[课程]_05_静态常量/","excerpt":"","text":"✎静态常量的本质含义静态常量在编译阶段会存入到调用这个静态常量的方法所在的类的静态常量池中，本质上，调用类并没有直接引用到定义静态常量的类，因此并不会触发定义静态常量的类的初始化。如下： Demo1234567class Parent&#123; public static final int parent = 1; static &#123; System.out.println(\"parent\"); &#125;&#125; 12345678910public class Test&#123; public static void main(String[] args) &#123; /**由于将静态常量存放到了Test的静态常量池中，不触发Test的初始化。所以输出： * 1 * * 我们甚至可以在编译完之后将Parent.class文件删除也不会影响程序运行结果(说明不会去加载Parent，更别说去初始化了)。 */ System.out.println(Parent.parent); &#125;&#125; 但是，当一个静态常量的值并非编译期间可以确定的，那么其值就不会被放到调用类的静态常量池中，这时在程序运行时，会主动使用这个静态常量所在的类，显然会导致这个类被初始化。将上述的Parent类改一下，如下： Demo1234567class Parent&#123; public static final int parent = UUID.randomUUID().toString(); static &#123; System.out.println(\"parent\"); &#125;&#125; Paren类将会被初始化，输出“parent”。 同理可得，非静态常量也不是非编译期间可以确定的，所以也不会被放到调用类的常量池中。 ✎✎反编译与助记符1、反编译命令javap -c [.class path] 反编译上面的Test.class文件，会发现Test的字节码文件中确实没有引用到到Parent，而是使用下述的助记符直接推静态常量。javap -verbose 能打印更详细的信息。(加上-p会打印private信息) 2、助记符 ldc：表示将int，float或是string类型的静态常量值从静态常量池中推送至栈顶。 sipush：表示格一个短整型静态常量值（-32768~32767）推送至栈顶。 bipush：表示将单字节（-128~127）的静态常量值推送至栈顶。 iconst_1：表示将int类型1推送至栈顶（iconst_1~iconst_5）。 double、char、byte类型呢？是否是优先使用表示“小区间”的助记符，如果不符合再使用“大区间”的？","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解JVM[课程]","slug":"学习笔记/JVM/深入理解JVM-课程","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解JVM-课程/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"03 | 类的初始化","slug":"深入理解JVM[课程]_03_类的初始化","date":"2019-10-20T08:19:55.000Z","updated":"2020-01-07T08:21:41.497Z","comments":true,"path":"2019/10/20/深入理解JVM[课程]_03_类的初始化/","link":"","permalink":"http://yoursite.com/2019/10/20/深入理解JVM[课程]_03_类的初始化/","excerpt":"","text":"✎初始化的功能为类的静态变量赋予正确的初始值。 ✎✎初始化的时机每个类或接口在被Java程序“首次主动使用”时才被初始化，首次使用分为以下7种情况： 创建类的实例。 访问某个类或接口的静态变量，或者对该静态变量赋值。 调用类的静态方法。 反射。(Class.forName) 初始化这个类的子类。 Java虚拟机启动时被标明为启动类的类（带有main方法的类）。 JDK1.7开始提供的动态语言支持：java.lang.invoke.MethodHandle实例的解析结果REF_getStatic，REF_putStatic，REF_invokeStatic句柄对应的类如果没有初始化，则初始化。 调用ClassLoader类的loadClass方法加载一个类，并不是对类的主动使用，不会导致类的初始化。 1、子类与父类初始化Demo1234567891011121314151617181920212223242526272829class Parent&#123; public static int parent = 1; static &#123; System.out.println(\"parent\"); &#125;&#125;class Child extends Parent&#123; public static int child = 1; static &#123; System.out.println(\"child\"); &#125;&#125;public class Test&#123; static &#123; System.out.println(\"main\"); &#125; public static void main(String[] args) &#123; /**首先会初始化main方法所在的类，之后使用到了Child的静态变量，所以Child需要被初始化，Child被初始化之前Child的父类也必须被初始化。输出： * main * parent * child * 1 */ System.out.println(Child.child); &#125;&#125; 上述例子中的类加载顺序和类初始化顺序其实是一样的，可以通过开启VM参数去观察一下这三个类的加载顺序。 123456789public class Test2&#123; public static void main(String[] args) &#123; /**此时没有直接使用到Child的静态变量而使用了Parent的静态变量，所以Child没有被初始化而Parent被初始化了。输出： * parent * 1 */ System.out.println(Child.parent); &#125;&#125; 2、反射与类加载器初始化Demo1234567891011121314151617181920212223public class Test &#123; public static void main(String[] args) throws ClassNotFoundException &#123; ClassLoader loader = ClassLoader.getSystemClassLoader(); loader.loadClass(\"CL\"); System.out.println(\"-----------\"); Class.forName(\"CL\"); /** * 输出： * ----------- * CL * * 说明类加载器加载类不会去初始化类，而反射会去初始化类。 */ &#125;&#125;class CL &#123; static &#123; System.out.println(\"CL\"); &#125;&#125; ✎✎✎初始化顺序类的初始化顺序是从上往下的，如下Demo可以说明：12345678910111213141516171819202122232425262728public class MyTest6 &#123; public static void main(String[] args)&#123; Singleton singleton = Singleton.getInstance(); System.out.println(\"counter1: \"+Singleton.counter1); System.out.printin(\"counter2: \"+Singleton.counter2); /** * 输出的结果是: * 1 * 0 */ &#125; &#125;class Singleton &#123; public static int counter1; private static Singleton singleton = new Singleton(); private Singleton()&#123; counter1++; counter2++; &#125; public static int counter2 = 0; public static singleton getInstance()&#123; return singleton; &#125;&#125; 当singleton类被加载完连接完后，counter1与counter2都被赋为了0，Singleton被赋为了null，此时的调用getInstance()这个静态方法（主动使用），Singleton将被初始化，从上往下赋值： singleton变量被赋值，触发构造方法Singleton()，此时counter1为1，counter2为1。 counter2被赋值为0。 注：类被加载进内存后，也可以被卸载。 问题1：类的构造方法是在哪个阶段调用？ 答：类的构造方法是在实例化的时候才会被调用，不要和这三个阶段搞混了。实例化已经不是Class层面上的执行步骤了。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解JVM[课程]","slug":"学习笔记/JVM/深入理解JVM-课程","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解JVM-课程/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"04 | vm参数","slug":"深入理解JVM[课程]_04_vm参数","date":"2019-10-20T08:19:55.000Z","updated":"2020-01-07T08:21:41.497Z","comments":true,"path":"2019/10/20/深入理解JVM[课程]_04_vm参数/","link":"","permalink":"http://yoursite.com/2019/10/20/深入理解JVM[课程]_04_vm参数/","excerpt":"","text":"✎vm参数设置方式 -XX:+&lt;option&gt;，表示开启option选项。 -XX:-&lt;option&gt;，表示关闭option选项。 -XX:&lt;option&gt;=&lt;value&gt;，表示格option选项的值设置为value。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解JVM[课程]","slug":"学习笔记/JVM/深入理解JVM-课程","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解JVM-课程/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"02 | 类的连接","slug":"深入理解JVM[课程]_02_类的连接","date":"2019-10-20T06:19:55.000Z","updated":"2020-01-07T08:21:41.496Z","comments":true,"path":"2019/10/20/深入理解JVM[课程]_02_类的连接/","link":"","permalink":"http://yoursite.com/2019/10/20/深入理解JVM[课程]_02_类的连接/","excerpt":"","text":"✎连接的步骤 验证：确保被加载的类的正确性。 准备：为类的静态变量分配内存，并将其初始化为默认值。 解析：把类中的符号引用转换为直接引用。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解JVM[课程]","slug":"学习笔记/JVM/深入理解JVM-课程","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解JVM-课程/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"01 | 类的加载","slug":"深入理解JVM[课程]_01_类的加载","date":"2019-10-20T05:19:55.000Z","updated":"2020-01-07T08:21:41.495Z","comments":true,"path":"2019/10/20/深入理解JVM[课程]_01_类的加载/","link":"","permalink":"http://yoursite.com/2019/10/20/深入理解JVM[课程]_01_类的加载/","excerpt":"","text":"在Java代码中，类型的加载、连接与初始化过程都是在程序运行期间完成的 ✎相关定义类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在内存中创建一个java.lang.Class对象用来封装类在方法区内的数据结构。 规范并未说明Class对象位于哪里，HotSpot虚拟机将其放在了方法区中。 JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。 但是实际情况下，在编译完之后，删除某个类的.class文件，如果需要加载它，会直接报错，而不是等到初始化才报错。 类加载器并不需要等到某个类被“首次主动使用”时再加载它。 这里有例子可以证明吗？ 若有一个类加载器能够成功加载Test类，那么这个类加载器被称为定义类加载器，所有能成功返回Class对象引用的类加载器（包括定义类加载器）都被称为初始类加载器。 ✎✎类加载器的类型 Java虚拟机自带的加载器 根类加载器（Bootstrap）：该加载器没有父加载器，它负责加载虚拟机的核心类库，如java.lang.*等。根类加载器从系统属性sun.boot.class.path所指定的目录中加载类库。根类加载器的实现依赖于底层操作系统（由C++编写），属于虚拟机的实现的一部分，它并没有继承java.lang.ClassLoader类 扩展类加载器（Extension）:它的父加载器为根类加载器。它从java.ext.dirs系统属性所指定的目录中加载类库，或者从JDK的安装目录的jre\\lib\\ext子目录（扩展目录）下加载类库，如果把用户创建的JAR文件放在这个目录下，也会自动由扩展类加载器加载。扩展类加载器是纯Java类，是java.lang.ClassLoader类的子类。 扩展类加载器只会去加载.jar结尾的文件，而不会去加载.class结尾的文件。 系统/应用类加载器（System）（AppClassLoader）:也称为应用类加载器，它的父加载器为扩展类加载器。它从环境变量classpath或者系统属性java.class.path所指定的目录中加载类，它是用户自定义的类加载器的默认父加载器。系统类加载器是纯Java类，是java.lang.ClassLoader类的子类。 用户自定义的类加载器 用户自己定制的java.lang.ClassLoader的子类。 根类加载器 &gt; 扩展类加载器 &gt; 系统/应用类加载器 &gt; 自定义的类加载器(箭头左边为箭头右边的父加载器，但是它们之间的关系并不是继承) 拓展类加载器与应用加载器是由根类加载器去加载的。 ✎✎✎加载信息的打印可用-XX:+TraceClassLoading这个vm参数打印vm加载类的信息。 ✎✎✎✎类加载的机制类加载器用来把类加载到Java虚拟机中。从JDK1.2版本开始，类的加载过程采用双亲委托机制，这种机制能更好地保证Java平台的安全。在此委托机制中，除了Java虚拟机自带的根类加载器以外，其余的类加载器都有且只有一个父加载器。当Java程序请求加载器loader1加载Sample类时，loader1首先委托自己的父加载器去加载Sample类，若父加载器能加载，则由父加载器完成加载任务，否则才由加载器loader1本身加载Sample类。 ✎✎✎✎✎获取类加载器的途径 获得当前类的ClassLoader：clazz.getClassLoader()。 获得当前线程上下文的ClassLoader：Thread.currentThread().getContextClassLoader()。 获得系统的ClassLoader：ClassLoader.getSystemClassLoader()。 获得调用者的ClassLoader：DriverManager.getCallerClassLoader()。 ✎✎✎✎✎✎数组的类加载器数组的Class对象不是由类加载器加载的，而是由虚拟机动态生成的。如果数组元素是原生类型，那么调用数组的getClassLoader()方法将会返回null，否则返回的是加载元素的类加载器。 ✎✎✎✎✎✎✎代码示例1、获取当前类的ClassLoader1234567public class Test&#123; public static void main(String[] args)&#123; Class&lt;?&gt; clazz = Class.forName(\"java.lang.String\"); //获得String类的加载器 ClassLoader classLoader = clazz.getClassLoader(); &#125; &#125; 加载java.lang.String的类加载器是根类加载器，所以HotSpot虚拟机输出为null。（但是有些虚拟机不是输出为Null，并没有严格的规定）Class.forName的类加载器默认是调用者的类加载器。且所加载的类默认会被初始化。 Reflection.getcallerClass()可以知道调用者是哪个类。 2、获取父加载器12345678public class Test&#123; public static void main(String[] args)&#123; //获得系统类加载器（AppClassLoader） ClassLoader classLoader = ClassLoader.getSystemClassLoader(); //获得系统类加载器的父加载器，也就是拓展类加载器（ExtClassLoader） classLoader = classLoader.getParent(); &#125; &#125; 3、自定义ClassLoaderDemo112345678910111213141516171819202122232425262728public class MyClassLoader extends ClassLoader&#123; private String classLoaderName; public MyClassLoader(String classLoaderName) &#123; super();//将AppClassLoader作为父加载器 this.classLoaderName = classLoaderName; &#125; public MyClassLoader(ClassLoader parent, String classLoaderName) &#123; super(parent);//将parent作为父加载器 this.classLoaderName = classLoaderName; &#125; public Class&lt;?&gt; findClass(String className) throws ClassNotFoundException &#123; //byte [] bytes = ... 通过className读取到字节数组 return this.defineClass(className , bytes , 0 ,bytes.length); &#125; public static void main(String[] args) throws Exception &#123; MyClassLoader classLoader = new MyClassLoader(\"MyClassLoader\"); Class&lt;?&gt; clazz =classLoader.loadClass(\"LoaderTest\"); Object object =clazz.newInstance(); &#125;&#125;class LoaderTest&#123; &#125; loadClass的流程： 若已经加载过此class，则直接返回内存里的Class对象。 否则用父加载器去加载此class。 若还是加载不成功，则调用findClass方法去加载class。 问题1：jvm在启动时，类加载器A根据.class文件创建相应的Class对象，如果后续此类加载器通过LoadClass手动生成Class对象，这两个Class对象有无联系？ 答：LoadClass在加载类的时候，会判断此类是不是已经在命名空间内，如果在，则直接返回Class对象。所以这两个Class对象其实是指向同一个地址的。 问题2：假设有对象TT，首先new TT()（也就是首次主动调用），后续通过LoadClass手动生成TT的Class对象，再通过newInstance()方法生成一个TT对象，那么后者还算是首次主动调用吗？ 答：如果这两个Class对象是同一个，那么就不算是“首次主动使用”。 问题3：上述代码要怎么体现双亲委托机制？如果用MyClassLoader去加载类，因为它的Parent ClassLoader是AppClassLoader（默认情况下），从而会一直往上委托，那么实际上加载类的应该是BootStrap ClassLoader？ 答：每一个类加载器都有自己指定加载类的路径。每一个类加载器都执行这样的逻辑：如果Parent ClassLoader加载不到才由自己本身去加载.class。 问题4：在什么情况下ClassLoader才会判断自己无法加载类？ 答：在自己的findClass方法逻辑中定义的。 问题5：发现一个很严重的问题：上述的Demo中findClass方法没有被调用。 答：因为LoadClass这个方法会先调用父加载器（本例中为AppClassLoader）去加载class。而不会往下走（执行findClass方法）。把上述例子中的class文件放到classpath外,就会调用findClass方法了。 问题6：Class&lt;?&gt; clazz = TT.class这段代码会导致类的加载吗？如果会被加载，那么是被哪个加载器加载？ 答：会导致类的加载，类加载器将是当前线程上下文类加载器。 问题7：如果新建两个MyClassLoader实例去加载classpath外的.class文件，会调用findClass两次（说明“类只会加载一次”的说法不成立？）。 答：由于实例不同，此时命令空间已经不同了，当然会去加载两次。 问题8：如果系统加载器与自定义加载器均加载了同样的类（内存中存在两个Class对象），那么Class&lt;?&gt; clazz = TT.class这样子调用的流程又会是怎么样？ 答：如果是加载了此全类名相同的类，那么说明自定义加载器与系统加载器没有任何关系。那么这一句代码使用的类加载器将会是线程上下文类加载器。 问题9：自定义加载器加载的类可以引用系统加载器加载的类吗？ 答：如果自定义加载器与系统加载器无任何关系，那么两者的类是完全隔离的。 若有两个jar包，两个包都存在全类名相同的类，那么会加载路径在前的jar包。 ✎✎✎✎✎✎✎✎命名空间1、定义每个类加载器都有自己的命名空间，命名空间由该加载器及所有父加载器所加载的类组成。在同一个命名空间中，只会存在一个类。 本质上就是同一个加载器（同一个实例）不会加载一个类两次。 ✎✎✎✎✎✎✎✎✎类之间的引用每个类都会使用自己的类加载器（即加载自身的类加载器）来去加载所依赖的类。 比如，如果A引用了B类，假设A类的定义类加载器是a，那么此时B类也会被a去加载（前提是a未被加载）。 问题1：如果.class（全类名名相同）由两个不同的类加载器加载，生成两个Class对象，那么由这两个Class对象生成的实例会有什么不同？ 1、既然全类名相同的两个.class能被两个不同的类加载器加载，说明这两个加载器不存在任何关系，否则在 委托加载的机制下，其中一个加载器肯定会委托另外一个加载器加载的。 2、由这两个全类名相同的Class对象生成的实例实际上不是同一个类型。 3、所以实际上类型 = classloader实例 + 全类名。 问题2：如果用同一个classloader实例去加载全类名相同的两个类（存放路径不同），那么结果会是如何？ 答：以先加载的那个.class为准。后面的会被忽略。因为在后面加载时，加载器会认为此类已经被加载过了（即使存放的路径不同）。 ✎✎✎✎✎✎✎✎✎✎双亲委托机制的好处 因为所有的类加载的上层加载器中都必然会有bootstrap classloader。所以能确保java核心类库（sun.boot.class.path下的类）是由bootstrap classloader 所加载的，确保了核心库的安全。 除了sun.boot.class.path下的类，我们可以通过自定义的加载器创建其他类的独立命名空间。 ✎✎✎✎✎✎✎✎✎✎✎Launcher Launcher是由根类加载器去加载的。 1、自定义系统类加载器根据java.lang.ClassLoader#getSystemClassLoader的描述可知，我们执行以下步骤指定自定义的类加载器为系统类加载器。 自定义类加载器必须要有一个构造方法，它的参数是ClassLoader。（用来指定自定义类加载器的parent classloader）。 自定义类加载器由原来默认的系统类加载器加载。且它的parent classloader是默认的系统类加载器。 通过java.system.class.loader 属性指定自己实现的加载器为系统类加载器。 2、Launcher的构造在Launcher的构造方法中，构造了ExtClassLoader与AppClassLoader。 ✎✎✎✎✎✎✎✎✎✎✎✎线程上下文类加载器 Thread类的类加载器是BootStrap ClassLoader。 线程上下文类加载器是从JDK 1.2开始引入的，Thread类中的getcontextclassLoader()与setContextClassLoader(ClassLoader cl)分别用来获取和设置上下文类加载器。如果没有显示对上下文类加载器进行设置的话，线程将继承其父线程的上下文类加载器。Java应用运行时的初始线程的上下文类加载器是系统类加载器。 在双亲委托机制下，父加载器是不能使用子加载器所加载的类的。但是如果使用父加载器的线程中设置线程上下文加载器为子加载器，就可以解决这个问题了。 这在SPI（Service Provider Interface）中很常见，比如说JDBC等。对于SPI来说，有些接口是Java核心库所提供的，而Java核心库是由启动类加载器来加载的，而这些接口的实现却来自于不同的jar包（厂商提供），一般情况下Java的启动类加载器是会加载其他来源的jar包，这样传统的双亲委托模型就无法满足SPI的要求。而通过给当前线程设置上下文类加载器，就可以由设置的上下文类加载器来实现对于接口实现类的加载。 这种场景如果用spring去实现是不是也能很好的解决呢？只关注实例bean，而不关注类。 线程上下文器的使用的代码示例123456789101112public class Test&#123; public void use()&#123; Claastoader originClassloader = Thread.currentehread().getcontextclaastoader(); try&#123; //设置为目标类加载器 Thread.currentThread().setcontextclassloader(targetClassLoader); //dosomething 做一些类加载的操作 &#125;finally&#123; Thread.currentThread().setcontextclassloader(originClassloader); &#125; &#125;&#125; ✎✎✎✎✎✎✎✎✎✎✎✎✎jar hell问题的定位 1234567891011121314public class Test &#123; public static void main(String[] args) throws IOException &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); String resourceName = \"Test.class\"; Enumeration&lt;URL&gt; urls = cl.getResources(resourceName); while (urls.hasMoreElements())&#123; URL url = urls.nextElement(); System.out.println(url); &#125; &#125;&#125; 上述demo可以打印出Test.class存在哪几个jar包中。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"深入理解JVM[课程]","slug":"学习笔记/JVM/深入理解JVM-课程","permalink":"http://yoursite.com/categories/学习笔记/JVM/深入理解JVM-课程/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"04 | 算法","slug":"网课_JVM_04_算法","date":"2019-10-16T16:33:49.000Z","updated":"2020-01-07T08:21:41.534Z","comments":true,"path":"2019/10/17/网课_JVM_04_算法/","link":"","permalink":"http://yoursite.com/2019/10/17/网课_JVM_04_算法/","excerpt":"","text":"✎复制算法1、使用场景年轻代中使用的是Minor GC，这种GC算法采用的是复制算法（Copying）。 2、原理对象在Eden（包括一个Survivor区域，这里假设是from区域）出生，在经过一次MinorGC后，如果对象还存活并且能够被另外一块Survivor区域所容纳（上面已经假设为from区域，这里应为to区域，即to区域有足够的内存空间来存储Eden和from区域中存活的对象），则使用复制算法将这些仍然还存活的对象复制到另外一块Survivor区域（即to区域）中，然后清理所使用过的Eden以及Survivor区域（即from区域），并且将这些对象的年龄设置为1，此时from区与to区角色交换。以后对象在Survivor区每熬过一次MinorGC，就将对象的年龄+1，当对象的年龄达到某个值时（默认是15岁，通过-XX:MaxTenuringThreshold来设定参数），这些对象就会成为老年代。当to区被填满时，则所有对象都会移动到老年区。 一些大对象会直接被分配在永久区。 3、优点 不会产生内存碎片 4、缺点 浪费“to区域”的空间。 当对象存活率高时，复制的时间会比较长。 ✎✎标记清除1、使用场景Full GC算法是由标记清除算法（Mark-Sweep）实现或是标记清除/整理算法混合实现。 2、原理 标记：从根集合开始扫描，对存活的对象进行标记。（第一次扫描） 清除：扫描整个内存空间，回收未被标记的对象。（第二次扫描） 为什么要两次扫描？不能第一遍扫描直接清除吗？ 3、优点不需要额外空间。 4、缺点 两次扫描，耗时严重。 会产生内存碎片。 ✎✎✎标记整理1、使用场景Full GC算法是由标记清除算法（Mark-Sweep）实现或是标记清除/整理算法混合实现。 2、原理基于标记清除算法下，再将内存空间整理一遍，消灭内存碎片。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"网课_JVM","slug":"学习笔记/JVM/网课-JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/网课-JVM/"}],"tags":[]},{"title":"03 | 堆","slug":"网课_JVM_03_堆","date":"2019-10-14T16:53:25.000Z","updated":"2020-01-07T08:21:41.529Z","comments":true,"path":"2019/10/15/网课_JVM_03_堆/","link":"","permalink":"http://yoursite.com/2019/10/15/网课_JVM_03_堆/","excerpt":"","text":"✎堆的结构当伊甸园的空间用完时，程序又需要创建对象，JVM的垃圾回收器将对伊甸区进行Minor GC。然后将伊甸区中的剩余对象移动到幸存0区。若幸存0区也满了，则对0区进行Minor GC，然后移动到1区。如果1区也满了，则对1区进行Minor GC，再将剩余对象移动到养老区。若养老区也满了，那么这个时候将产生Full GC（Major GC）。若养老区执行了Full GC之后发现依然无法进行对象的保存，就会产生OOM。 1、新生区新生区又分为两部分： 伊甸区（Eden space）。 幸存者区（Survivor pace）。 新生区进行的是Minor GC。Eden:Survivor0:Survivor1的比例默认是8:1:1。 2、养老区养老区进行的是Full GC（Major GC）。 Full GC偶尔会对新生代、永久代进行GC。连接池对象一般都在这个区活跃。 3、永久区永久区不会被回收。用于存放JDK自身所携带的Class，Interface的元数据（例如Object类）。 4、方法区java1.8以前，可以理解为永久区是方法区的实现。 ✎✎代码体现1、查看当前可以使用的最大堆内存1Runtime.getRuntime().maxMemory()/1024/1024) ✎✎异常分析1、java.lang.OutOfMemoryError:Java heap space Java虚拟机设置的堆内存不够大。 代码中创建了大量大对象，并且长时间不能被垃圾收集器收集（一直被引用）。 2、java.lang.0utOfMemoryError:PermGen space Java虚拟机对永久代Perm内存设置不够。 一般出现这种情况，都是程序启动需要加载大量的第三方jar包。例如：在一个Tomcat下部署了太多的应用。或者大量动态反射生成的类不断被加载，最终导致Perm区被占满。 ✎✎✎JDK版本 Jdk1.6及之前：有永久代，常量池在方法区。 Jdk1.7：有永久代，常量池在堆。 Jdk1.8及之后：无永久代，常量池1.8在元空间。 ✎✎✎✎堆的配置与GC1、java1.7 2、java1.8 ✎✎✎✎✎堆内存调优1、配置 -Xms：设置初始分配大小，默认为物理内存的1/64。 -Xmx：最大分配内存，默认为物理内存的1/4。 -XX:+PrintGCDetails：输出详细的GC处理日志。 注意：上述分配的堆空间不包含元数据区/方法区，只有新生区和老年区。 2、代码12345678public static void main(String[] args)&#123; //返回 Java 虚拟机试图使用的最大内存量。 long maxMemory = Runtime.getRuntime().maxMemory(); //返回 Java 虚拟机中的内存总量。 long totalMemory = Runtime.getRuntime().totalMemory(); System.out.println(\"MAX_MEMORY = \" + maxMemory + \"（字节）、\" + (maxMemory / (double)1024 / 1024) + \"MB\"); System.out.println(\"TOTAL_MEMORY = \" + totalMemory + \"（字节）、\" + (totalMemory / (double)1024 / 1024) + \"MB\");&#125;","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"网课_JVM","slug":"学习笔记/JVM/网课-JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/网课-JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"02 | 栈","slug":"网课_JVM_02_栈","date":"2019-10-13T11:21:32.000Z","updated":"2020-01-07T08:21:41.529Z","comments":true,"path":"2019/10/13/网课_JVM_02_栈/","link":"","permalink":"http://yoursite.com/2019/10/13/网课_JVM_02_栈/","excerpt":"","text":"1、栈是什么？栈也叫栈内存，主管Java程序的运行，是在线程创建时创建，它的生命期是跟随线程的生命期，线程结束栈内存也就释放，对于栈来说不存在垃场回收问题，只要线程一结束该栈就Over，生命周期和线程一致，是线程私有的。基本类型的变量和对象的引用变量都是在函数的栈内存中分配。 2、栈帧的存储栈帧中主要保存3类数据： 本地变量（Local Variables）：输入参数和输出参数以及方法内的变量。 栈操作（Operand Stack）：记录出栈、入栈的操作。 栈帧数据（Frame Data）：包括类文件、方法等等。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"网课_JVM","slug":"学习笔记/JVM/网课-JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/网课-JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"04 | Kafka消费者--向Kafka读取数据","slug":"Kafka权威指南_04_Kafka消费者--从Kafka读取数据","date":"2019-10-09T12:56:59.000Z","updated":"2020-03-16T12:32:21.390Z","comments":true,"path":"2019/10/09/Kafka权威指南_04_Kafka消费者--从Kafka读取数据/","link":"","permalink":"http://yoursite.com/2019/10/09/Kafka权威指南_04_Kafka消费者--从Kafka读取数据/","excerpt":"","text":"✎消费者组1、分配分区每个消费者组有一个自己的群组协调器（broker），当消费者要加入群组时，它会向协调器发送一个JoinGroup请求。第一个加入群组的消费者将成为“群主”。群主可以从协调器那里获得组员的所有信息，并为组员分配分区（通过实现PartitionAssignor接口的类）。群主将分配情况发送给群组协调器，再由群组协调器发送给所有组员。每当消费者离开（主动断开或心跳失败）时会触发再均衡，此时会再重新分区。 新组员加进来时，是否也会触发再均衡？ 消费者会在轮询消息或提交偏移量时，发送心跳消息。如果消费组里的消费者，超过主题的分区数量，那么有一部分消费者就会被闲置，不会接收到任何消息。 ✎✎消费者的配置1、group.id指定组id。 2、fetch.min.bytes与fetch.max.wait.msfetch.min.bytes表示消费者从服务器获取记录的最小字节数。fetch.max.wait.ms表示获取数据时的等待时间，默认为500ms。两者哪个先被满足就会接收消息。 3、max.partition.fetch.bytes该属性指定了服务器从每个分区里返回给消费者的最大字节数。它的默认值是1MB。 4、session.timeout.ms与heartbeat.interval.mssession.timeout.ms指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认是3s。heartbeat.interval.ms指定了poll()方法向协调器发送心跳的频率。一般是session.timeout.ms的三分之一。 5、auto.offset.reset该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的记录已经过时并被删除）该作何处理。 latest。默认值，从最新的记录开始读。 earliest。从起始的记录开始读。 6、enable.auto.commit是否自动提交偏移量。默认值为true。可以通过auto.commit.interval.ms（默认为5S）来控制自动提交的频率。 7、partition.assignment.strategy分区分配的策略： Range：把主题的若干个连续的分区分配给消费者。 RoundRobin：把主题的所有分区逐个分配给消费者。 8、client.id客户端Id。 9.max.poll.records该属性用于控制单次调用call()方法能够返回的记录数量。 10.receive.buffer.bytes 和send.buffer.bytesTCP的缓冲区配置。默认为-1（使用操作系统默认值）。 ✎✎✎提交1、手动提交偏移量enable.auto.commit设置为false。并手动调用commitSync()或commitASync()。 2、同步提交与异步提交 commitSync()：同步提交。如果出错会重试。 commitASync()：异步提交。如果出错不会重试，因为如果重试的话有可能会让偏移量小的提交覆盖偏移量大的提交。 解决方法：因为异步提交支持回调，所以可以在本地记录上一次已成功提交的偏移量，在回调方法中，若提交失败则根据当前提交偏移量与本地保存的偏移量决定是否要重试。 默认情况下，手动提交默认都是提交最后一个偏移量，也可以指定提交特定的偏移量。 3、同步提交与异步提交结合伪代码实现如下：123456try&#123; poll(); commitASync();&#125;finally&#123; commitSync();&#125; ✎✎✎✎再均衡监听器1、步骤 实现ConsumerRebalanceListener这个类。 在subscribe时，传入ConsumerRebalanceListener实现类。 2、作用当发生分区再均衡/分区被分配时，可以通知到消费者，这时我们可以做一些相应的操作（如强制提交偏移量等）。还可以结合seek()方法，在本地维护偏移量（将处理消息与保存偏移量放在同一个事务中）。可以实现消息的“零重复/零丢失”。 ✎✎✎✎✎安全的退出可以通过consumer.wakeup()方法退出poll()，并且poll()能抛出WakeupException，在退出时最好要调用consumer.close(),因为它会主动地像群组协调器发送自己要离开的消息，而不用等到超时触发再均衡。并且还能主动提交任何还未提交的东西。 ✎✎✎✎✎✎读取特定的分区可以通过comsumer.assign()方法去读取特定的分区，此时就不需要订阅主题，也不需要群组了。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"Kafka权威指南","slug":"学习笔记/Kafka/Kafka权威指南","permalink":"http://yoursite.com/categories/学习笔记/Kafka/Kafka权威指南/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"03 | Kafka生产者--向Kafka写入数据","slug":"Kafka权威指南_03_Kafka生产者--向Kafka写入数据","date":"2019-10-08T11:33:31.000Z","updated":"2020-01-07T08:21:41.403Z","comments":true,"path":"2019/10/08/Kafka权威指南_03_Kafka生产者--向Kafka写入数据/","link":"","permalink":"http://yoursite.com/2019/10/08/Kafka权威指南_03_Kafka生产者--向Kafka写入数据/","excerpt":"","text":"✎生产者发送流程 ✎✎生产者配置参数1、bootstrap.servers指定broker地址，建议设置两个以上。不必要设置全部broker，因为只要连上一个broker，就能查找到其他broker的信息。 2、acks这个参数指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的。(只有0、1、all这三个参数) 3、buffer.memory该参数用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。这个时候，send()方法调用要么被阻塞，要么抛出异常，取决于如何设置max.block.ms参数。 4、retries这个参数指定了当发送消息时，返回可重试错误时，生产者重试发送的次数。默认重试间隔为100ms，可通过retry.backoff.ms改变这个间隔。 5、batch.size与linger.msbatch.size指定了一个批次可以使用的内存大小（按照字节数计算）。linger.ms指定了一个批次在等待到达batch.size时的最大等待时间。 6、max.in.flight.requests.per.connection该参数指定了生产者在收到服务器响应之前可以发送多少个消息。把它设为1可以保证消息是按照发送的顺序写入服务器的，即使发生了重试。 7、timeout.ms、request.timeout.ms和metadata.fetch.timeout.ms request.timeout.ms指定了生产者在发送数据时等待服务器返回响应的时间。 metadata.fetch.timeout.ms指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间。如果等待响应超时，那么生产者要么重试发送数据，要么返回一个错误（抛出异常或执行回调）。 timeout.ms指定了broker等待同步副本返回消息确认的时间，与asks的配置相匹配。 8、max.block.ms该参数指定了在调用send()方法或使用partitionsFor()方法获取元数据时生产者的阻塞时间。 9、max.request.size该参数用于控制生产者发送的请求大小。 ✎✎✎生产者发送消息KafkaProducer在发送消息时一般会发生两类错误： 可重试错误。如连接错误、“无主”错误等。可配置成自动重试。 不可重试错误。如“消息太大”错误，会直接抛出异常。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"Kafka权威指南","slug":"学习笔记/Kafka/Kafka权威指南","permalink":"http://yoursite.com/categories/学习笔记/Kafka/Kafka权威指南/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"02 | 安装Kafka","slug":"Kafka权威指南_02_安装Kafka","date":"2019-10-08T06:36:33.000Z","updated":"2020-01-07T08:21:41.403Z","comments":true,"path":"2019/10/08/Kafka权威指南_02_安装Kafka/","link":"","permalink":"http://yoursite.com/2019/10/08/Kafka权威指南_02_安装Kafka/","excerpt":"","text":"✎常规配置1、zookeeper.connect该配置参数是用冒号分隔的一组hostname:port/path列表。/path是可选的Zookeeper路径，作为Kafka集群的chroot环境。如果不指定，默认使用根路径。如果指定的chroot路径不存在，broker会在启动的时候创建它。最好是配置/path，那么一个Zookeeper下就可以存在多个kafka集群了而不会发生冲突了。 2、log.dirs如果指定了多个路径，那么broker会根据“最少使用”原则，把同一个分区的日志片段保存到同一个路径下。要注意，broker会往拥有最少数目分区的路径新增分区，而不是往拥有最小磁盘空间的路径新增分区。 3、num.recovery.threads.per.data.dir对于如下3种情况，Kafka会使用可配置的线程池来处理日志片段： 服务器正常启动，用于打开每个分区的日志片段。 服务器崩溃后重启，用于检查和截短每个分区的日志片段。 服务器正常关闭，用于关闭日志片段。 默认情况下，每个日志目录只使用一个线程。所配置的数字对应的是log.dirs指定的单个日志目录，如果num.recovery.threads.per.data.dir被设为8，并且log.dirs指定了3个路径，那么总共需要24个线程。配置多个线程，对于包含大量分区的服务器来说，一旦发生崩溃，在进行恢复时使用并行操作可能会省下数小时的时间。 ✎✎主题配置1、数据的保留参数配置 log.retention.ms/minutes/hours log.retention.bytes log.segment.ms log.segment.bytes 上面的参数都是作用在分区上的，当达到segment的限制时，日志片段就会被关闭。此时这个片段就进入等待删除阶段。当等待删除阶段达到了retention限制，这个日志片段就会被删除。retention是通过检查磁盘上日志片段文件的最后修改时间来实现的。所以如果移动了处于等待删除阶段的日志片段文件导致最后修改时间改变，那么删除的数据就会不准确。 2、message.max.bytes这个参数用来限制单个消息的大小，默认是1000000（1MB）。若超过这个大小，broker会返回错误。这个参数必须要与消费者的fetch.message.max.bytes与集群里broker的replica.fetch.max.bytes进行协调，否则若fetch.message.max.bytes与replica.fetch.max.bytes小于这个参数，那么会出现堵塞的情况。 ✎✎✎操作系统调优1、vm.swappiness默认为60，表示剩余内存低于40%时，使用交换空间。0意味着“在任何情况下都不要发生交换”。所以现在建议把这个值设为1。 2、vm.dirty_background_ratio与vm.dirty_ratio当脏页数量到达vm.dirty_background_ratio时，会触发刷新进程异步地将脏页写入磁盘。应设置为小于10（大部分情况下设为5即可）。当脏页数量到达vm.dirty_ratio时，会触发刷新进程同步地将脏页写入磁盘，此时写操作阻塞。可以设置得大一些（60~80）。 当达到vm.dirty_background_ratio阈值时，触发异步写入磁盘进程，若此时写缓存的速度大于写入磁盘的速度，那么脏页数量就会一直增加，直到达到vm.dirty_ratio阈值，此时同步将缓存的数据写入硬盘，不给写缓存。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"Kafka权威指南","slug":"学习笔记/Kafka/Kafka权威指南","permalink":"http://yoursite.com/categories/学习笔记/Kafka/Kafka权威指南/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"01 | 初识Kafka","slug":"Kafka权威指南_01_初识Kafka","date":"2019-10-08T05:59:29.000Z","updated":"2020-01-07T08:21:41.402Z","comments":true,"path":"2019/10/08/Kafka权威指南_01_初识Kafka/","link":"","permalink":"http://yoursite.com/2019/10/08/Kafka权威指南_01_初识Kafka/","excerpt":"","text":"✎消息模式 模式 强类型转换 消息模式升级 传统的json、xml 不支持 不支持 序列化框架（如Apache Avro） 支持 支持，可向前/向后兼容，消除消息读写操作之间的耦合性 ✎✎集群之间的消息复制Kafka的消息复制机制只能在单个集群里进行，不能在多个集群之间进行。可使用MirrorMaker实现集群间的消息复制。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"Kafka权威指南","slug":"学习笔记/Kafka/Kafka权威指南","permalink":"http://yoursite.com/categories/学习笔记/Kafka/Kafka权威指南/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"01 | JVM架构介绍","slug":"网课_JVM_01_jvm架构介绍","date":"2019-09-22T04:35:19.000Z","updated":"2020-01-07T08:21:41.527Z","comments":true,"path":"2019/09/22/网课_JVM_01_jvm架构介绍/","link":"","permalink":"http://yoursite.com/2019/09/22/网课_JVM_01_jvm架构介绍/","excerpt":"","text":"JVM架构图 1、方法区（Method Area）方法区是被所有线程共享，所有字段和方法字节码，以及一些特殊方法如构造函数，接口代码也在此定义。简单说，所有定义的方法的信息都保存在该区域，此区属于共享区间。 静态变量+常量+类信息+运行时常量池存在方法区中。 2、执行引擎（Execution Engine）负责解释命令，提交操作系统执行。 3、运行时数据区（Runtime Data Area）RunTimeException是在这里抛出来的。 4、类加载器（ClassLoader）负责加载class文件，class文件在 文件开头有特定的文件标识，并且ClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定。 5、程序计数器（PCRegister）每个线程都有一个程序计数器，就是一个指针，指向方法区中的方法字节码（下一个将要执行的指令代码），由执行引擎读取下一条指令，是一个非常小的内存空间，几乎可以忽略不记。 栈管运行，堆管存储。只有方法区与堆是线程共享的。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"JVM","slug":"学习笔记/JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/"},{"name":"网课_JVM","slug":"学习笔记/JVM/网课-JVM","permalink":"http://yoursite.com/categories/学习笔记/JVM/网课-JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"}]},{"title":"03 | Kafka核心组件","slug":"Kafka入门与实践_03_Kafka核心组件","date":"2019-09-17T03:14:12.000Z","updated":"2020-01-07T08:21:41.400Z","comments":true,"path":"2019/09/17/Kafka入门与实践_03_Kafka核心组件/","link":"","permalink":"http://yoursite.com/2019/09/17/Kafka入门与实践_03_Kafka核心组件/","excerpt":"","text":"✎延迟操作组件1、DelayedOperationDelayedOperation框架DelayedOperation调用流程 TimerTask.cancel()：将该延迟操作从TimerTaskList链表中移除。 forceCompete()：调用TimerTask.cancel()，并且当completed为true时，调用onComplete()方法，确保onComplete()只被调用一次。 safeTryComplete()：以synchronized同步锁调用onComplete()方法，供外部调用。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"Kafka入门与实践","slug":"学习笔记/Kafka/Kafka入门与实践","permalink":"http://yoursite.com/categories/学习笔记/Kafka/Kafka入门与实践/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"01 | Kafka简介","slug":"Kafka入门与实践_01_Kafka简介","date":"2019-09-16T11:36:56.000Z","updated":"2020-01-07T08:21:41.399Z","comments":true,"path":"2019/09/16/Kafka入门与实践_01_Kafka简介/","link":"","permalink":"http://yoursite.com/2019/09/16/Kafka入门与实践_01_Kafka简介/","excerpt":"","text":"✎Leader副本和Follower副本如果采用“所有副本都同时负责读/写请求处理”这种方式，那么得保证这些副本之间数据的一致性，假设有n个副本则需要有n x n条通路来同步数据，这样数据的一致性和有序性就很难保证。而采用“Leader副本进行读写，Follower副本从Leader副本同步消息”这种方式，对于n个副本只需n-1条通路即可。 上述采用第一种方式，通路数应该是n x (n - 1)，原书作者应该是算错了。其实这种方式就是Eureka注册中心的实现方式。 ✎✎消费者组如果不指定消费组，则该消费者属于默认消费组test-consumer-group。每个消费者也有一个全局唯一的id，通过配置项client.id指定，如果客户端没有指定消费者的id，Kafka会自动为该消费者生成一个全局唯一的id，格式为${groupld}-${hostName}-${timestamp}-${UUID前8位字符}。 ✎✎✎ISRKafka在ZooKeeper中动态维护了一个ISR（In-sync Replica），即保存同步的副本列表，该列表中保存的是与Leader副本保持消息同步的所有副本对应的代理节点id。 ✎✎✎✎高吞吐量的实现 Kafka充分利用磁盘的顺序读写，将数据写到磁盘。 同时，Kafka在数据写入及数据同步采用了零拷贝（zero-copy）技术，采用sendFile()函数调用，sendFile()函数是在两个文件描述符之间直接传递数据，完全在内核中操作。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"Kafka入门与实践","slug":"学习笔记/Kafka/Kafka入门与实践","permalink":"http://yoursite.com/categories/学习笔记/Kafka/Kafka入门与实践/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"06 | 大数据之Kafka_06_Kafka低级Api实战","slug":"大数据之Kafka_06_Kafka低级Api实战","date":"2019-09-16T07:04:16.000Z","updated":"2020-01-07T08:21:41.460Z","comments":true,"path":"2019/09/16/大数据之Kafka_06_Kafka低级Api实战/","link":"","permalink":"http://yoursite.com/2019/09/16/大数据之Kafka_06_Kafka低级Api实战/","excerpt":"","text":"✎消费使用步骤 获取指定的分区的leader 获取分区最新的消费进度 从leader拉取分区的消息 识别leader的变化，重试 ✎API实现1、参数定义1234567891011121314//定义相关参数ArrayList&lt;String&gt;brokers=new ArrayList&lt;&gt;();//kafika集群brokers.add(\"hadoop102\");brokers.add(\"hadoop103\");brokers.add(\"hadoop104\");//端口号int port=9092；//主题String topic=\"second\"；/分区int partition=0；//offset long offset=2; 2、获取分区leader1234567891011121314151617181920212223242526272829private BrokerEndPoint findLeader(List&lt;String&gt; brokers, int port, String topic, int partition)&#123; for(String broker : brokers)&#123; //创建获收分区leader的消费者对象 SimpleConsumer getLeader=new SimpleConsumer(broker , port , 1000, 1024*4 , \"getLeader\"); //创建一个主题元数据信息请求 TopicMetadataRequest topicMetadataRequest = new TopicMetadataRequest (Collections.singletonlist(topic)); //获取主题元数据返回信 TopicMetadataResponse metadataResponse = getLeader.send(topicMetadataRequest); //解析元数据返回值 List&lt;TopicMetadata&gt; topicsMetadata = metadataResponse.topicsMetadata(); //遍历主题元数据 for(TopicMetadata topicMetadatum : topicsMetadata)&#123; //获取多个分区的元数据信息 List&lt;PartitionMetadata&gt; partitionsMetadata = topicMetadatum.partitionsMetadata(); //遍历分区元数据 for(PartitionMetadata partitionMetadata : partitionsMetadata)&#123; //partition = 0 if(partition == partitionMetadata.partitionld())&#123; return partitionMetadata.leader()； &#125; &#125; &#125; &#125; return null;&#125; 3、获取分区数据12345678910111213141516171819202122232425262728private void getData(List&lt;String&gt; brokers, int port, String topic, int partition, long offset)&#123; //获取分区leader BrokerEndPoint leader = findLeader(brokers, port, topic, partition); if(leader == null)&#123; return; &#125; String leaderHost = leader.host(); //获取数据的消费者对象 SimpleConsumer getData = new SimpleConsumer (leaderHost, port, 1000, 1024*4, \"getData\"); //创建获取数据的对象,100表示获取返回的字节数 FetehRequest fetchRequest = new FetehRequestBuilder().addFetch(topic, partition, offset, 100).build(); //获取数据返回值 FetchResponse fetchResponse=getData.fetch(fetchRequest); //解析返回值 ByteBufferMessageSet messageAndoffsets = fetchResponse.messageSet(topic，partition); for(MessageAndOffset messageAndOffset : messageAndOffsets)&#123; long offset1 = messageAndOffset.offset(); ByteBuffer payload = messageAndOffset.message().payload(); byte[] bytes = new byte[payload.limit()]; payload.get(bytes); System.out.println(offset1+\"—\"+new String(bytes)); &#125;&#125;","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"大数据之Kafka","slug":"学习笔记/Kafka/大数据之Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/大数据之Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"08 | 泛型程序设计","slug":"Java核心技术卷1_08_泛型程序设计","date":"2019-09-11T06:15:35.000Z","updated":"2020-01-07T08:21:41.399Z","comments":true,"path":"2019/09/11/Java核心技术卷1_08_泛型程序设计/","link":"","permalink":"http://yoursite.com/2019/09/11/Java核心技术卷1_08_泛型程序设计/","excerpt":"","text":"✎泛型的定义1、泛型类的定义123public class MyPair &lt;T,U&gt;&#123; private T data;&#125; 泛型类可以有多个类型变量。像上面的T、U。类型变量使用大写形式，且比较短。 2、泛型方法的定义12345public static &lt;T&gt; T say(T... a)&#123; return a[0];&#125;int result = MyMethod.&lt;Integer&gt;say(1,2,3); //这种调用可以省略 -&gt; MyMethod.say(1,2,3)。 1double result = MyMethod.say(3.14,1); 上面的方法会报错，原因是：编译器将会自动打包参数为1个Double和1个Integer对象，而后寻找这些类的共同超类型，以确定T究竟是什么类型。 12public final class Double extends Number implements Comparable&lt;Double&gt;;public final class Integer extends Number implements Comparable&lt;Integer&gt;; 由上面代码可知，Double和Integer的共同超类时Number，所以只要改成如下既不会报错：1Number result = MyMethod.say(3.14,1); 3、类型变量的限定123public static &lt;T extends Parent&amp;Serializable&gt; void say1(T a)&#123; a.say();&#125; 如果要调用这个方法，T必须要实现Parent接口和Serializable接口。限定中，可以有限定多个接口，但是只能限制一个父类，且父类必须放到第一位。 ✎泛型代码和虚拟机1、原始类型无论何时定义一个泛型类型， 都自动提供了一个相应的原始类型（raw type)。 Pair&lt;T&gt;的原始类型如下：123public class Pair &#123; private Object data;&#125; 因为T没有限定变量，所以T就被替换成Object类型，如果有限定变量，就替换为限定变量，如果有多个限定变量，就替换为第一个限定变量。Pair&lt;T extends Parent&gt;的原始类型如下：123public class Pair &#123; private Parent data;&#125; 1class Interval&lt;T extends Serializable &amp; Comparable&gt; 上面的声明是低效率的，因为原始类型用Serializable替换T, 而编译器在必要时要向Comparable插入强制类型转换。为了提高效率，应该将标签（tagging) 接口（即没有方法的接口，如上例中的Serializable）放在边界列表的末尾。 2、翻译泛型表达式12Pair&lt;Employee&gt; buddies = ...Employee buddy = buddies.getFirst(); 编译器把这个方法调用翻译为两条虚拟机指令： 对原始方法Pair.getFirst的调用，返回Object。 将返回的Object 类型强制转换为Employee类型。 当存取一个泛型域时也要插人强制类型转换。 3、翻译泛型方法和上面Pair的翻译方式类似。 4、桥方法 1234public class Employee&lt;T&gt; &#123; public T salary; //getter、setter&#125; 123456789public class Manager extends Employee&lt;Integer&gt;&#123; public void setSalary(Integer salary) &#123; this.salary = 10*salary; &#125; public Integer getSalary()&#123; return this.salary; &#125;&#125; 按照虚拟机的翻译方式，Employee里的setSalary(T salary)会被翻译成setSalary(Object salary)，此时Manager继承Employee就有了两个setSalary方法：setSalary(Integer salary)和setSalary(Object salary)。 按下面的调用方式：123Manager manager = new Manager();Employee&lt;Integer&gt; employee = manager;employee.setSalary(11); Employee的setSalary被翻译成setSalary(Object salary)，由于Manager也有setSalary(Integer salary)这个方法，所以按照多态，employee.setSalary(11)将会调用Employee的setSalary(Object salary)方法。 为了解决这个问题，编译器在Manager类中生成一个桥方法，如下：123public void setSalary(Object salary)&#123; set((Integer)salary);&#125; 这样的话就会调用Manager的setSalary(Integer salary)方法了。 同样道理，在虚拟机里Manager也会有Integer getSalary()方法和Object getSalary()方法，在Java里我们不能这样编写，因为方法签名是由方法名+参数组成，但是在虚拟机里用参数类型和返回类型确定一个方法，所以虚拟机可以正确处理这个情况。 Java 泛型转换的事实： 虚拟机中没有泛型，只有普通的类和方法。 所有的类型参数都用它们的限定类型替换。 桥方法被合成来保持多态。 为保持类型安全性，必要时插人强制类型转换。 ✎约束性与局限性1、不能用基本类型实例化类型参数不能用类型参数代替基本类型。因此，没有Pair, 只有Pair。原因是类型擦除之后， Pair类含有Object类型的域， 而Object不能存储double。 2、运行时类型查询只适用于原始类型123if (a instanceof Pair&lt;String&gt;) // Errorif (a instanceof Pair&lt;T&gt;) // Errorif (a instanceof Pair) //true 值得注意的点：123Pair pair = new Pair&lt;Employee&gt;();pair.setData(\"aa\");System.out.println(pair.getData().getClass()); //class java.lang.String 123Pair&lt;String&gt; stringPair = . .Pair&lt;Employee〉employeePair = . .if (stringPair.getClassO == employeePair.getClassO) // true 两次调用getClass都将返回Pair.class。 3、不能创建参数化类型的数组、1Pair&lt;String&gt;[] table = new Pair&lt;String&gt;[10]; // Error 不能创建参数化类型数组的原因: 假设这是合法的: 1Pair&lt;String&gt;[] table = new Pair&lt;String&gt;[10]; 擦除之后，table的类型是Pair[]。 那么可以把它转换为Object[]: 1Object[] objarray = table； 数组会记住它的元素类型（Pair），如果试图存储其他类型的元素，就会抛出一个ArrayStoreException异常（但是编译可以通过）： 1objarray[0] = \"Hello\"; // Error component type is Pair 不过对于泛型类型， 擦除会使这种机制无效。以下赋值： 1objarray[0] = new Pair&lt;Employee&gt;; 能够通过数组存储检査，不过这是一个类型错误。所以不允许这样子创建。 注意：只是不允许创建这些数组， 而声明类型为Pair&lt;String&gt;[]的变量仍是合法的。只是不能用new Pair&lt;String&gt;[10]初始化这个变量。 解决方法：可以声明通配类型的数组，然后进行类型转换：1Pair&lt;String&gt;[] table = (Pair&lt;String&gt;[]) new Pair&lt;?&gt;[10]; 为什么加个通配符就可以了？ 4、不能实例化类型变置123public Pair() &#123; data = new T(); &#125; // Error 通过反射调用Class.newlnstance方法来构造泛型对象。12345678public Pair(T t) &#123; this.data = t;&#125;public static &lt;T&gt; Pair&lt;T&gt; makePair(Class&lt;T&gt; cl) throws Exception &#123; return new Pair&lt;&gt;(cl.newInstance());&#125;Pair&lt;String&gt; p = Pair.makePair(String.class); 5、不能构造泛型数组123public static &lt;T extends Comparable&gt; T[] minmax(T[] a)&#123; T[] mm = new T[2]; //Error&#125; 类型擦除会让这个方法永远构造 Comparable[2] 数组。 如果数组仅仅作为一个类的私有实例域， 就可以将这个数组声明为Object[]，并且在获取元素时进行类型转换。例如,ArrayList类可以这样实现：123456789101112public class ArrayList&lt;E&gt;&#123; private Object[] elements; @SupressWarning(\"unchecked\") public E get(int n)&#123; return (E)elements[n]; &#125; public void set(int n , E e)&#123; elements[n] = e; &#125;&#125; 下面这个例子中，编译时不会有任何警告。但当Object引用强转为Comparable时，将会发生ClassCastException异常。12345public static &lt;T extends Comparable&gt; T[] minmax(T... a)&#123; Object[] mm = new Object[2]; ... return (T[])mm;&#125; 可以用如下方法解决（通过constr构造相符类型的数组）123456public static &lt;T extends Comparable&gt; T[] minmax(IntFunction&lt;T[]&gt; constr , T... a)&#123; T[] mm = constr.apply(2); ...&#125;String[] ss = minmax(String[]::new , \"Tom\" , \"Dick\", \"Harry\"); 用这种函数式接口，和匿名内部类的思想一样。重点要理解“延迟执行”（在这里把new数组的操作放到了方法内部） 还可以利用反射（老式）1234public static &lt;T extends Comparable&gt; T[] minmax(T... a)&#123; T[] mm = (T[])Array.newInstance(a.getClass().getComponentType() , 2); ...&#125; 6、不能在静态域或方法中引用类型变量1234567public class Singleton&lt;T&gt;&#123; private static T singleInstance;//Error public static T getSingleInstance()&#123; //Error ... &#125; &#125; 7、泛型类扩展Throwable是不合法的1public class Problem&lt;T&gt; extends Exception &#123;/*...*/&#125;//Error--can't extend Throwable 8、catch 子句中不能使用类型变量1234567public static &lt;T extends Throwable&gt; void doWork(Class&lt;T&gt; t)&#123; try &#123; //do work &#125; catch(T e)&#123; //Error--can't catch type variable &#125;&#125; 9、在异常规范中使用类型变量是允许的12345678public static &lt;T extends Throwable&gt; void doWork(T t) throws T&#123; //0K try&#123; //do work &#125; catch (Throwable realCause)&#123; t.initCause(realCause); throw t; &#125;&#125;","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java核心技术卷1","slug":"学习笔记/Java/Java核心技术卷1","permalink":"http://yoursite.com/categories/学习笔记/Java/Java核心技术卷1/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"07 | 异常","slug":"Java核心技术卷1_07_异常","date":"2019-09-09T11:53:31.000Z","updated":"2020-01-07T08:21:41.397Z","comments":true,"path":"2019/09/09/Java核心技术卷1_07_异常/","link":"","permalink":"http://yoursite.com/2019/09/09/Java核心技术卷1_07_异常/","excerpt":"","text":"✎Java异常层次结构 Error类层次结构描述了Java运行时系统的内部错误和资源耗尽错误。应用程序不应该抛出这种类型的对象。 Exception这个层次结构又分解为两个分支： RuntimeException：由程序错误导致的异常属于RuntimeException。其异常包含下面几种情况： 错误的类型转换。 数组访问越界。 访问null指针。 其他异常：由于像I/O错误这类问题导致的异常属于其他异常。其异常包含以下几种情况： 试图在文件尾部后面读取数据。 试图打开一个不存在的文件。 试图根据给定的字符串查找Class对象，而这个字符串表示的类并不存在。 如果出现RuntimeException异常，那么就一定是程序的问题。 派生于Error类或RuntimeException类的所有异常称为非受查（unchecked）异常，所有其他的异常称为受查（checked）异常。受查异常一定要try-catch捕获或者throw出去。 ✎✎异常相关代码编写1、合并 catch 子句12345try&#123; //code that might throw exceptions&#125;catch (IOException | FileNotFoundException e)&#123; e.printStackTrace();&#125; 只有当捕获的异常类型彼此之间不存在子类关系时才需要这个特性。捕获多个异常时， 异常变量隐含为final变量。 2、再次抛出异常与异常链在catch子句中可以抛出一个异常，这样做的目的是改变异常的类型，12345try&#123; ...&#125;catch (SQLException e)&#123; throw new IOException(e.getMessage());&#125; 可以有一种更好的处理方法，并且将原始异常设置为新异常的“原因”：1234567try&#123; ...&#125;catch (SQLException e)&#123; Throwable se = new IOException(\"Exception 转换\"); se.initCause(e); throw se;&#125; 当捕获到异常时， 就可以使用下面这条语句重新得到原始异常：1Throwable se = se.getCause(); 如果在一个方法中发生了一个受查异常，而不允许抛出它，那么包装技术就十分有用。我们可以捕获这个受查异常，并将它包装成一个运行时异常。 3、finally块抛异常假设在try语句块中的代码抛出了一些非IOException的异常，并throw了出去。最后执行finally语句块，并调用close方法。而close方法本身也有可能抛出IOException异常。当出现这种情况时，原始的异常将会丢失，转而抛出close方法的异常。 4、带资源的 try语句资源如果实现了AutoCloseable接口或者Closeable接口（Closeable是AutoCloseable的子接口），可以用如下方法关闭资源：123456try(PrintWriter writer = new PrintWriter(\"/\");PrintWriter writer1 = new PrintWriter(\"/\"))&#123; writer... writer1...&#125; catch (FileNotFoundException e) &#123; e.printStackTrace();&#125; 无论这个块是否正常退出，writer都会自动关闭。如果关闭的时候抛出异常，这些异常将自动捕获，并由addSuppressed方法增加到原来的异常。可以调用getSuppressed方法，它会得到从close方法抛出的异常列表。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java核心技术卷1","slug":"学习笔记/Java/Java核心技术卷1","permalink":"http://yoursite.com/categories/学习笔记/Java/Java核心技术卷1/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"03 | 内存管理","slug":"操作系统_03_内存管理","date":"2019-08-23T09:21:24.000Z","updated":"2020-01-07T08:21:41.472Z","comments":true,"path":"2019/08/23/操作系统_03_内存管理/","link":"","permalink":"http://yoursite.com/2019/08/23/操作系统_03_内存管理/","excerpt":"","text":"✎CPU结构 MMU（内存管理单元）：负责处理CPU的内存访问请求。 ✎✎内存结构 ✎✎✎地址空间与地址生成程序访问的地址空间是逻辑地址空间。逻辑地址空间需要由操作系统转换为物理地址空间（内存、硬盘）。 1、地址空间的定义 物理地址空间指的是硬件支持的地址空间。 逻辑地址空间是程序运行所拥有的内存范围。 2、逻辑地址的生成逻辑地址是由程序经过编译后生成的。 3、物理地址的访问 首先操作系统生成逻辑地址与物理地址的映射。 CPU中的计算逻辑单元（ALU）执行指令时，需要访问所传入的逻辑地址的内存内容。 CPU中的内存管理单元MMU寻找此逻辑地址与物理地址的映射。（若找不到映射，则去内存中找，CPU再缓存此映射） 逻辑地址与物理地址的映射关系不仅存储在MMU，还存储在内存。（由上可知，内存的映射表比MMU的还要大） CPU中的控制器发送读取此物理地址内存内容的请求。 内存通过总线传送相应的内存内容给CPU。 4、地址空间的独立访问这块不熟悉。 ✎✎✎✎内存碎片有两种内存碎片： 外部碎片：在分配单元间的未使用内存。 内部碎片：在分配单元内的未使用内存。 课程上都是为程序分配固定的内存。假设程序内部有逻辑会去存数据到内存中，这个内存要怎么再去分配呢？","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"操作系统","slug":"学习笔记/操作系统","permalink":"http://yoursite.com/categories/学习笔记/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/tags/操作系统/"}]},{"title":"02 | 系统调用、异常、中断","slug":"操作系统_02_系统调用、异常、中断","date":"2019-08-20T15:30:48.000Z","updated":"2020-01-07T08:21:41.472Z","comments":true,"path":"2019/08/20/操作系统_02_系统调用、异常、中断/","link":"","permalink":"http://yoursite.com/2019/08/20/操作系统_02_系统调用、异常、中断/","excerpt":"","text":"✎定义 系统调用（来源于应用程序）：应用程序主动向操作系统发出服务请求。 异常（来源于不良的应用程序）：非法指令或者其他坏的处理状态（如：内存出错）。 中断（来源于外设）：来自不同的硬件设备的计时器或网络的中断。 应用程序不能直接访问外设，需要通过内核间接的访问。 ✎✎应用程序的响应 中断：应用程序持续执行，中断对用户应用程序是透明的（用户应用程序感知不到中断），所以说中断对于应用程序来说是异步的。 异常：杀死或者重新执行意想不到的应用程序指令。异常对于应用程序来说是同步的。 系统调用：应用程序等待（阻塞）或者持续运行。所以系统调用对于应用程序来说既可以是同步也可以是异步的。 ✎✎✎中断处理过程 操作系统首先建立一个中断映射表，key是中断号，value是对应的服务例程。 外设设置中断标记，CPU根据中断标记会产生一个对应的中断号，并发送给操作系统。 操作系统保存当前执行程序的执行现场。 操作系统根据中断号找到对应的处理服务例程。 操作系统执行中断服务例程。 清除中断标记。 操作系统恢复之前被打断程序的执行现场。 ✎✎✎✎异常处理过程 操作系统首先建立一个异常映射表，key是异常编号，value是对应的服务例程。 程序执行过程中发生了异常时，会发送一个异常编号给操作系统。 操作系统保存当前执行程序的执行现场。 操作系统根据异常号找到对应的处理服务例程。 操作系统执行异常服务例程，会有以下两种结果： 杀死产生了异常的程序。 重新执行异常指令，恢复之前异常程序的执行现场。 ✎✎✎✎系统调用同样的，操作系统也会为系统调用建立一个映射表，key是调用号，value是对应的处理例程。1、CPU的状态CPU有两种状态：用户态和内核态。 用户态：不能执行一些特权级的指令，不能直接访问IO。 内核态：可以执行所有的指令，可以直接访问IO。 当应用程序调用一个系统调用时，会完成从用户态到内核态的转换。 2、系统调用与函数调用的区别 系统调用需要切换堆栈，需要将用户态转换成内核态。 函数调用是在一个堆栈里面进行的。所以系统调用的开销会比较大。 ✎✎✎✎系统调用、异常、中断的开销 在执行时间上的开销超过函数调用。 需要建立中断、异常、系统调用号与对应服务例程映射表。 建立、维护内核堆栈。（这个堆栈与应用程序的堆栈是隔离的） 发生系统调用时，操作系统需要验证传进来的参数是否合法。 系统调用完成后返回一些数据给应用程序时，需要把这些数据从内核堆栈复制到用户堆栈。 更新页面映射权限。（这个后面会讲） TLB。（这个后面会讲）","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"操作系统","slug":"学习笔记/操作系统","permalink":"http://yoursite.com/categories/学习笔记/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/tags/操作系统/"}]},{"title":"01 | 操作系统的启动","slug":"操作系统_01_操作系统的启动","date":"2019-08-20T12:11:57.000Z","updated":"2020-01-07T08:21:41.471Z","comments":true,"path":"2019/08/20/操作系统_01_操作系统的启动/","link":"","permalink":"http://yoursite.com/2019/08/20/操作系统_01_操作系统的启动/","excerpt":"","text":"✎启动过程 加载BIOS。 BIOS进行POST（加电后自检）。 将Bootloader从磁盘的引导扇区（512字节）加载到0×7c00。跳转到0x7C00，将CPU交给Bootloader。 将操作系统的代码和数据从硬盘加载到内存中。 跳转到操作系统的起始地址。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"操作系统","slug":"学习笔记/操作系统","permalink":"http://yoursite.com/categories/学习笔记/操作系统/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/tags/操作系统/"}]},{"title":"06 | 接口、lambda表达式与内部类","slug":"Java核心技术卷1_06_接口、lambda表达式与内部类","date":"2019-08-19T09:23:20.000Z","updated":"2020-01-07T08:21:41.396Z","comments":true,"path":"2019/08/19/Java核心技术卷1_06_接口、lambda表达式与内部类/","link":"","permalink":"http://yoursite.com/2019/08/19/Java核心技术卷1_06_接口、lambda表达式与内部类/","excerpt":"","text":"✎接口1、接口概念接口中的所有方法自动地属于public。因此，在接口中声明方法时，不必提供关键字public。在实现接口时，必须把方法声明为public。接口中不能包含实例域，但却可以包含常量。与接口中的方法都自动地被设置为public一样，接口中的域将被自动设为pubic static final。每个类只能够拥有一个超类，但却可以实现多个接口。在Java SE 8中，允许在接口中增加静态方法。 2、Comparable如果希望使用Arrays类的sort方法对A对象数组进行排序，那么A类就必须实现Compareble接口。 12//用这个对象与oj进行比较。如果对象小于o则返回负值，相等返回0，大于返回正值。java.lang.Comparable&lt;T&gt; public int compareTo(T o); 1234/*** java.lang.Integer*/static int compare(int x , int y) //如果x&lt;y返回一个负整数，相等返回0，大于返正整数。 1234/*** java.lang.Double*/static int compare(double x , double y) //如果x&lt;y返回一个负数，相等返回0，大于返正数。 语言标准规定：对于任意的x和y，实现必须能够保证sgn(x.compareTo(y)) = sgn(y.compareTo(x))。（也就是说，如果y.compare(x)抛出一个异常，那么x.compareTo(y)也应该抛出一个异常。）这里的“sgn”是一个数值的符号：如果n是负值，sgn(n)等于-1；如果n是0，sgn(n) 等于0；如果n是正值，sgn(n) =1。与equals方法一样，在继承的时候可能会出现问题，解决的方式也与equals一样。 可以对一个字符串数组排序，因为String类实现了Comparable&lt;String&gt;，而且String.compareTo方法可以按字典顺序比较字符换。 现在假设要按照长度对字符串进行排序，那么肯定不能让String类用两种不同的方式实现compareTo方法，而且String类也不应由我们来修改。要处理这种情况的时候，Arrays.sort方法还有第二个版本，如下：12345678910111213public class LengthComparator implements Comparator&lt;String&gt; &#123; @Override public int compare(String first, String second) &#123; return first.length() - second.length(); &#125;&#125;public static void main(String [] args)&#123; String[] friends = &#123;\"1\",\"111\",\"11\"&#125;; Arrays.sort(friends,new LengthComparator()); System.out.println( Arrays.toString(friends));&#125; 3、默认方法可以为接口方法提供一个默认实现。必须用defalut修饰符标记这样一个方法。 默认方法的一个重要用法是“接口演化”。假设A实现了B接口后，此时如果再为B接口添加一个非默认方法b的话，将不能保证“源代码兼容”，A类将不能成功编译。若将b声明为默认方法则不会有这个问题。 解决默认方法的冲突如果先在一个接口将一个方法定义为默认方法，然后又在超类或另一个接口中定义了同样的方法，会发生什么情况呢？ 超类优先。如果超类提供了一个具体方法，同名而且有相同参数类型的默认方法会被忽略。 接口冲突。如果一个接口 提供了一个默认方法，另一个接口提供了一个同名并且参数类型相同的方法(不论是否是默认方法)，必须覆盖这个方法来解决冲突。 两个接口都是默认方法的解决方法Demo123456public class SomeOne implements Worker,Employee&#123; @Override public String getName() &#123; return Worker.super.getName(); &#125;&#125; 千万不要让一个默认方法重新定义Object类中的某个方法。由于“类优先”原则，这样的方法绝对无法超越Object的方法（因为所有类都继承Object）。 4、对象克隆如果希望copy是一个新对象，它的初始状态与original相同，但是之后他们各自会有自己不同的状态，这种情况下就可以使用clone方法。 浅复制对象克隆Demo123456789101112public class CloneDemo implements Cloneable&#123; private Date date = new Date(); private boolean flag = false; //getter and setter... public CloneDemo clone() throws CloneNotSupportedException &#123; CloneDemo copy = (CloneDemo)super.clone(); return copy; &#125;&#125; 由于Object的clone()方法是protected的，所以自己创建的对象想要实现克隆方法则必须要重载。Cloneable本身只是一个定义没有任何方法interface，实现它只是为了表明这个类可以被克隆，若不实现，逻辑上没有错误，但是在运行时克隆会抛错。 上述的只是浅复制克隆，值能对一些基本类型的复制，而并不能对对象进行复制。上面的例子中，如果原始对象对Date进行而更改了，克隆对象的Date也会随之改变。 深度复制对象克隆Demo12345678910111213public class CloneDemo implements Cloneable&#123; private Date date = new Date(); private boolean flag = false; //getter and setter... public CloneDemo clone() throws CloneNotSupportedException &#123; CloneDemo copy = (CloneDemo)super.clone(); copy.setDate((Date)this.getDate().clone()); return copy; &#125;&#125; 这个例子当原始对象的Date改变了，克隆对象的Date也不会改变，这称之为深度复制。其实Object的clone只是new一个对象，然后把原始对象的基本类型set进去，而对象引用再没做额外操作的情况下，还是会引用原来的。 也就是说原始的Object的clone方法是浅复制。 所有数组类型都有一个public的clone方法。可以用这个方法建立一个新的数组，包含原数组所有元素的副本。 ✎✎lambda表达式1、Demo12(String first , String second) -&gt;first.length() - second.length(); 如果代码要完成的计算无法放在一个表达式中，就可以像写方法一样，把这些代码放在{}中，如下：123456789(String first , String second) -&gt; &#123; if(first.length() &lt; second.length())&#123; return -1; &#125;else if(first.length() &gt; second.length())&#123; return 1; &#125;else&#123; return 0; &#125;&#125; 即使lambda表达式没有参数，仍然要提供空括号，就像无参数方法一样：123()-&gt;&#123; //do something&#125; 如果可以推导一个lambda表达式的参数类型，则可以忽略其类型。如下：123456LambdaComp&lt;String&gt; comp = (first,second) -&gt; first.length() - second.length();public interface LambdaComp&lt;T&gt; &#123; int compare(T a , T b);&#125; 如果方法只有一个参数，而且这个参数的类型可以推导得出，那么甚至还可以省略小括号：12Comparable&lt;String&gt; comp = first -&gt; first.length(); 无需指定lambda表达式的返回类型。lambda表达式的返回类型总是会由上下文推导得出。其实lambda表达式可以看做是对只有一个抽象方法的interface的实现。如果设计你自己的接口，其中只有一个抽象方法，可以用@FunctionalInterface注解来标记这个接口。表明这个接口是一个函数式接口。当无意中增加了另一个非抽象方法时会编译错误。在Java中，lambda表达式就是闭包。 2、函数式接口对于只有一个抽象方法的接口，需要这种接口的对象时，就可以提供一个lambda表达式。这种接口称为函数式接口。 需要注意的是，一定是“一个抽象方法”。接口完全有可能重新声明Object类的方法，如toString或clone，这些声明可能会让方法不再是抽象的。而且，在JavaSE8中，接口可以声明非抽象方法。 3、方法引用 12LambdaComp&lt;String&gt; comp = System.out::println;comp.test(\"aa\"); //输出aa 相当于1LambdaComp&lt;String&gt; comp = x-&gt; System.out.println(x); 方法引用主要有3种情况： Object::instanceMethod Class::staticMethod Class::instanceMethod 前两种情况中，方法引用等价于提供方法参数的lambda表达式。System.out::println等价于x-&gt;System.out.println(x)。Math::pow等价于(x,y)-&gt;Math.pow(x,y)。第三种情况，第一个参数会成为方法的目标。String::compareToIgnoreCase等同于(x,y)-&gt;x.compareToIngnoreCase(y)。 可以在方法引用中使用this或者super参数。 当一个Lambda表达式调用了一个已存在的方法,就可以用方法引用。 4、构造器引用构造器引用与方法引用很类似，只不过方法名为new。例如，Person::new是Person构造器的一个引用。 可以用数组类型建立构造器引用。例如。int[]::new是一个构造器引用。它有一个参数：即数组的长度，等价于x-&gt;new int[x]。 5、变量作用域 不合法的Demo12345for(int i = 0;i&lt;10;i++)&#123; ActionListener listener = event -&gt;&#123; System.out.println(i); &#125;;&#125; 但是这样又是合法的：123456for(int i = 0;i&lt;10;i++)&#123; int finalI = i; ActionListener listener = event -&gt;&#123; System.out.println(finalI); &#125;;&#125; 6、Comparator接口的静态方法Comparator接口包含很多方便的静态方法来创建比较器。 例如，假设有一个Person对象数组，可以如下（提取一个键）按名字对这些对象排序。1Arrays.sort(person,Comparator.comparing(Person::getName)); 可以把比较器与thenComparing方法串起来。1Arrays.sort(person ,Comparator.comparing(Person::getLastName).thenComparing(Person::getFirstName)); 也可以为键指定一个比较器，按照名字长度倒序排序。1Arrays.sort(employees, comparing(Employee::geteFlag,(s,t)-&gt;t-s)); ✎✎✎内部类 内部类方法可以访问该类定义所在的作用域的数据，包括私有数据。 内部类可以对同一个包中的其他类隐藏起来。 当想要定义一个回调函数且不想编写大量代码时，使用匿名内部类比较便捷。 1、使用内部类访问对象状态 内部类既可以访问自身的数据域，也可以访问创建它的外围类对象的数据域。 内部类的对象总有一个隐式引用，它指向了创建它的外部类对象。这个引用在内部类的定义是不可见的。 外围类的引用要在构造器中设置。编译器修改了所有的内部类的构造器，添加一个外围类引用的参数。 只有内部类可以是私有类（private），而常规类只可以具有包可见性(default)，或公有可见性(public)。 2、内部类的特殊语法规则 外部类引用：OuterClass.this 创建内部类：outerObject.new InnerClass() 在外围类的作用域之外，可以这样引用内部类：OuterClass.InnerClass 非静态内部类不能有静态方法也不能有静态变量。 3、内部类是否有用、必要和安全编译器会将内部类翻译成用$(美元符号)分隔外部类名与内部类名的常规类文件，而虚拟机则对此一无所知。假设现在将Outer定义为常规类，将Inner定义为Outer的内部类，那么Inner在创建的时候，Outer的对象会传给Inner，但是即使是这样，Inner也访问不了Outer私有域，那么内部类是如何管理这些额外的访问特权呢？ 用反射的方法去查看Outer类会发现12345678class Outer&#123; private int interval; private boolean beep; public Outer(int , boolean); static boolean access$0(Outer); public void start();&#125; access$0将返回beep。（方法名可能稍有不同，如access$000，这取决于你的编译器。） 4、局部内部类 Demo123456789101112131415public class Outer &#123; public void start()&#123; class Inner implements ActionListener&#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.println(\"hello world\"); &#125; &#125; ActionListener listener = new Inner(); Timer t = new Timer(1,listener); t.start(); &#125;&#125; 局部内部类不能用public或private访问说明符进行声明。 局部类有一个优势，除了start方法之外，没有任何类知道Inner方法的存在。 5、由外部方法访问变量与其他内部类相比，局部内部类还有一个优点。它们不仅能够访问包含它们的外部类，还可以访问局部变量。不过那些局部变量不可以被改变。（Java 8之前这些局部变量必须声明为final）。 Demo1234567891011121314151617public class Outer &#123; public void start(int interval , boolean beep)&#123; class Inner implements ActionListener&#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.println(\"hello world\"); if(beep)&#123; System.out.println(\"beep\"); &#125; &#125; &#125; //beep = false; //如果加上这句编译会错误 ActionListener listener = new Inner(); Timer t = new Timer(interval,listener); t.start(); &#125;&#125; 在创建Inner类时有保存interval与beep两个参数的局部副本。 6、匿名内部类1234567891011121314public void start(int interval , boolean beep)&#123; ActionListener listener = new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.println(\"hello world\"); if(beep)&#123; //do nothing &#125; &#125; &#125;; Timer t = new Timer(interval,listener); t.start();&#125; 如果构造参数的括号后面跟一个大括号，正在定义的就是匿名内部类。 7、双括号初始化1invite(new ArrayList&lt;String&gt;()&#123;&#123;add(\"Harry\");add(\"Tony\");&#125;&#125;); 8、静态内部类只有内部类可以声明为static。在内部类不需要访问外围类对象的时候，应该使用静态内部类。与常规内部类不同，静态内部类可以有静态域和方法。声明在接口中的内部类自动成为static和public类。静态内部类可以直接new。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java核心技术卷1","slug":"学习笔记/Java/Java核心技术卷1","permalink":"http://yoursite.com/categories/学习笔记/Java/Java核心技术卷1/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"字符串查找算法","slug":"字符串查找算法","date":"2019-08-14T12:13:45.000Z","updated":"2020-01-07T08:21:41.470Z","comments":true,"path":"2019/08/14/字符串查找算法/","link":"","permalink":"http://yoursite.com/2019/08/14/字符串查找算法/","excerpt":"","text":"✎BF算法1、定义Brute-Force算法，简称为BF算法，常用于在一个主串S内查找一个子串T的出现位置。1对于给定的主串S与子串P，主串S的长度为N，子串T的长度为M。 它的核心思想与操作是： 首先，将S[1]和T[1]进行比较。 若相等，则再比较S[2]和T[2]，一直到T[M]为止。 若S[1]和T[1]不等，则T向右移动一个字符的位置，再依次进行比较。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"博客与公众号","slug":"学习笔记/博客与公众号","permalink":"http://yoursite.com/categories/学习笔记/博客与公众号/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"}]},{"title":"05 | 大数据之Kafka_05_Kafka高级Api实战","slug":"大数据之Kafka_05_Kafka高级Api实战","date":"2019-08-09T06:41:04.000Z","updated":"2020-01-07T08:21:41.459Z","comments":true,"path":"2019/08/09/大数据之Kafka_05_Kafka高级Api实战/","link":"","permalink":"http://yoursite.com/2019/08/09/大数据之Kafka_05_Kafka高级Api实战/","excerpt":"","text":"✎生产者Api使用1、pom文件123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;0.11.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka_2.12&lt;/artifactId&gt; &lt;version&gt;0.11.0.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2、生产者Demo1234567891011121314151617181920212223242526public static void main(String[] args) &#123; Properties props = new Properties(); // Kafka服务端的主机名和端口号 props.put(\"bootstrap.servers\", \"hadoop103:9092\"); // 等待所有副本节点的应答 props.put(\"acks\", \"all\"); // 消息发送最大尝试次数 props.put(\"retries\", 0); // 一批消息处理大小 props.put(\"batch.size\", 16384); // 请求延时 props.put(\"linger.ms\", 1); //达到linger.ms的时间或者达到batch.size就会提交。 // 发送缓存区内存大小 props.put(\"buffer.memory\", 33554432); // key序列化 props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // value序列化 props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); for (int i = 0; i &lt; 50; i++) &#123; producer.send(new ProducerRecord&lt;String, String&gt;(\"first\", Integer.toString(i), \"hello world-\" + i)); &#125; producer.close();&#125; ✎带回调函数的生产者12345678910producer.send(new ProducerRecord&lt;String, String&gt;(\"first\", \"hello\" + i), new Callback() &#123; @Override public void onCompletion(RecordMetadata metadata, Exception exception) &#123; if (metadata != null) &#123; System.err.println(metadata.partition() + \"---\" + metadata.offset()); &#125; &#125;&#125;); ✎自定义分区的生产者12345678910111213141516public class CustomPartitioner implements Partitioner &#123; @Override public void configure(Map&lt;String, ?&gt; configs) &#123; &#125; @Override public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123; // 控制分区 return 0; &#125; @Override public void close() &#123; &#125;&#125; 1props.put(\"partitioner.class\", \"com.atguigu.kafka.CustomPartitioner\");","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"大数据之Kafka","slug":"学习笔记/Kafka/大数据之Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/大数据之Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"缓存与数据库的双写一致性方案","slug":"缓存与数据库的双写一致性方案","date":"2019-08-06T07:05:53.000Z","updated":"2020-01-07T08:21:41.524Z","comments":true,"path":"2019/08/06/缓存与数据库的双写一致性方案/","link":"","permalink":"http://yoursite.com/2019/08/06/缓存与数据库的双写一致性方案/","excerpt":"","text":"✎读/写操作的逻辑读操作基本上都是这样的逻辑：先读缓存，读不到就去DB读，然后将读到的值写到缓存。 写操作根据业务场景不同可以有以下几个逻辑： 先更新缓存，再更新数据库。 先更新数据库，再更新缓存。 先删除缓存，再更新数据库。 先更新数据库，再删除缓存。 总的来说就是更新/删除缓存与更新数据库先后顺序的排列组合。更新缓存与删除缓存两者其实是很相似的，更新缓存可以理解为删除缓存后立刻去读数据库（这一步是原子操作）。从加载角度来说，删除缓存就是懒加载，更新缓存就是立刻加载。 ✎✎缓存设置过期时间从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。但是某些业务场景如果需要缓存的及时更新的话，这种策略可能不能满足场景。因为在缓存过期的这段时间内，业务逻辑读取的缓存都是脏数据。 ✎✎✎先更新缓存，在更新数据库✎✎✎✎先更新数据库，再更新缓存从以下两个角度分析其弊端： 线程安全角度同时有请求A和请求B进行更新操作，那么会出现： 线程A更新了数据库。 线程B更新了数据库。 线程B更新了缓存。 线程A更新了缓存。 会导致缓存与数据库的数据库不一致。出现脏数据。这种访问顺序有可能是网络的原因或者是计算机线程调度的原因导致的，可以用如下方法去优化这个问题： 把“更新数据库+更新缓存”放到队列中执行，通过串行来解决并行的问题，保证原子性。但是这个恐怕会非常影响吞吐量（因为每次只能有一个线程在更新数据库与更新缓存）。可以再优化一下，将每一次操作的key进行路由，扔进不同的队列。但这仍然还是会有数据倾斜的问题。 如果说数据库每次更新有一个唯一的自增的update version，（如数据记录的update time等），可以把更新缓存的操作直接push进队列。队列另一端的消费者只对update version比上一个update version大的数据更新进缓存。 业务角度如果业务场景中写场景比较多，而读场景比较少，缓存会被频繁的更新，导致浪费性能。（如果更新要花费的代价很大，比如要连表查询之类的，就更浪费性能了）这种是由于业务场景决定的，是不可能解决。所以对于大多数场景这种策略是不推荐的。 需要注意的是，我们上面只讨论了写操作之间的线程安全性，还没讨论写/读操作之间的线程安全性。接下来会继续讨论。 ✎✎✎✎✎先删除缓存，再更新数据库同时有一个请求A进行更新操作，另一个请求B进行查询操作，会出现以下问题：1、读写不分离 请求A进行写操作，删除缓存。 请求B查询发现缓存不存在。 请求B去数据库查询得到旧值。 请求B将旧值写入缓存。 请求A将新值写入数据库。 会导致缓存与数据库的数据库不一致。出现脏数据。 可采用延时双删解决上述问题： 先淘汰缓存。 再写数据库（这两步和原来一样）。 休眠N秒，再次淘汰缓存。（休眠时间=读数据业务逻辑的耗时+几百ms即可。） 2、读写分离 请求A进行写操作，删除缓存。 请求A将数据写入数据库。 请求B查询缓存发现，缓存没有值。 请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值。 请求B将旧值写入缓存。 数据库完成主从同步，从库变为新值。 会导致缓存与数据库的数据库不一致。出现脏数据。 同样可采用延时双删解决上述问题，只是从上述可知，休眠时间应该=读数据业务逻辑的耗时+主从同步耗时+几百ms。 3、总结虽然可以用延时双删的策略解决大部分问题，但是还是存在以下弊端： 休眠时间内可能有读业务把最新数据给缓存进去了，这种情况第二次删除将会是无意义的。 这种情况可以忽略。 休眠时间非常难保证是完全正确的，万一有某个读业务花费大量时间，那么仍会有脏数据的风险。 这种情况很难避免。 第二次删除的时候，如果是同步休眠那么会造成吞吐量降低。 解决办法是异步去作第二次删除。 若第二次删除失败，仍旧会造成脏数据。 这种情况可以用重试机制解决。 4、用队列解决问题先找准问题的本质是什么，其实就是数据库更新与数据库读这两部由于并发导致执行顺序会不符合预期。那么可以将这两步放进一个队列去串行执行。所以步骤如下： 进行写操作时，删除缓存并把更新数据库的操作发送至队列。 进行读操作时，若缓存为空，则向队列发送读取数据库数据至缓存的命令，并定时监听缓存是否更新，可做监听超出一定时间后直接读数据库的处理。 发送更新缓存的命令时，若前面一条命令也是更新缓存，那么可以不必发送。 还可以增加多一些队列，对操作命令作路由。根据操作的key发送到某条队列。 弊端还是会有，如果某条队列，更新数据库的命令积压过多，那么后续更新缓存的命令可能会超时。 ✎✎✎✎✎✎✎先更新数据库，再删缓存这种策略就是我们常说的Cache-Aside pattern： 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从cache中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 同时有一个请求A进行更新操作，另一个请求B进行查询操作，会出现以下问题： 缓存刚好失效。 请求A查询数据库，得一个旧值。 请求B将新值写入数据库。 请求B删除缓存。 请求A将查到的旧值写入缓存。 从而导致脏数据。但是一般来说上述情况不会出现，因为写入数据总是会比查询数据慢的，所以请求A查询数据库的用时一般不会比请求B写入数据库的用时少。但不能完全保证。 我们也可以用上述说到的异步延时双删去解决这个问题，同样的，我们也不能解决缓存删除失败的问题。 ✎✎✎✎✎✎✎✎重试机制解决删除失败问题1、方案一该方案有一个缺点，对业务线代码造成大量的侵入，所以可以优化为方案二。 2、方案二上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"博客与公众号","slug":"学习笔记/博客与公众号","permalink":"http://yoursite.com/categories/学习笔记/博客与公众号/"}],"tags":[{"name":"缓存架构","slug":"缓存架构","permalink":"http://yoursite.com/tags/缓存架构/"}]},{"title":"04 | Kafka工作流程分析","slug":"大数据之Kafka_04_Kafka工作流程分析","date":"2019-08-05T02:58:46.000Z","updated":"2020-01-07T08:21:41.454Z","comments":true,"path":"2019/08/05/大数据之Kafka_04_Kafka工作流程分析/","link":"","permalink":"http://yoursite.com/2019/08/05/大数据之Kafka_04_Kafka工作流程分析/","excerpt":"","text":"✎生产过程分析1、写入方式producer采用push模式将消息发布到broker，每条消息都被append到patition中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障kafka吞吐率）。 2、分区要理解topic本质上就是一个文件目录，而topic又由分区组成。分区也是文件目录，文件目录名会类似topic-0、topic-1这样的命名。 每个Partition中的消息都是有序的，分区内的每一个消息都被赋予了一个唯一的offset值。消息可以重复被消费，经常所说的“offset消费到哪里了”是针对消费者而不是生产者。 分区的原因 方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了。 可以提高并发，因为可以以Partition为单位读写。 分区的原则（使用默认分区器） 指定了patition，则直接使用。 未指定patition但指定key，通过对key的value进行hash出一个patition。 patition和key都未指定，使用轮询选出一个patition。 3、副本同一个partition可能会有多个replication（对应server.properties配置中的default.replication.factor=N）。没有replication的情况下，一旦broker 宕机，其上所有 patition 的数据都不可被消费，同时producer也不能再将数据存于其上的patition。引入replication之后，同一个partition可能会有多个replication，而这时需要在这些replication之间选出一个leader，producer和consumer只与这个leader交互，其它replication作为follower从leader 中复制数据。 4、写入流程ack为on可以保证生产者不会丢数据。ack为on时的写入流程如下： ✎✎Broker保存消息1、存储方式消息实际上是保存在分区文件夹下的.log文件。 2、存储策略无论消息是否被消费，kafka都会保留所有消息。有两种策略可以删除旧数据： 基于时间：log.retention.hours=168 基于大小：log.retention.bytes=1073741824 3、zk存储结构 ✎✎✎Kafka消费过程分析1、消费者组每个分区在同一时间只能由group中的一个消费者读取，但是多个group可以同时消费这个partition。如果一个消费者失败了，那么其他的group成员会自动负载均衡读取之前失败的消费者读取的分区。 2、消费者组Demo 指定groupId。修改/config/consumer.properties配置文件中的group.id属性。 12vi consumer.propertiesgroup.id=atguigu 启动消费者 1bin/kafka-console-consumer.sh --zookeeper hadoop102:2181 --topic first --consumer.config config/consumer.properties","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"大数据之Kafka","slug":"学习笔记/Kafka/大数据之Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/大数据之Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"03 | Kafka命令行操作","slug":"大数据之Kafka_03_Kafka命令行操作","date":"2019-08-01T16:51:03.000Z","updated":"2020-01-07T08:21:41.454Z","comments":true,"path":"2019/08/02/大数据之Kafka_03_Kafka命令行操作/","link":"","permalink":"http://yoursite.com/2019/08/02/大数据之Kafka_03_Kafka命令行操作/","excerpt":"","text":"1、查看当前服务器中的所有topic1bin/kafka-topics.sh --zookeeper hadoop102:2181 --list 2、创建 topic1bin/kafka-topics.sh --zookeeper hadoop102:2181 --create --replication-factor 2 --partitions 2 --topic first 选项说明： topic。定义topic名。 replication-factor。定义副本数（副本数不能大于broker数）。 partitions。定义分区数。 问题：为什么跟topic有关的操作指定的是zk而不是kafka broker的IP:PORT?但日常在用JAVA API 操作TOPIC的时候，是不需要连接zk的。broker数量与zk的数量有关系吗？ 无。 logs文件夹不仅仅存日志，还存topic的分区。上面的命令会在102的logs/目录下新建first-0和first-1的分区文件目录，会在103上新建first-0副本，在104上新建first-1副本。（因为有2个副本） 问题：创建副本的规律是什么？为什么不是103创建first-1副本、102创建first-0副本？两个副本可以都放到102或者103中吗？ 3、删除topic1bin/kafka-topics.sh--zookeeper hadoopl02:2181 --delete --topic first 需要server.properties中设置delete.topic.enable=true否则只是标记删除或者直接重启。 4、发送消息123bin/kafka-console-producer.sh --broker-list hadoop102:9092 --topic first&gt;hello world&gt;atguigu atguigu 如果往不存在的主题发送数据，那么这个主题会被创建。 5、消费消息1bin/kafka-console-consumer.sh --zookeeper hadoop102:2181 --from-beginning --topic first from-beginning会把first主题中以往所有的数据都读取出来。 新版本zk直接用--bootstrap-server去连kafka实例。新版本的kafka会把offset维护在本地（consumer_offsets这个topic）而不是zk。consumer在消费时如果没指定组id，则随机分配一个组Id。 6、查看某个Topic的详情1bin/kafka-topics.sh --zookeeper hadoop102:2181 --describe --topic first","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"大数据之Kafka","slug":"学习笔记/Kafka/大数据之Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/大数据之Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"02 | Kafka集群部署","slug":"大数据之Kafka_02_Kafka集群部署","date":"2019-08-01T15:35:15.000Z","updated":"2020-01-07T08:21:41.453Z","comments":true,"path":"2019/08/01/大数据之Kafka_02_Kafka集群部署/","link":"","permalink":"http://yoursite.com/2019/08/01/大数据之Kafka_02_Kafka集群部署/","excerpt":"","text":"1、解压安装包1tar -zxvf kafka_2.11-0.11.0.0.tgz -C /opt/module/ 2、修改解压后的文件名称1mv kafka_2.11-0.11.0.0/ kafka 3、在/opt/module/kafka 目录下创建 logs 文件夹1mkdir logs 4、修改配置文件12cd config/vi server.properties 输入以下内容：1234567891011121314151617181920212223242526272829303132333435363738#broker的全局唯一编号，不能重复broker.id=0#删除topic功能使能delete.topic.enable=true#处理网络请求的线程数量num.network.threads=3#用来处理磁盘IO的现成数量num.io.threads=8#发送套接字的缓冲区大小socket.send.buffer.bytes=102400#接收套接字的缓冲区大小socket.receive.buffer.bytes=102400#请求套接字的缓冲区大小socket.request.max.bytes=104857600#kafka运行日志存放的路径log.dirs=/opt/module/kafka/logs#topic在当前 broker上的分区个数num.partitions=1#用来恢复和清理 data下数据的线程数量num.recovery.threads.per.data.dir=1#已关闭segment文件保留的最长时间，超时将被删除，单位是小时，即是7天。log.retention.hours=168#segment文件超过这个大小就会被关闭，等待删除（1个G）log.segment.bytes=1073741824#配置连接Zookeeper集群地址zookeeper.connect=hadoop102:2181 , hadoop103:2181 , hadoop104:2181 黑科技：可以用sublime text直接连上服务器的文件修改。（安装sftp插件）问题：kafka配置文件中没有指定kafka的集群配置，只指定了zk的集群配置。这其中是怎么实现kafka集群的？ 5、配置环境变量（这步其实可以不用配置，只是方便而已，但是可以了解一下配置环境变量的步骤）1sudo vi /etc/profile 1234#KAFKA_HOME export KAFKA_HOME=/opt/module/kafka export PATH=$PATH:$KAFKA_HOME/bin source /etc/profile 6、同步1xsync kafka/ 7、分别在各台服务器启动（启动之前需要先启动zk）1bin/kafka-server-start.sh config/server.properties 8、关闭1bin/kafka-server-stop.sh stop","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"大数据之Kafka","slug":"学习笔记/Kafka/大数据之Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/大数据之Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"01 | Kafka概述","slug":"大数据之Kafka_01_Kafka概述","date":"2019-08-01T07:36:05.000Z","updated":"2020-01-07T08:21:41.451Z","comments":true,"path":"2019/08/01/大数据之Kafka_01_Kafka概述/","link":"","permalink":"http://yoursite.com/2019/08/01/大数据之Kafka_01_Kafka概述/","excerpt":"","text":"✎消息模式 点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）点对点模型通常是一个基于拉取或者轮询的消息传送模型，这种模型从队列中请求信息，而不是将消息推送到客户端。这个模型的特点是发送到队列的消息被一个且只有一个接收者接收处理，即使有多个消息监听者也是如此。 发布/订阅模式（一对多，数据生产后，推送给所有订阅者）发布订阅模型则是一个基于推送的消息传送模型。发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，而持久订阅者则监听主题的所有消息，即使当前订阅者不可用，处于离线状态。 Kafka是基于点对点模式实现的，同一时刻，同一个组只有一个消费者可以消费到同一分区的消息。但是消息被消费后不会被删除。 一个topic可以分为多个分区。 一个组下有多个消费者。 ✎✎Kafka架构 Broker相当于一个kafka实例。 Producer不与zk打交道。 Follower只能作备份，不能作读写。可以在leader宕机的时候升级为leader。 问题：LF选举不是基于zk之间的吗？zk下的节点也可以进行选举？","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Kafka","slug":"学习笔记/Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/"},{"name":"大数据之Kafka","slug":"学习笔记/Kafka/大数据之Kafka","permalink":"http://yoursite.com/categories/学习笔记/Kafka/大数据之Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"04 | Zookeeper实战","slug":"大数据之Zookeeper_04_Zookeeper实战","date":"2019-07-15T12:02:50.000Z","updated":"2020-01-07T08:21:41.470Z","comments":true,"path":"2019/07/15/大数据之Zookeeper_04_Zookeeper实战/","link":"","permalink":"http://yoursite.com/2019/07/15/大数据之Zookeeper_04_Zookeeper实战/","excerpt":"","text":"✎分布式安装部署1.集群规划A、B和C三个节点上部署Zookeeper。 2.解压安装。 在A的服务器解压安装zk。 同步zk到B、C。1xsync [ZK_PATH]/ xsync是怎么同步A到B和C上的，在其他地方是否有相关设置？ 3.配置服务器编号。 创建目录[dataDir_path]。 在[dataDir_path]目录下创建一个myid的文件。 编辑myid文件，在文件中添加与server对应的唯一编号[SERVER_ID]。 拷贝配置好的zookeeper到其他机器上。1xsync myid 并分别在B、C上修改myid文件中内容为自己的[SERVER_ID]。 4.配置 zoo.cfg文件 修改配置文件为zoo.cfg。 修改数据存储路径配置dataDir为[dataDir_path]。 增加如下配置。 123server.[A_ID]=A:2888:3888server.[B_ID]=B:2888:3888server.[C_ID]=C:2888:3888 同步zoo.cfg配置文件。 1xsync zoo.cfg 这里的A、B、C是怎么映射到IP的？ ✎✎配置参数解读server.A=B:C:D A是一个数字，表示这个是第几号服务器。集群模式下在dataDir目录下配置一个文件myid，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。 B是这个服务器的ip地址。 C是这个服务器与集群中的Leader服务器交换信息的端口。 D是用来执行重新选举时服务器相互通信的端口。 ✎✎✎集群操作 分别启动Zookeeper。 分别查看状态。可从结果中知道这个节点是follower还是leader。 ✎✎✎✎客户端命令行操作1、显示所有操作命令1help 2、查看znode中所包含的内容 查看当前znode 1ls / 查看sanguo znode 1ls /sanguo 3、查看当前节点详细数据1ls2 / 4、创建普通节点1create /sanguo &quot;jinlian&quot; 也可创建多级目录：1create /sanguo/shuguo &quot;liubei&quot; 5、获得节点的值1get /sanguo/shuguo 6、创建短暂节点1create -e /sanguo/wuguo &quot;zouyu&quot; 7、创建带序号的节点1create -s /sanguo/weiguo &quot;caocao&quot; 8、修改节点数据值1set /sanguo/shuguo &quot;diaocan&quot; 9、节点的值变化监听1get /sanguo watch(只监听一次) 10、节点的子节点变化监听（路径变化）1ls /sanguo watch(只监听一次) 11、删除节点1delete /sanguo/banzhang 12、递归删除节点1rmr /sanguo 13、查看节点状态1stat /sanguo ✎✎✎✎API1、创建zk客户端123456789101112131415public class TestZookeeper&#123; private String connectString=\"hadoop102:2181,hadoop103:2181,hadoop104:2181\"; private int sessionTimeout=2000; private Zookeeper zkClient; @Test public void init()throws IOException&#123; zkClient=new Zookeeper(connectstring,sessionTimeout,new Watcher()&#123; @Override public void process(WatchedEvent event)&#123; //do something &#125; &#125;); &#125;&#125; 当有数据变化时，process会被调用。 2、创建一个节点12345678910@Test public void createNode()throws KeeperException，InterruptedException&#123; String path =zkClient.create（ \"/atguiku\", \"dahaigezuishuai\".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT ); System.out.print1n(path);&#125; 3、获取子节点1List&lt;String&gt; children = zkClient. getchildren(\"/\", true); true表示注册监听。 4、判断节点是否存在1Stat stat=zkclient. exists(\"/atguigu\", false); 5、监听服务器节点动态上下线流程如下： 服务端启动时去注册信息（创建都是临时节点）。 客户端启动就去getChildren，获取到当前在线服务器列表，并且注册监听。 服务器节点下线。 服务器节点上下线事件通知。 process()重新再去获取服务器列表，并注册监听。 重点在于服务器向zk注册信息时，创建的节点是临时的且带编号的。 问题：如果多台机创建的path相同（节点相同），那么如果节点是带编号的，就不会重合，但如果不带编号的，又会是什么状况呢？","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Zookeeper","slug":"学习笔记/Zookeeper","permalink":"http://yoursite.com/categories/学习笔记/Zookeeper/"},{"name":"大数据之Zookeeper","slug":"学习笔记/Zookeeper/大数据之Zookeeper","permalink":"http://yoursite.com/categories/学习笔记/Zookeeper/大数据之Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://yoursite.com/tags/Zookeeper/"}]},{"title":"03 | Zookeeper内部原理","slug":"大数据之Zookeeper_03_Zookeeper内部原理","date":"2019-07-15T10:43:28.000Z","updated":"2020-01-07T08:21:41.466Z","comments":true,"path":"2019/07/15/大数据之Zookeeper_03_Zookeeper内部原理/","link":"","permalink":"http://yoursite.com/2019/07/15/大数据之Zookeeper_03_Zookeeper内部原理/","excerpt":"","text":"✎选举机制 半数机制：集群中半数以上机器存活，集群可用。所以Zookeeper适合安装奇数台服务器。 Zookeeper虽然在配置文件中并没有指定Master和Slave。但是，Zookeeper工作时，如果有一个节点为Leader，其他则为Follower，Leader是通过内部的选举机制临时产生的。 选举（启动时）的过程：一个节点进来时，先投自己，如果没有选出leader，则把票给id最大的server。 ✎✎节点类型1、类型 持久（Persistent）：客户端和服务器端断开连接后，创建的节点不删除。持久分为两种类型： 持久化目录节点：客户端与Zookeeper断开连接后，该节点依旧存在。 持久化顺序编号目录节点：客户端与Zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号。 短暂（Ephemeral）：客户端和服务器端断开连接后，创建的节点自己删除。短暂节点可以用作探知client是否在线。（因为如果客户端没连的话，这个节点就被删除了）短暂节点分为两种类型： 临时目录节点：客户端与Zookeeper断开连接后，该节点被删除。 临时顺序编号目录节点：客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号。 2、顺序标识创建znode时设置顺序标识，znode名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护。在分布式系统中，顺序号可以被用于为所有的事件进行全局排序，这样客户端可以通过顺序号推断事件的顺序。 这个顺序标识可以知道全局中哪个节点先上线。 ✎✎✎Stat结构体 czxid：创建节点的事务zid 每次修改ZooKeeper状态都会收到一个zxid形式的时间戳，也就是ZooKeeper事务ID。 事务ID是ZooKeeper中所有修改总的次序。每个修改都有唯一的zxid，如果zxid1小于zxid2，那么zxid1在zxid2之前发生。 ctime-znode：被创建的毫秒数（从1970年开始）。 mzxid-znode：最后更新的事务zxid。 mtime-znode：最后修改的毫秒数（从1970年开始）。 pZxid-znode：最后更新的子节点zxid。 cversion-znode：子节点变化号，zmode子节点修改次数。 dataversion-znode：数据变化号。 aclVersion-znode：访问控制列表的变化号。 ephemeralOwner：如果是临时节点，这个是znode拥有者的session id。如果不是临时节点则是0。 dataLength：znode的数据长度。 numChildren：znode子节点数量。 ✎✎✎✎监听器原理1、监听过程 首先要有一个main()线程。 在main线程中创建Zookeeper客户端，这时就会创建两个线程，一个负责网络连接通信（connet），一个负责监听（listener）。 通过connect线程将注册的监听事件发送给Zookeeper。 在Zookeeper的注册监听器列表中将注册的监听事件添加到列表中。 Zookeeper监听到有数据或路径变化，就会将这个消息发送给listener线程。 listener线程内部调用了process()方法。(回调方法) ✎✎✎✎✎写数据流程 Client向ZooKeeper的Server1上写数据，发送一个写请求。 如果Server1不是Leader，那么Server1会把接受到的请求进一步转发给Leader，因为每个ZooKeeper的Server里面有一个是Leader。这个Leader会将写请求广播给各个Server，比如Server1和Server2，各个Server写成功后就会通知Leader。 当Leader收到大多数(半数以上)Server数据写成功了，那么就说明数据写成功了。 如果这里三个节点的话，只要有两个节点数据写成功了，那么就认为数据写成功了。写成功之后，Leader会告诉Server1数据写成功了。 Server1会进一步通知Client数据写成功了，这时就认为整个写操作成功。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Zookeeper","slug":"学习笔记/Zookeeper","permalink":"http://yoursite.com/categories/学习笔记/Zookeeper/"},{"name":"大数据之Zookeeper","slug":"学习笔记/Zookeeper/大数据之Zookeeper","permalink":"http://yoursite.com/categories/学习笔记/Zookeeper/大数据之Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://yoursite.com/tags/Zookeeper/"}]},{"title":"02 | Zookeeper安装","slug":"大数据之Zookeeper_02_Zookeeper安装","date":"2019-07-15T09:10:02.000Z","updated":"2020-01-07T08:21:41.466Z","comments":true,"path":"2019/07/15/大数据之Zookeeper_02_Zookeeper安装/","link":"","permalink":"http://yoursite.com/2019/07/15/大数据之Zookeeper_02_Zookeeper安装/","excerpt":"","text":"✎安装1、解压 安装jdk。 拷贝Zookeeper安装包到Linux系统下。 解压到指定目录1tar -zxvf [zookeeper.tar.gz] -C [PATH] 2、配置修改 将[zk解压路径]/conf这个路径下的zoo_sample.cfg修改为zoo.cfg； 1mv zoo_sample.cfg zoo.cfg 打开zoo.cfg文件，修改dataDr路径： 1dataDir=[自定义的zkData路径] 根据dataDir配置在相应的目录上创建相应文件夹。 3、操作Zookeeper 启动Zookeeper 1[ZK_PATH]/bin/zkServer.sh start 查看进程是否启动 1[ZK_PATH]/jps 查看状态 1[ZK_PATH]/bin/zkServer.sh status 可以知道这个server是leader还是follower。 启动客户端 1[ZK_PATH]/bin/zkCli.sh 退出客户端： 1quit 停止Zookeeper 1[ZK_PATH]/bin/zkServer.sh stop 客户端查看根节点 1ls / ✎✎配置参数解读 tickTime=2000每隔一个tickTime就会发送一个心跳，时间单位为毫秒。它用于心跳机制，并且设置session的最小超时时间是2*tickTime。 initLimit=10LF初始通信时限。集群中的Follower与Leader之间初始连接时最长等待时间为initLimit*tickTime。 syncLimit=5LF同步通信时限。假如响应超过syncLimit*tickTime，Leader认为Follwer死掉，从服务器列表中删除Follwer。 dataDir数据文件目录+数据持久化路径。主要用于保存Zookeeper中的数据。 clientPort=2181客户端连接端口监听客户端连接的端口。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Zookeeper","slug":"学习笔记/Zookeeper","permalink":"http://yoursite.com/categories/学习笔记/Zookeeper/"},{"name":"大数据之Zookeeper","slug":"学习笔记/Zookeeper/大数据之Zookeeper","permalink":"http://yoursite.com/categories/学习笔记/Zookeeper/大数据之Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://yoursite.com/tags/Zookeeper/"}]},{"title":"01 | Zookeeper入门","slug":"大数据之Zookeeper_01_Zookeeper入门","date":"2019-07-15T04:56:07.000Z","updated":"2020-01-07T08:21:41.460Z","comments":true,"path":"2019/07/15/大数据之Zookeeper_01_Zookeeper入门/","link":"","permalink":"http://yoursite.com/2019/07/15/大数据之Zookeeper_01_Zookeeper入门/","excerpt":"","text":"✎概述Zookeeper是一个开源的分布式的，为分布式应用提供协调服务的Apache项目。 ✎✎工作机制Zookeeper从设计模式角度来理解：是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper就通知已经在Zookeeper上注册的其他观察者。 联想：Eureka客户端是定时去注册中心获取服务。并把获取到的服务列表缓存起来。而zk在服务器列表有变化时，会发送消息给客户端，客户端就会重新向zk缓存服务列表。也就是说，对服务列表变化非常敏感的场景，zk应该是更好的选择。 ✎✎✎工作机制 一个领导者（Leader），多个跟随者（Follower）组成的集群。 集群中只要有半数以上节点存活，zk集群就能正常服务。 全局数据一致：每个Server保存一份相同的数据副本，Client无论连接到哪个Server，数据都是一致的。 更新请求顺序进行，来自同一个Client的更新请求按其发送顺序依次执行。 数据更新原子性，一次数据更新要么成功，要么失败。 实时性，在一定时间范围内，Client能读到最新数据。 ✎✎✎✎数据结构ZooKeeper数据模型的结构与Unix文件系统很类似，整体上可以看作是一棵树，每个节点称做一个ZNode。每一个ZNode默认能够存储1MB的数据，每个ZNode都可以通过其路径唯一标识。 ✎✎✎✎✎应用场景提供的服务包括：统一命名服务、统一配置管理、统一集群管理、服务器节点动态上下线、软负载均衡等。 1、统一命名服务在分布式环境下，经常需要对应用/服务进行统一命名，便于识别。（类似Eureka Server） 2、统一配置管理 将配置信息写入ZooKeeper上的一个Znode。 各个客户端服务器监听这个Znode。 一旦Znode中的数据被修改，zk将通知各个客户端服务器。 3、服务器节点动态上下线客户端能实时洞察到服务器上下线的变化，过程如下： 服务端启动时去注册信息（创建都是临时节点）。 客户端获取到当前在线服务器列表，并且注册监听。 服务器节点下线，将通知客户端。 4、软负载均衡在Zookeeper中记录每台服务器的访问数，让访问数最少的服务器去处理最新的客户端请求。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Zookeeper","slug":"学习笔记/Zookeeper","permalink":"http://yoursite.com/categories/学习笔记/Zookeeper/"},{"name":"大数据之Zookeeper","slug":"学习笔记/Zookeeper/大数据之Zookeeper","permalink":"http://yoursite.com/categories/学习笔记/Zookeeper/大数据之Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://yoursite.com/tags/Zookeeper/"}]},{"title":"05 | 继承","slug":"Java核心技术卷1_05_继承","date":"2019-07-09T08:13:20.000Z","updated":"2020-01-07T08:21:41.395Z","comments":true,"path":"2019/07/09/Java核心技术卷1_05_继承/","link":"","permalink":"http://yoursite.com/2019/07/09/Java核心技术卷1_05_继承/","excerpt":"","text":"✎子类构造器如果子类的构造器没有显示地调用超类的构造器，则将自动地调用超类默认（没有参数）的构造器。如果超类没有默认的构造器，而且子类又没有显示地调用超类其他的构造器，那么会编译错误。 所以这就是有些类的构造方法中为什么一定要有super的原因 一个对象变量可以指示多种实际类型的现象被称为多态，在运行时能够自动地选择调用哪个方法的现象称为动态绑定。 子类数组的引用可以转换成超类数组的引用，而不需要采用强制类型的转换。 同样的子类对象的引用可以转换成超类对象的引用，而不需要采用强制类型的转换。 总的来说就是：引用一定要“&gt;=”对象。赋值时，左边的引用要“&gt;=”右边的引用，否则需要强转。（有可能强转失败） Employee类（父类）123public class Employee &#123;&#125; Manager类（子类）123public class Manager extends Employee&#123; public void say()&#123;&#125;&#125; 以下代码会导致ArrayStoreException：1234Manager[] managers = new Manager[10];Employee[] staff = managers;staff[0] = new Employee(); //出错在这一步managers[0].say(); ✎✎理解方法调用1、方法调用过程假设要调用x.f(args)，x声明为类C的一个对象。下面是调用过程： 如果是private方法，static方法，final方法或者构造器，那么编译器可以直接知道在哪个类中调用方法（因为这些方法不能重写）。这种调用方式称为静态绑定。其他的都称为动态绑定。如果是动态绑定则继续按下个步骤走。 编译器查看对象的声明类型和方法名。编译器将会列举C类中名为f的方法和其超类中访问属性为public(protected与default不行？)且名为f的方法以及子类中名为f的方法。至此，编译器已经获得所有候选方法。 编译器查看调用方法时提供的参数类型。在候选方法中找到与之参数类型完全匹配的方法。否则将会报错。至此，编译器已经获得了需要调用的方法名以及参数类型。 当采用动态绑定调用方法时。假设x的实际类型是D，它是C类的子类。如果D类定义了f(args)，就直接调用；否则将在C类查找f(args)。 Demo：调用e.getSalary()的详细过程 由于getSalary不是private方法、static方法或final方法，所以将采用动态绑定。虚拟机为Employee和Manager两个类生成方法表（如果Employee有子类，也会为子类生成方法表）。在Employee的方法表中，列出了这个类定义的所有方法： 12345Employee： getName() -&gt; Employee.getName() getSalay() - &gt; Employee.getSalary() getHireDay() -&gt; Employee.getHireDay(); raiseSalary(double) -&gt; Employee. raiseSalary(double) Manager方法表： 123456Manager： getName() -&gt; Employee.getName() getSalay() - &gt; Manager .getSalary() getHireDay() -&gt; Employee.getHireDay(); raiseSalary(double) -&gt; Employee. raiseSalary(double) setBonus(double) -&gt; Manager.setBonus(double) 三个方法是继承Employee的，一个方式是重新定义的，一个方法是新增加的。 方法表略去了Object的方法。 虚拟机搜索定义getSalary签名的类。此时虚拟机已经知道该调用哪个方法。 虚拟机调用方法。 2、覆盖方法时的注意事项 子类方法不能低于超类方法的可见性。 允许子类将覆盖方法的返回类型定义为原返回类型的子类型。如下： ✎✎✎阻止继承 ： final类与方法1、finalfinal修饰的类与方法不能被继承。 将一个类定义为final后，这个类的全部方法都将变为final，但属性并不会变成final。 早期的Java中，有些程序员为了避免动态绑定带来的系统开销而使用final关键字。 2、内联如果一个方法没有被覆盖、被调用很频繁并且很短，编译器就能够对它进行优化，这个过程被称为内联。 1e.g 如果getName()方法没有被覆盖，内联调用e.getName()将被替换为访问e.name域。 如果getName()在另外一个类中被覆盖，编译器无法知道被覆盖的代码将做什么操作，也就不能对它进行内联处理了。 当虚拟机加载了另外一个子类，而这个子类中包含了对内联方法的覆盖，那么优化器将取消对覆盖方法的内联。 在继承链上进行向下的转换会报ClassCastException错误，所以在强转前最好先事先用instanceof判断一下。e.g.123if(C instanceof D)&#123;//假设C是D的子类 ...&#125; 如果C为null，也不会产生异常。 3、equals 重写equals Demo1234567891011121314151617public class Employee &#123; int flag; public boolean equals(Object otherObj)&#123; if(this == otherObj)&#123; return true; &#125; if(otherObj == null)&#123; return false; &#125; if(getClass() != otherObj.getClass())&#123; return false; &#125; Employee other = (Employee)otherObj; return this.flag == other.flag; &#125;&#125; Objects.equals(a,b)：可以避免a为空导致a.equals(b)出错的情况。static boolean equals(Object a ,Object b)：如果a和b都为null，返回true；如果只有其中之一为null，则返回false；否则返回a.equals(b)。（这个方法在实际中还是挺好用的） 在子类定义equals方法时，首先调用超类的equals(前提是超类已经重写了equals方法)。如果检测失败，对象就不可能相等。 子类重写equals Demo1234567891011public class Manager extends Employee&#123; private int mFlag; public boolean equals(Object otherObj)&#123; if(!super.equals(otherObj))&#123; return false; &#125; Manager other = (Manager)otherObj; return mFlag == other.mFlag; &#125;&#125; Java语言规范要求equals方法具有下面的特性： 自反性：对于任何非空引用x，x.equals(x)应该返回true。 对称性。对于任何引用x和y，当且仅当y.equlas(x)返回true，x.equals(y)也应该发挥true。 传递性。对于任何引用x、y和z，如果x.equals(y)返回true，y.equals(z)返回true，x.equals(z)也应该返回true。 一致性。如果x和y引用的对象没有发生变化，反复调用x.equals(y)应该返回同样结果。 对于任意非空引用x，x.equals(null)应该返回false。 在上述的Employee类中，如果用 123if (!(otherObj instanceof Employee)) &#123; return false;&#125; 代替123if(getClass() != otherObj.getClass())&#123; return false;&#125; 这样会违反对称性原则，原因如下：假设e是Employee对象，而m是一个Manager对象，假设两个对象的属性都相同。当调用e.quals(m)时，会返回true。而调用m.equals(e)时，会出现ClassCastException错误，因为在检验过程中Employee无法转换成为Manager。 如果用getClass的方式检测的话，e.quals(m)返回false，m.equals(e)返回false，符合对称性原则，但是又会违反里氏置换原则。所以这是一个矛盾的点。 里氏置换原则：所有引用基类的地方必须能够透明的使用其子类对象。也就是说，只要父类出现的地方子类就能够出现，而且替换为子类不会产生任何错误或异常。但是反过来，子类出现的地方，替换为父类就可能出现问题了。 Java中有一个AbstractSet类的equals方法检测两个集合是否有相同元素。AbstractSet类有两个具体的实现类：TreeSet和HashSet，它们分别使用不同的算法实现查找集合的操作。无论集合采用何种方式实现，都需要拥有对任意两个集合进行比较的功能。集合是一个相当特殊的例子，因为没有一个子类需要重新定义集合是否相等的语义，所以AbstractSet的equals方法应该被声明为final(实际上并没有)。所以有一个隐患就是如果AbstractSet的子类重写了equals方法，则会出现上述的矛盾问题。 所以可以总结出以下两条法则： 如果超类有自己的相等概念且本类也拥有自己的的相等概念（即“上头 ”有自己的相等概念），则对称性需求将强制采用getClass进行检测。 如果只由本类决定是否相等。（即“上头 ”没有自己的相等概念 ），那么就可以使用instanceof，并且将equals方法声明为final。这种情况不会违反任何原则。 对于数组类型的域，可以使用静态的Arrays.equals方法检测相应的数组元素是否相等。static Boolean equals(type[] a ,type[] b)如果两个数组成都相同，并且在对应的位置上数据元素也均相同，将返回true。数组的类型可以是Object、int、long、short、char、byte、boolean、float或double。（也可以是他们相应的包装器类） ✎✎✎✎hashCode方法String类使用下列算法计算散列码: 1234567891011public int hashCode() &#123; int h = hash; //hash默认为0 if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; //value就是String值，用char[]类型存储。 for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125; 为什么是31？ 31*i = (i&lt;&lt;5)-i，jvm可以对这个乘法进行优化，用移位以及减法代替。 31不会太大也不会太小。 可以知道，String的散列值是根据String值算出来的。由于hashCode方法定义在Object类中，因此每个对象都有一个默认的散列码，其值为对象的存储地址。 用以下例子可以验证上面的结论：123456String s = \"OK\";String t = new String(\"OK\");StringBuffer sb = new StringBuffer(s);StringBuffer tb = new StringBuffer(t);System.out.println(s.hashCode() +\" \"+sb.hashCode());//2524 1163157884System.out.println(t.hashCode() +\" \"+tb.hashCode());//2524 1956725890 如果要重新定义equals方法，就必须重新定义hashCode方法，以便用户可以将对象插入到散列表中。 hashCode方法应该返回一个整型数值（可以为负数）。 以下是Employee方法的hashCode方法Demo12345public class Employee &#123; public int hashCode()&#123; return 7 * name.hashCode() + 11 * number.hashCode() + 13 * new Double(salary).hashCode(); &#125;&#125; 不过上面的Demo有一个缺陷，就是name有可能为空，为此可以用以下方法代替: static int hashCode(Object a):如果a为null就返回0，否则就返回a.hashCode()，如下：12345public class Employee &#123; public int hashCode()&#123; return 7 * Objects.hashCode(name ) + 11 * Objects.hashCode (number ) + 13 * Double.hashCode (salary); &#125;&#125; 还有更好的做法，如下:12345public class Employee &#123; public int hashCode()&#123; return Objects.hash(name,salary,number); &#125;&#125; static int hash(Object... objects):返回一个散列码，由提供的所有对象的散列码组合而成。 Equals与hashCode的定义必须一致：如果x.equals(y)返回true，那么x的hashIndex就必须等于y的hashIndex(hashcode也可以不一样)。 如果equals方法返回false，hashcode可以相等，但是这样不利于哈希表的性能。哈希表判断对象是否相同的依据是equals与hashIndex都相同。如果存在数组类型的域，那么可以使用静态的Arrays.hashCode方法计算一个散列码，这个散列码由数组元素的散列码组成。 ✎✎✎✎✎toString方法Object类定义了toString方法，用来打印输出对象所属的类名和散列码。 ✎✎✎✎✎✎泛型数组列表如果已经清楚或能够估计出数组可能存储的元素数量，就可以在填充数组之前调用ensureCapacity方法： 1staff.ensureCapacity(100); ArrayList如果没有一次性扩到想要的最大容量的话，它就会在添加元素的过程中，一点一点的进行扩容，而对数组扩容是要进行数组拷贝的，这就会浪费大量的时间。而ensureCapacity可以一次性扩容到指定的数量。如果指定的容量小于原来数组容量的1.5倍+1，那么扩容的容量将会是原来的1.5倍+1，否则数组容量将被扩容到指定的容量。还可以把初始容量传递给ArrayList构造器：1ArrayList&lt;Employee&gt; staff = new ArrayList&lt;&gt;(100); 一旦确认数组列表的大小不再发生变化，就可以调用trimToSize方法。这个方法将存储区域的大小调整为当前元素数量所需要的存储空间数目。垃圾回收器将回收多余的存储空间。 只有i小于或等于数组列表的大小时，才能够调用list.set(i,x)。以下这段代码是错误的：12List&lt;String&gt; employeeList = new ArrayList&lt;&gt;();employeeList.set(0,\"1\"); 会报错：IndexOutOfBoundsException ✎✎✎✎✎✎✎对象包装器与自动装箱对象包装器类拥有很明显的名字：Integer、Long、Float、Double、Short、Byte、Character、Void和Boolean（前6个类派生于公共的超类Number）。对象包装类是不可变的，即一旦构造了包装器，就不允许更改包装在其中的值。同时，对象包装器类还是final，因此不能定义它们的子类。 自动装箱Demo：1list.add(3); 将自动变换成1list.add(Integer.valueof(3)) 自动拆箱Demo:1int n = list.get(i); 会被翻译器自动翻译成1int n = list.get(i).intValue(); 甚至在算数表达式中也能自动地装箱和拆箱：12Integer n = 3;n++; 编译器将自动插入一条对象拆箱的指令，然后进行自增计算，最后再将结果装箱。 ✎✎✎✎✎✎✎✎直接赋值与new的区别1234String s1 = \"a\";String s2 = \"a\";String s3 = new String(\"a\");String s4 = new String(\"a\"); 上面的值中s1==s2 , s3!=s4 , s1!=s3。原因是: 直接赋值时，编译器会先去常量池（不是堆也不是栈）找是否存在a,没有的话在常量池创建值为a的对象，此时s1再引用这个对象，此时常量池已经存在了值为a的对象，所以s1与s2引用的也是同一个对象。 而用new操作时，会在堆中创建一个新的对象。 注：==比较的是对象的内存地址,与hashcode没有任何一点关系。 ==陷阱当在以下值的范围内，采用直接赋值方式且value相等的包装箱类，使用“==”的情况: Integer。在-128~127范围内返回true。编译器会把值-128~127的Integer类缓存,以后当要赋值在此范围的Integer时，直接去缓存里面找。 Short。在-128~127范围内返回true。类似Integer。 Byte。永远都返回true。类似Integer，并且byte的范围是-128~127，所以肯定会返回true。 Long。在-128~127范围内返回true。类似Integer。 Character。在0~127范围内返回true。编译器会把值0~127的Character类缓存,以后当要赋值在此范围的Character时，直接去缓存里面找。 Boolean。永远返回true。（用字符串形式赋值时，不区分大小写，非”true”的其他值都为”false”）Boolean类里边定义了值为true和false的两个final类。不管Boolean的值是什么都只会引用这两个类。 Float。永远返回false。返回值是直接根据float值new出来的Float对象 Double。永远返回false。类似Float。 如果在一个条件表达式中混合使用Integer和Double类型，Integer就会拆箱，提升为double，再装箱为Double。 如果想编写可以改变一个可以修改数值参数（假设为int类型）的方法，不能用Integer，因为Integer类是不可改变的。可以用IntHolder。 ✎✎✎✎✎✎✎✎✎参数数量可变的方法12public void test(Object...)&#123;&#125; Object..参数类型与Object[]完全一样。调用时像以下这样调用：1test(Object1 , Object2); ✎✎✎✎✎✎✎✎✎✎枚举类1234public enum TestEnum &#123; ONE, TWO&#125; 这个声明定义的类型是一个类，它刚好有2个实例，所以在比较两个枚举类型的值时，永远不需要调用equals，而直接使用“==”就可以了。 可以与单例模式关联起来。 可以在枚举类型中添加一些构造器、方法和属性：1234567891011public enum TestEnum &#123; ONE(1), TWO(2); private Integer value; TestEnum(Integer value)&#123; this.value = value; &#125; public void setValue(Integer value) &#123; this.value = value; &#125;&#125; static Enum valueOf(Class enumClass , String name)返回指定名字、给定类的枚举常量。 String toString()返回枚举常量名。 int ordinal()返回枚举常量在enum声明中的位置，位置从0开始计数。 int compareTo(E other)如果枚举常量出现在other之前，则返回一个负值；如果this==other，则返回0；否则返回正值。枚举常量的出现次序在enum声明中给出。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java核心技术卷1","slug":"学习笔记/Java/Java核心技术卷1","permalink":"http://yoursite.com/categories/学习笔记/Java/Java核心技术卷1/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"04 | 对象与类","slug":"Java核心技术卷1_04_对象与类","date":"2019-07-09T07:01:16.000Z","updated":"2020-01-07T08:21:41.394Z","comments":true,"path":"2019/07/09/Java核心技术卷1_04_对象与类/","link":"","permalink":"http://yoursite.com/2019/07/09/Java核心技术卷1_04_对象与类/","excerpt":"","text":"✎对象与对象变量下面代码里deadLine变量与birthDay变量引用的是同一个变量。12Date deadLine = new Date();Date birthDay = deadLine; ✎✎GregorianCalendar类1234567891011121314151617181920Calendar c = new GregorianCalendar(); //Calendar是抽象类 //1.直接设置年月日时分秒//c.set(2015, Calendar.AUGUST, 2); //2015.08.02 //2.通过块分别设置相应的年月日时分秒//注：可以按这种格式继续设置时分秒，如果省略，则按照本地默认设置c.set(Calendar.YEAR, 2015); //2015年c.set(Calendar.MONTH, 1); //2月，0为1月c.set(Calendar.DAY_OF_MONTH, 2); //Calendar.DATE == Calendar.DAY_OF_MONTH Date d = c.getTime();System.out.println(d); //Mon Feb 02 21:15:13 CST 2015 //获取相应的年月日时分秒System.out.println(c.get(Calendar.YEAR)); //2015 //测试日期计算c.add(Calendar.YEAR, 10); //增加10年,减的话把10变成负的即可System.out.println(c.getTime()); //Sun Feb 02 21:15:13 CST 2025 不要编写如下的返回引用对象的访问器方法，因为容易被外部修改。1234567class Enployee&#123; private Date hireDay; public Date getHireDay()&#123; return hireDay; &#125;&#125; 如果要返回一个对象的引用，应该首先对它进行克隆。如下：1234567class Enployee&#123; private Date hireDay = new Date(); public Date getHireDay()&#123; return hireDay==null?null:(Date)hireDay.clone(); &#125;&#125; Date实现了clone方法。 ✎✎✎基于类的访问权限一般来说，如果把属性设置为private后，外部在调用的时候是不可以直接通过“点”的方式调用的，但是以下两种例外。1234567public class Employee &#123; private String name; public boolean equals(Employee other)&#123; return name.equals(other.name); &#125;&#125; 因为other本来就属于Employee，所以可以在这个类中可以直接调用。 123456789101112131415public class Demo &#123; public static void main(String [] args) &#123; Employee employee = new Employee(); System.out.println(employee.name); &#125; static class Employee &#123; private String name; public boolean equals(Employee other)&#123; return name.equals(other.name); &#125; &#125;&#125; 因为Employee属于Demo的内部类，所以在Demo的方法里可以访问Employee的私有属性。 ✎✎✎✎final 实例域对象的final属性在构建对象时必须被初始化。 ✎✎✎✎✎静态常量System.out是一个静态常量，如下: 123public class System&#123; public static final PrintStream out = . . . ;&#125; System类里面有有一个setOut方法可以将System.out设置为不同的流，因为setOut是一个本地方法（native），而不是用Java语言实现的。本地方法可以绕过Java语言的存储控制机制，从而对final属性进行修改。自己编写程序时，不应该这样处理。 ✎✎✎✎✎✎静态方法当对象里有静态方式时，建议使用类名，而不是通过构建的对象来调用静态方法。 可以通过调用方法对属性进行初始化（这种方式有点意思 ），如下:12345678910public class Employee &#123; private static int nextId; private int id = assignId(); private static int assignId()&#123; int r = nextId; nextId++; return r; &#125;&#125; 这样写就让assignId相当于一个初始化方法。 ✎✎✎✎✎✎✎调用另一个构造器如果构造器的第一个语句如this(…)，这个构造器将调用同一个类的另一个构造器,如下123456789public class Employee &#123; private int id ; public Employee()&#123; this(1); &#125; public Employee(int id)&#123; this.id = id; &#125;&#125; ✎✎✎✎✎✎✎✎对象析构与finalize方法可以为任何一个类添加finalize方法。finalize方法将在垃圾回收器清除对象之前调用。在实际应用中，不要依赖于使用这个方法回收任何短缺的资源，因为很难知道这个方法什么时候才能够调用。 ✎✎✎✎✎✎✎✎✎类的导入只能使用星号*导入一个包，而不能使用Import java.*或者Import java.*.*导入以java为前缀的所有包。 ✎✎✎✎✎✎✎✎✎✎包作用域 private : 只能被定义它们的类访问。 default : 只能被同一包中的类访问。 protected : 具有default的权限，并且可以被不同包中所继承的子类访问。 public ： 可以被任意类访问。 ✎✎✎✎✎✎✎✎✎✎✎文档注释JDK包含一个很有用的工具，叫做javadoc，它可以由源文件生成一个HTML文档。 javadoc从下面几个特性中抽取信息： 包 公共类与接口 公有的和受保护的构造器及方法 公有的和受保护的域 ✎✎✎✎✎✎✎✎✎✎✎✎通用注释 @author:用在类文档的注释中，表示后作者姓名。可以用多个@author标记。 @version:对当前版本的描述。 @since:始于什么版本。 @deprecated:对类、方法或变量不再使用的标识。 @see:链接到某个方法或某个超链接。 12//将链接到Test类的test(double)方法。@see com.huangjunlong.Test#test(double) @link:同@see。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java核心技术卷1","slug":"学习笔记/Java/Java核心技术卷1","permalink":"http://yoursite.com/categories/学习笔记/Java/Java核心技术卷1/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"08 | 发布到阿里云","slug":"Docker核心技术_08_发布到阿里云","date":"2019-07-09T03:35:40.000Z","updated":"2020-01-07T08:21:41.383Z","comments":true,"path":"2019/07/09/Docker核心技术_08_发布到阿里云/","link":"","permalink":"http://yoursite.com/2019/07/09/Docker核心技术_08_发布到阿里云/","excerpt":"","text":"1、登录1sudo docker login --username=[阿里账号] registry.cn-hangzhou.aliyuncs.com 2、命名1sudo docker tag [IMAGE_ID] [REPOSITORY]:[TAG] 3、发布1sudo docker push [REPOSITORY]:[TAG]","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Docker","slug":"学习笔记/Docker","permalink":"http://yoursite.com/categories/学习笔记/Docker/"},{"name":"Docker核心技术","slug":"学习笔记/Docker/Docker核心技术","permalink":"http://yoursite.com/categories/学习笔记/Docker/Docker核心技术/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"07 | DockerFile","slug":"Docker核心技术_07_DockerFile","date":"2019-07-08T12:14:14.000Z","updated":"2020-01-07T08:21:41.382Z","comments":true,"path":"2019/07/08/Docker核心技术_07_DockerFile/","link":"","permalink":"http://yoursite.com/2019/07/08/Docker核心技术_07_DockerFile/","excerpt":"","text":"✎DokcerFile构建步骤 编写Dockerfile文件。 docker build。 docker run。 ✎✎DokcerFile基础知识 每条保留字指令都必须为大写字母且后面要跟随至少一个参数。 指令按照从上到下，顺序执行。 ‘#’表示注释。 每条指令都会创建一个新的镜像层，并对镜像进行提交。 ✎✎✎DockerFile执行流程 docker从基础镜像运行一个容器。 执行一条指令并对容器作出修改。 执行类似docker commit的操作提交一个新的镜像层。 docker再基于刚提交的镜像运行一个新容器。 执行dockerfile中的下一条指令直到所有指令都执行完成。 ✎✎✎✎DokcerFile保留字指令 FROM：基础镜像，当前新镜像是基于哪个镜像的。 MAINTAINER: 镜像维护者的姓名和邮箱地址。 RUN: 容器构建时需要运行的命令。 EXPOSE: 当前容器对外暴露出的端口。 WORKDIR: 指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点。 ENV: 用来在构建镜像过程中设置环境变量。 问题：设置的环境变量永久生效吗？ ADD: 将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar压缩包。 COPY: 类似ADD，拷贝文件和目录到镜像中。 COPY src dest COPY [&quot;src&quot;,&quot;dest&quot;] VOLUME: 容器数据卷，用于数据保存和持久化工作。 CMD: 指定一个容器启动时要运行的命令。Dockerfile中可以有多个CMD指令，但只有最后一个生效。CMD会被docker run之后的参数替换。 shell格式：CMD&lt;命令&gt; exec 格式：CMD[“可执行文件”，“参数1”，“参数2..] 参数列表格式：CMD[“参数1”，“参数2”,...]。在指定了ENTRYPOINT指令后，用CMD指定具体的参数。 ENTRYPOINT: 指定一个容器启动时要运行的命令。ENTRYPOINT的目的和CMD一样，都是在指定容器启动程序及参数，ENTRYPOINT不会被dockerrun之后的参数替换，而是追加这个参数命令。 ONBUILD: 当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像的onbuild被触发。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Docker","slug":"学习笔记/Docker","permalink":"http://yoursite.com/categories/学习笔记/Docker/"},{"name":"Docker核心技术","slug":"学习笔记/Docker/Docker核心技术","permalink":"http://yoursite.com/categories/学习笔记/Docker/Docker核心技术/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"06 | Docker数据卷容器","slug":"Docker核心技术_06_Docker数据卷容器","date":"2019-07-04T03:27:58.000Z","updated":"2020-01-07T08:21:41.381Z","comments":true,"path":"2019/07/04/Docker核心技术_06_Docker数据卷容器/","link":"","permalink":"http://yoursite.com/2019/07/04/Docker核心技术_06_Docker数据卷容器/","excerpt":"","text":"✎卷的概念卷就是目录或文件，存在于一个或多个容器中，由docker挂载到容器，但不属于联合文件系统，因此能够绕过UnionFS提供一些用于持续存储或共享数据的特性。卷的设计目的就是数据的持久化，完全独立于容器的生存周期，因此Docker不会在容器删除时删除其挂载的数据卷。 ✎✎卷的作用 容器的持久化。 容器间继承+共享数据。 容器与主机的数据共享。 ✎✎✎卷的特点 数据卷可在容器之间共享或重用数据。 卷中的更改可以直接生效。 数据卷中的更改不会包含在镜像的更新中。 数据卷的生命周期一直持续到没有容器使用它为止。 ✎✎✎✎容器内添加数据卷1、直接命令添加1docker run -it -v /宿主机绝对路径目录:/容器内目录 IMAGE 可以通过inspect命令查看数据卷是否挂载成功。容器关了后，在主机的挂载目录下添加文件A，等容器重启后，容器相应的挂载目录也能看到这个文件A。 1docker run-it-v/宿主机绝对路径目录:/容器内目录:ro IMAGE 上面的命令中(ro = read only,默认是rw)，容器只能对挂载目录进行读，但是主机可以对挂载目录进行读写。 问题：如果主机不存在此目录，会自动创建吗？ 2、DockerFile添加可在Dockerfile中使用VOLUME指令来给镜像添加一个或多个数据卷:1VOLUME[&quot;/dataVolumeContainer&quot;，&quot;/dataVolumeContainer2&quot;，&quot;/dataVolumeContainer3] 该命令创建指定的主机目录是随机目录，无法指定特定目录，具体目录路径可以用inspect命令查看。 3、DockerFile Demo1234FROM centosVOLUME[&quot;/dataVolumeContainer1&quot;,&quot;/dataVolumeContainer2&quot;]（这个会在什么时候创建？）CMD echo &quot;finished,--------success1&quot;（这个会在什么时候打印？）CMD /bin/bash （这个有什么用？） 4、build构建镜像1docker build -f /mydocker/Dockerfile -t IMAGE . 问题：Docker挂载主机目录Docker访问出现cannot open directory:Permission denied。解决办法：在挂载目录后多加一个-privileged=true参数即可。 ✎✎✎✎✎数据卷容器命名的容器挂载数据卷，其它容器通过挂载这个（父容器）实现数据共享，挂载数据卷的容器，称之为数据卷容器。 1docker run -it --name dc02 --volumes-from dc01 IMAGE dc02容器继承dc01容器，同时子容器02的数据也能被01看到。使父容器与子容器的数据共享。 --volumes-from不要理解为继承，理解为“联系”会更好一点，而且这种联系是“多向”的。在任何时候，数据卷都是同步的。假设A与B联系，然后C与A联系，那么C与B也会联系。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Docker","slug":"学习笔记/Docker","permalink":"http://yoursite.com/categories/学习笔记/Docker/"},{"name":"Docker核心技术","slug":"学习笔记/Docker/Docker核心技术","permalink":"http://yoursite.com/categories/学习笔记/Docker/Docker核心技术/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"05 | Docker镜像","slug":"Docker核心技术_05_Docker镜像","date":"2019-07-04T02:52:23.000Z","updated":"2020-01-07T08:21:41.380Z","comments":true,"path":"2019/07/04/Docker核心技术_05_Docker镜像/","link":"","permalink":"http://yoursite.com/2019/07/04/Docker核心技术_05_Docker镜像/","excerpt":"","text":"✎镜像是什么镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。 ✎✎UnionFS（联合文件系统）Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下（unite several directories into a single virtual filesystem）。Union文件系统是Docker镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。 特性：一次同时加载多个文件系统，从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。 ✎✎✎Docker镜像加载原理bootfs（boot file system）主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs，这一层与我们典型的Linux/Unix系统是一样的：包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。rootfs（root file system），在bootfs之上。包含的就是典型Linux系统中的/dev，/proc，/bin，/etc等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。重点说是就是内核共用。 ✎✎✎✎镜像的分层分层的优点：最大的一个好处就是共享资源。比如：有多个镜像都从相同的base镜像构建而来，那么宿主机只需在磁盘上保存一份base镜像，同时内存中也只需加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。 ✎✎✎✎✎特点 Docker镜像都是只读的。 当容器启动时，一个新的可写层被加载到镜像的顶部，这一层通常被称作“容器层”，容器层”之下的都叫“镜像层”。 ✎✎✎✎✎✎镜像Commit提交容器副本使之成为一个新的镜像。1docker commit -m=&quot;提交的描述信息&quot; -a=&quot;作者&quot; 容器lD 要创建的目标镜像名:[标签名]","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Docker","slug":"学习笔记/Docker","permalink":"http://yoursite.com/categories/学习笔记/Docker/"},{"name":"Docker核心技术","slug":"学习笔记/Docker/Docker核心技术","permalink":"http://yoursite.com/categories/学习笔记/Docker/Docker核心技术/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"04 | Docker命令","slug":"Docker核心技术_04_Docker命令","date":"2019-07-03T09:40:42.000Z","updated":"2020-01-07T08:21:41.379Z","comments":true,"path":"2019/07/03/Docker核心技术_04_Docker命令/","link":"","permalink":"http://yoursite.com/2019/07/03/Docker核心技术_04_Docker命令/","excerpt":"","text":"✎帮助命令123docker versiondocker infodocker --help ✎✎镜像命令1、列出本机的镜像1docker images [OPTIONS] 表头信息： REPOSITORY：镜像的仓库源。 TAG：镜像的标签（同一仓库源可以有多个TAG）。 IMAGE ID：镜像ID。 CREATED：镜像创建时间。 SIZE：镜像大小。 OPTIONS： -a：列出本地所有的镜像（含中间映像层 ）。 -q：只显示镜像ID。 –digests：显示镜像的摘要信息。 –no-trunc：显示完整的镜像信息。 镜像就相当于一个千层饼。 2、Docker镜像查找1docker search [IMAGE_NAME] #可模糊查找，即使配了阿里云镜像加速，也会到DockerHub查。 OPTIONS： –no-trunc：显示完整的镜像描述。 -s：列出收藏数不小于指定值的镜像。 –automated：只列出automated build类型的镜像。 3、拉Docker镜像1docker pull [IMAGE_NAME] 4、删除镜像123docker rmi -f [IMAGE_ID] #删除单个docker rmi -f [IMAGE_NAME] [IMAGE_NAME] #删除多个docker rmi -f $(docker images -qa) #删除全部 5、查看镜像构建历史1docker history [IMAGE] 6、给镜像命名1docker tag [IMAGE_ID] [REPOSITORY]:[TAG] ✎✎✎容器命令1、新建并启动容器1docker run [OPTIONS] [IMAGE] [COMMAND][ARG..] OPTIONS： –name：为容器指定一个名称。 -d：后台运行容器，并返回容器ID，也即启动守护式容器。 -i：以交互模式运行容器，通常与-t同时使用。 -t：为容器重新分配一个伪输入终端，通常与-i同时使用。 -e：设置环境的变量。 -P：随机端口映射。 -p：指定端口映射，有以下四种格式： ip:hostPort:containerPort ip:containerPort hostPort:containerPort containerPort 启动并进入交互式容器1docker run -it [IMAGE] = docker run -it [IMAGE] /bin/bash 启动守护式容器(以后台进程方式运行)1docker run -d [IMAGE] Docker容器运行，需要有一个前台进程。容器运行的命令如果不是那些一直挂起的命令（比如运行top，tail)，是会自动退出的。可以启动容器并循环打印消息到前台（如下），这样容器就不会自动退出。（自动退出检测的时间间隔是多久？）1docker run-d [IMAGE] /bin/sh -c &quot;while true;do echo hello zzyy;sleep 2;done&quot;（可以通过容器日志看到这些输出。） 启动时指定端口映射1234docker run -it -p 8080(容器端口):8080(宿主机端口) [IMAGE]#宿主机端口随机分配docker run -it -P [IMAGE] 2、列出当前所有正在运行的容器1docker ps [OPTIONS] OPTIONS： -a：列出当前所有正在运行的容器+历史上运行过的 -l ：显示最近创建的容器。 -n：显示最近n个创建的一个容器。 -q：静默模式，只显示容器编号。 –no-trunc：不截断输出。 3、退出容器 exit: 容器停止退出。 ctrl+P+Q: 容器不停止退出。 4、启动容器1docker start [CONTAINER] 5、重启容器1docker restart [CONTAINER] 6、停止容器1docker stop [CONTAINER] 7、强制停止容器1docker kill [CONTAINER] 8、删除已停止的容器12docker rm [CONTAINER_ID]docker rm -f [CONTAINER_ID](强制删除，可以删除正在运行的容器) 9、一次性删除多个容器12docker rm -f $(docker ps -a -q)docker ps -a -q | xargs docker rm 10、查看容器日志1docker logs -f -t --tail [CONTAINER_ID] -t: 是加入时间戳。 -f: 跟随最新的日志打印。 –tail: 数字显示最后多少条。 11、查看容器内运行的进程1docker top [CONTAINER_ID] 12、查看容器内部细节1docker inspect [CONTAINER_ID] 13、进入正在运行的容器并以命令行交互1docker exec -it [CONTAINER_ID] [BASH_SHELL] exec是在容器中打开新的终端，并且可以启动新的进程。（不用进入到容器内进行交互，可以直接执行bashShell）1docker attach [CONTAINER_ID] = docker exec-t [CONTAINER_ID] /bin/bash attach直接进入容器启动命令的终端，不会启动新的进程attach进入容器后，exit会退出并关闭容器，exec进入容器（用/bin/bash这种方式），exit会退出但并不关闭容器。 13、从容器内拷贝文件到主机上1docker cp [CONTAINER_ID]:[容器内路径] [目的主机路径] ✎✎✎导入与导出1、导出镜像 &gt; 导入镜像123456#导出docker save -o [目标文件] [IMAGE]docker save &gt; [目标文件] [IMAGE]#导出docker load &lt; [目标文件]docker load -i [目标文件] 2、导出容器 &gt; 导入镜像12345#导出docker export -o [目标文件] [CONTAINER]#导入docker import [目标文件] [REPOSITORY]:[TAG]cat [目标文件] | docker import - [REPOSITORY]:[TAG] 3、这两者的区别 save的来源是镜像，export的来源是容器。 export的文件会小一点。 load会保存镜像的所有历史记录。import丢失所有元数据和历史记录，仅保存容器当时的状态。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Docker","slug":"学习笔记/Docker","permalink":"http://yoursite.com/categories/学习笔记/Docker/"},{"name":"Docker核心技术","slug":"学习笔记/Docker/Docker核心技术","permalink":"http://yoursite.com/categories/学习笔记/Docker/Docker核心技术/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"03 | Docker的helloworld","slug":"Docker核心技术_03_Docker的helloworld","date":"2019-07-03T09:19:48.000Z","updated":"2020-01-07T08:21:41.376Z","comments":true,"path":"2019/07/03/Docker核心技术_03_Docker的helloworld/","link":"","permalink":"http://yoursite.com/2019/07/03/Docker核心技术_03_Docker的helloworld/","excerpt":"","text":"✎镜像加速将配置文件的仓库地址修改为阿里云的镜像加速地址。（具体步骤可以去阿里云仓库看）可用ps -ef命令查看docker的启动配置是否是修改的阿里云镜像加速地址。 ✎✎run hello world镜像1docker run hello-world（不添加版本号，则默认是 hello-world:latest） run的过程 ✎✎✎运行原理Docker是一个Client-Server结构的系统，Docker守护进程运行在主机上，然后通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Docker","slug":"学习笔记/Docker","permalink":"http://yoursite.com/categories/学习笔记/Docker/"},{"name":"Docker核心技术","slug":"学习笔记/Docker/Docker核心技术","permalink":"http://yoursite.com/categories/学习笔记/Docker/Docker核心技术/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"02 | Docker的安装","slug":"Docker核心技术_02_Docker的安装","date":"2019-07-02T12:03:01.000Z","updated":"2020-01-07T08:21:41.376Z","comments":true,"path":"2019/07/02/Docker核心技术_02_Docker的安装/","link":"","permalink":"http://yoursite.com/2019/07/02/Docker核心技术_02_Docker的安装/","excerpt":"","text":"✎✎系统要求Docker运行在CentOs-6.5或更高版本的CentOs上，要求系统为64位、系统内核版本为2.6.32-431或者更高版本。 查看自己的内核1uname -r 查看centos版本1cat /etc/reahat-release ✎✎Centos6.8安装Docker1、Docker使用EPEL发布，RHEL系的OS首先要确保已经持有EPEL仓库，否则先检查OS的版本，然后装相应的EPEL包。1yum install-y epel-release 2、安装Docker1yum install-y docker-io 3、安装后的配置文件路径1/etc/sysconfig/docker 4、启动Docker后台服务1service docker start 5、验证Docker版本1docker version ✎✎✎开启2375端口1、编辑以下文本123vim /usr/lib/systemd/system/docker.service#或者vim /lib/systemd/system/docker.service 将文件内容编辑如下(简略)：1ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix://var/run/docker.sock \\ 2、重启docker systemctl daemon-reload systemctl restart docker","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Docker","slug":"学习笔记/Docker","permalink":"http://yoursite.com/categories/学习笔记/Docker/"},{"name":"Docker核心技术","slug":"学习笔记/Docker/Docker核心技术","permalink":"http://yoursite.com/categories/学习笔记/Docker/Docker核心技术/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"01 | Docker基础概念","slug":"Docker核心技术_01_Docker基础概念","date":"2019-07-02T11:33:08.000Z","updated":"2020-01-07T08:21:41.375Z","comments":true,"path":"2019/07/02/Docker核心技术_01_Docker基础概念/","link":"","permalink":"http://yoursite.com/2019/07/02/Docker核心技术_01_Docker基础概念/","excerpt":"","text":"✎Docker与传统虚拟机1、DockerDocker是用Go语言写的。Docker Client只与Docker daemon交互。Docker三要素：仓库、镜像、容器。 Docker镜像： Docker镜像就是一个只读的模板。 镜像可以用来创建Docker容器，一个镜像可以创建多个容器。 镜像就相当于一个类。 容器 容器的定义和镜像几乎一模一样，也是有一堆层，唯一的区别在于容器的最上面那一层是可读可写的。 容器相当于一个对象。 容器不是模拟一个完整的操作系统，而是对进程进行隔离。（只需要内核） 仓库 仓库是集中存放镜像文件的场所。 仓库和仓库注册服务器是有区别的。仓库注册服务器上往往存放着多个仓库，每个仓库又包含了多个镜像，每个镜像有不同的标签。 仓库分为公开仓库和私有仓库两种形式。 最大的公开仓库是Docker Hub。国内的公开仓库包括阿里云、网易云等。 2、传统虚拟机传统虚拟机缺点：资源占用多、冗余步骤多、启动慢。（模拟一个完整的操作系统，包括硬件等 ） 3、区别 传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整的操作系统，在该系统上再运行所需应用进程。 而容器内应用直接运行于宿主内核，容器内没有自己的内核，而且也没有进行硬件虚拟，因此容器要比传统虚拟机更加轻便。 每个容器之间互相隔离，每个容器有自己的文件系统，容器之间进程不会互相影响，能区分计算资源。 问题：那么宿主的版本会影响容器吗？会。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Docker","slug":"学习笔记/Docker","permalink":"http://yoursite.com/categories/学习笔记/Docker/"},{"name":"Docker核心技术","slug":"学习笔记/Docker/Docker核心技术","permalink":"http://yoursite.com/categories/学习笔记/Docker/Docker核心技术/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"03 | Java的基本程序设计结构","slug":"Java核心技术卷1_03_Java的基本程序设计结构","date":"2019-06-14T08:26:40.000Z","updated":"2020-01-07T08:21:41.388Z","comments":true,"path":"2019/06/14/Java核心技术卷1_03_Java的基本程序设计结构/","link":"","permalink":"http://yoursite.com/2019/06/14/Java核心技术卷1_03_Java的基本程序设计结构/","excerpt":"","text":"✎规范1、类名的规范名字必须以字母开头，后面可以跟字母和数字的任意组合，长度基本上没有限制。(不能用java保留字)。 2、main方法main方法必须声明为public。 ✎✎数据类型在Java中，一共有8种基本类型，其中4种整型、2种浮点类型、1种字符类型char、1种boolean类型。 1、整型整型用于表示没有小数部分的数值，它允许是负数。在Java中，整型的范围与与进行Java代码的机器无关。具体内容如下: 类型 存储需求(单位：byte) byte 1 short 2 int 4 long 8 2、长整型数值 长整型数值有一个后缀L(如40000000000L)。 十六进制数值有一个前缀0x（如0xCAFE）。 八进制有一个前缀0，(如010对应八进制中的8)，但是很容易混淆，所以最好不要用。 二进制有一个前缀0b（从java7开始，如0b1001就是9）。 从java7开始还可以为数字字面量加下划线（如1_000_000）方便阅读，java编译器会去除这些下划线。Java没有任何无符号类型(unsigned)。 3、浮点类型浮点类型用于表示有小数部分的数值。在Java中有两种浮点类型。如下表: 类型 存储需求(单位：byte) float 4 double 8 double的数值精度是float类型的两倍，所以也被称为双精度数值。float类型的数值有一个后缀F（例如3.14F）。没有后缀F的浮点数值（如3.14）默认为double类型。(3.14D也表示double类型)。jdk5.0中，可以用十六进制表示浮点数值。例如，0.125可以表示成0x1.0p-3，在十六进制表示法中，使用p表示指数而不是e。尾数采用十六进制，指数采用十进制。且指数的基数是2（p是2）而不是10。所有的浮点数值计算都遵循IEEE754规范。 double在内存里的表现形式 float在内存里的表现形式 第一位s代表符号为，1代表负数，0代表正数。 第二个域是指数域。 单精度数的偏差值为-127，而双精度double类型的偏差值为-1023。 第三个域为尾数域。 尾数为1.xxxx…xxx的形式。 计算公式（双精度） Demo：将存储在内存的2进制转换为float类型 s：1 -&gt; 表示负数。 e：10000010 -&gt; 130 -&gt; (130-127) = 3,也即尾数部分小数点向右移3位。 m：10110000000000000000000,尾数加上前面省略的1和小数点为：1.10110000000000000000000。 现在三个部分都已经算出来了，通过指数值调整小数点的位置，得到结果为：1101.10000000000000000000。 转换成10进制,整数部分为：1×2^3+1×2^2+1×2^0 = 13; 小数部分为：1×2^-1 = 0.5。 最后整数部分加上小数部分，再加上符号，所表示的实数就是：−13.5。 用于表示溢出和出错情况的三个特殊的浮点数值 正无穷大 -&gt; Double.POSITIVE_INFINITY 负无穷大 -&gt; Double.NEGATIVE_INFINITY NaN（不是一个数字）-&gt; Double.NaN 所有非数值的数字都是不相同的，所以不能像下面这样检测一个特定值是都等于Double.NaN。1if(x == Double.NaN) 但可以用以下代码判断是不是NaN:1if(Double.isNaN(x)) 浮点数值不适用于出现舍入误差的金融计算中（带小数点的计算）1System.out.println(2.0-1.1); 输出的将会是 0.8999999999999999。其主要原因是浮点数值采用二进制系统表示，而在二进制系统中无法精确的表示分数1/10。 小数转换二进制的方法十进制数的整数位是二进制数的整数位，十进制数的小数位是二进制数的小数位。两部分分开转换。 整数部分。除以2取余，逆序排列。 小数部分。乘2取整，顺序排列。 Demo： 十进制的0.1转换为二进制12345670.1 × 2 = 0.2 ......00.2 × 2 = 0.4 ......00.4 × 2 = 0.8 ......00.8 × 2 = 1.6.......10.6 × 2 = 1.2.......10.2 × 2 = 0.4.......0......无限循环 从上面过程可以知道，在将一个十进制的小数的小数部分转换为二进制的小数时，除非最后的一位是5，否则是不可能乘尽的，也就意味着这个十进制的小数是无法用二进制来精确表示的。若需要在数值计算中不含有任何误差，就应该使用BigDecimal类。 问题集锦 double类型的计算中有时精确有时不精确的问题。 直接赋值小数给double类型，按道理来讲尾数不为5的应该都表示不了，但实际上可以表示。 @see https://www.zhihu.com/question/56545018 这个问题里怎么知道一个double有2个近似值，从而取有效位比较小的那个近似值。 4、char类型char类型用来表示单个字符，通常用来表示字符常量。&#39;A&#39;是编码65对应的字符常量。&quot;A&quot;是一个包含字符A的字符串。Unicode编码单元可以表示为十六进制值，范围从\\u0000到\\uffff。char类型是基于Unicode编码的，所以占用两个字节。 用于表示特殊字符的转义序列符如下: 转义序列 名称 Unicode值 \\b 退格 \\u0008 \\t 制表 \\u0009 \\n 换行 \\u000a \\r 回车 \\u000d \\&quot; 双引号 \\u0002 \\&#39; 单引号 \\u0027 \\\\ 反斜杠 \\u005c 所有的转义字符都必须出现在字符常量或字符串的引号内，如&#39;\\u2122&#39;或&#39;Hello\\n&#39;。 5、boolean 类型数值型和布尔值之间不能进行相互转换。 ✎✎✎变量变量名必须是一个以字母开头的由字母或数字构成的序列。其中字母包括&#39;A&#39;~&#39;Z&#39;、&#39;a&#39;~&#39;z&#39;、&#39;_&#39;、&#39;$&#39;或在某种语言中代表字母的任何Unicode字符(实际上并不能用Unicode)，变量名的长度没有限制。尽管$是一个合法的Java字符，但最好不要用。它只用在Java编译器或其他工具生成的名字中。 ✎✎✎✎常量关键字final表示这个变量只能被赋值一次，赋值以后就不可以再被更改了。 ✎✎✎✎✎运算符当参与/运算的两个操作数都是整数时，表示整数除法，否则表示浮点除法。整数除以0将会产生一个异常，而浮点（不包括0.0）除以0将会得到无穷大结果。计算0.0/0或者负数的平方根结果为NaN。 ✎✎✎✎✎✎位运算符1、位运算符列表 符号 名称 &amp; 与 I 或 ^ 异或 ~ 非 &lt;&lt; 左位移运算符 &gt;&gt; 右位移运算符 &lt;&lt;&lt; 无符号右移运算符 运算符中，除~以外，其他均为二元运算符。操作数只能为整型和字符型数据。 2、位运算符运算规则 与运算 操作数1 操作数2 结果 0 0 0 0 1 0 1 0 0 1 1 1 或运算 操作数1 操作数2 结果 0 0 0 0 1 1 1 0 1 1 1 1 非运算 操作数 结果 0 1 1 0 异或运算 操作数1 操作数2 结果 0 0 0 0 1 1 1 0 1 1 1 0 左位移符号位不变，低位补0。 右位移符号位不变，并用符号位补溢出的高位。 无符号右移符号位也跟着改变，高位补0。 没有无符号左移的运算符。&amp;与|运算符与&amp;&amp;和||非常相似，只是不按短路方式计算。 ✎✎✎✎✎✎✎数学函数在Math类中，为了达到最快的性能，所有方式都使用计算机浮点单元中的例程。如果想要结果完全正确，那么就应该使用StrictMath类。 1、数值类型之间的合法转换 5个实心箭头表示无信息丢失的转换。3个虚箭头表示可能有精度损失的转换。当用上面两个数值进行二元操作时： 如果两个操作数有一个是double类型的，另一个操作数就会转换成double类型。 否则如果其中一个操作数是float类型，另一个操作数就会转换成float类型。 否则如果其中一个操作数是long类型，另一个操作数就会转换成long类型。 否则，两个操作数都将被转换成int类型。 2、强制转换如果试图将一个数值从一种类型强制转换成另一种类型而又超出了目标类型的表示范围，结果就会被截断成一个完全不同的值。 e.g (byte)300的结果为44。 ✎✎✎✎✎✎✎✎java字符串Java字符串就是Unicode的字符序列。由于不能修改Java字符串中的字符，所以在Java文档中将String类兑现称为不可变字符串。不可变字符串却有一个优点：编译器可以让字符串共享。 在Java的栈中，有共享池的概念，会把一些常量放到这个共享池中，包括字符串常量和基本类型常量。共享的操作在编译时由编译器完成的，可以节省内存，并提高效率。例如语句String str = &quot;hello&quot;，首先在栈中创建字符串引用变量str，再看看常量池中有没有”hello”，如果有str就直接指向它，没有就创建”hello”并放在常量池中，然后指向它。(对于int之类的基本类型的变量也差不多都是这样的。)而对于String str = new String(&quot;hello&quot;)，则是创建新的对象，并放在堆内存中。是在runtime的时候分配的。这样做效率和节省内存的方面不如String str = &quot;hello&quot;，但是更灵活。如果在编译时不知道要创建什么样的字符串，就只能运行时创建了。 1、代码点与代码单元代码点 &gt;= 代码单元。Java字符串由char序列组成。char数据类型是一个采用UTF-16编码表示Unicode代码点的代码单元。 大多数的常用Unicode字符使用一个代码单元就可以表示，而辅助字符需要一对代码单元表示。String的length方法将返回采用UTF-16编码表示的代码单元数量。而想要得到实际的长度，即代码点数量。需要如下方法:1int count = str.codePointCount(0,str.length()); 调用charAt(n)方法返回的是位置n的代码单元。 2、遍历代码点的两种方法12345678910111213String str = \"\\uD835\\uDD6B\"+\"a\";//代码点数量int count = str.codePointCount(0,str.length());System.out.println(\"code length :\"+count); //2int i = 0;while(i&lt;count)&#123; //得到第i个代码点 int index = str.offsetByCodePoints(0,i); int cp = str.codePointAt(index); System.out.println(Character.toChars(cp)); //𝕫 、a i++;&#125; 1234567891011//第一个代码点的indexint index = str.offsetByCodePoints(0,0);while(index&lt;str.length())&#123; int cp = str.codePointAt(index); System.out.println(Character.toChars(cp)); //𝕫 、a if(Character.isSupplementaryCodePoint(cp))&#123; index+=2; &#125;else&#123; index++; &#125;&#125; 3、构建字符串 StringBuilder与StringBuffer的区别 这两个类的API是相同的。 StringBuffer的效率比较低，但是是线程安全的。 Java8中，用String拼接字符串默认使用StringBuilder进行拼接。 可以使用标签的形式跳出循环，但是只能跳出语句不能跳进语句。1234label:&#123; if(condition) break label;&#125; ✎✎✎✎✎✎✎✎✎数组创建一个数字数组时，所有元素都初始化为0。boolean数组的元素都会初始化为false。对象数组的元素则初始化为一个特殊值null。一旦创建了数组，就不能再改变它的大小。 1、打印数组中的所有值1Arrays.toString(a); 2、数组初始化 静态初始化1int[] smallPrimes = &#123;2,3,5&#125;; 动态初始化12int[] smallPrimes = new int[2];smallPrimes[0] = 1; 匿名数组1new int[]&#123;2,3,5&#125; ; Java中数组长度可以为0。数组长度为0与null不同。 3、数组拷贝在Java中，允许将一个数组变量拷贝给另一个数组变量。这时，两个变量将引用同一个数组。12int[] luckyNumbers = smallPrimes;luckyNumbers[5] = 12 //now smallPrimes[5] is also 12 如果只是希望拷贝数组的值而不是变量，可以用Arrays类的copyOf方法。 4、数组排序1Arrays.sort(a); 这个方法使用了优化的快速排序算法。 5、二维数组12345int[][] magicSquare = &#123; &#123;1,2,3&#125;, &#123;2,3,4&#125; &#125;; 快速打印一个二维数组可以用Arrays.deepToString(a)方法。 6、不规则数组123int[][] odds = new int[NMAX + 1][];for(int n = 0;n&lt;=NMAX; n++) odds[n] = new int[n + 1];","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java核心技术卷1","slug":"学习笔记/Java/Java核心技术卷1","permalink":"http://yoursite.com/categories/学习笔记/Java/Java核心技术卷1/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://yoursite.com/tags/Java基础/"}]},{"title":"08 | 使用Zuul构建微服务网关","slug":"Spring Cloud与Docker微服务架构实战_08_使用Zuul构建微服务网关","date":"2019-06-05T05:51:29.000Z","updated":"2020-01-07T08:21:41.442Z","comments":true,"path":"2019/06/05/Spring Cloud与Docker微服务架构实战_08_使用Zuul构建微服务网关/","link":"","permalink":"http://yoursite.com/2019/06/05/Spring Cloud与Docker微服务架构实战_08_使用Zuul构建微服务网关/","excerpt":"","text":"✎Zuul使用的客户端 Apache HTTP Client(默认) RestClient(设置ribbon.restclient.enabled=true) okhttp3.OkHttpClient(设置ribbon.okhttp.enabled=true) ✎✎Zuul的整合 引入spring-cloud-starter-netfilx-zuul 在启动类上添加@EnbaleZuulProxy 在配置加上Eureka注册中心的地址（zuul整合了Ribbon与Hystrix）。 访问形式http://ZUUL_HOST:ZUUL_PROT/微服务名称/** ✎✎✎管理端点 通过/routes访问端点。 通过/routes?format=details可以访问更多的详细信息。 使用GET方式请求，可以得到当前映射的路由列表。 使用POST方式请求，强制刷新当前路由。 通过/filters 返回Zuul中所有的过滤器详情。 ✎✎✎✎路由配置1、配置指定微服务的访问路径1zuul.routes.xx-service-name: /user/** 或12345zuul: routes: user-route: #user-route只是给路由起名字，可以随意起 service-id: xx-service-name path: /user/** 2、忽略指定微服务，只代理其他服务1zuul.ignored-services: xx-service-name 3、忽略所有微服务，只代理指定服务1234zuul: ignored-services: &apos;*&apos; routes: xx-service-name: /user/** 4、指定path和url123456#将 /user/**映射到http//localhost:8080/,但是会破坏ribbon与hystrixzuul: routes: user-route: path: /user/** url: http//localhost:8080/ 12345678910111213#不破坏ribbon与hystrixzuul: routes: user-route: service-id: xx-service-name path: /user/** ribbon: eureka: enabled: falsexx-service-name: ribbon: listOfServers: localhost:8000,localhost:8001 5、可借助PatternServiceRouteMapper实现正则映射。 6、路由前缀 zuul.strip-prefix决定在访问时是否带上zuul.prefix。 zuul.routes.&lt;service-name&gt;.strip-prefix决定在访问时是否带上zuul.routes.&lt;service-name&gt;.path 7、忽略某些路径12345#在访问service-name这个服务时，会忽略/admin/路径。zuul: ignoredPatterns: /**/admin/** routes: &lt;service-name&gt;： /user/** 8、本地转发123456#在访问/path-a/**时，会转发到/path-b。zuul: routes: &lt;route-name&gt;: path: /path-a/** url: forward:/path-b ✎✎✎✎✎ZUUL日志级别1logging.level.com.netflix ✎✎✎✎✎✎ZUUL的安全与Header1、为特定service设置敏感header列表 1zuul.routes.&lt;service-name&gt;.sentive-headers 2、覆盖全局配置1zuul.routes.*.sentive-headers 3、忽略（丢弃）Header1zuul.ignored-headers ignored-headers默认为空，但是在在zuul配合spring security时默认值会是Expires等Spring Security的Header，如果需要使用它们，则可以设置zuul.ignoreSecurityHeaders为false。 ✎✎✎✎✎✎Zuul与文件上传 文件小于1M。无须任何处理。 文件大于10M。在访问zuul时需要加上zuul/前缀。 对于超大文件，要将hystrix和ribbon的超时时间设置长一点。12hystrix.command.default.execution.isolation.thread.timeoutInMillisecondsribbon.ConnectTimeout.ReadTimeout ✎✎✎✎✎✎✎Zuul的过滤器1、过滤器类型 PRE ROUTING POST ERROR 2、ZUUL请求的生命周期图 3、编写zuul过滤器 继承抽象类ZuulFilter，实现其抽象方法。 将这个新编写的filter注册成一个bean。 4、可使用过滤器做以下事情 限流 安全认证（传播安全token） 灰度发布 5、禁用过滤器1zuul.&lt;SimpleClassName&gt;.&lt;filterType&gt;.disable = true 6、注解@EnableZuulProxy是@EnableZuulServer的增强版。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"Spring Cloud与Docker微服务架构实战","slug":"学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"07 | 使用Hystrix实现微服务的容错处理","slug":"Spring Cloud与Docker微服务架构实战_07_使用Hystrix实现微服务的容错处理","date":"2019-06-04T09:35:40.000Z","updated":"2020-01-07T08:21:41.440Z","comments":true,"path":"2019/06/04/Spring Cloud与Docker微服务架构实战_07_使用Hystrix实现微服务的容错处理/","link":"","permalink":"http://yoursite.com/2019/06/04/Spring Cloud与Docker微服务架构实战_07_使用Hystrix实现微服务的容错处理/","excerpt":"","text":"✎断路器状态转换图 ✎✎整合Hystrix 引入spring-cloud-starter-netflix-hystrix 在启动类上添加@EnableCircuitBreaker或@EnbaleHystrix 在Mapping方法上添加注解: 1@HystrixCommand(fallbackMethod = \"findByIdFallback\") findByIdFallback是一个自定义方法，若业务发生异常则则回调用此方法。 123public User findByIdFallback(Long id)&#123;...&#125; @HystrixCommand下的commandProperties可配置超时等属性。 findByIdFallback的参数与Mapping注解下的方法参数需一致，若想对异常进行一些处理，可以再加上Throwable参数，如下: 123public User findByIdFallback(Long id ,Throwable e)&#123;...&#125; 若在某些异常情况下，不回调findByIdFallback方法，可以通过@HystrixCommand下的ignoreExceptions属性去设置。 ✎✎✎Hystrix与Actuator可以通过Actuator去监控Hystrix状态。服务正常时，状态是up，但是当我们关闭服务时再访问，Hystrix会由于业务失败执行回退逻辑，此时Hystrix的状态仍旧是up，这是由于失败率还没达到阈值，断路器还未被打开（默认是5S内20次失败）。 ✎✎✎✎Hystrix线程隔离策略 Hystrix线程隔离策略有两种： THREAD：HystrixCommand将在将在单独的线程执行。 SEMAPHORE：HystrixCommand将在调用线程上执行。 Hystrix默认的策略是THREAD。 在同一个线程，才能访问request上下文，所以使用THREAD策略会出现访问不到上下文的情况。 可通过execution.isolation.strategy属性指定隔离策略。 ✎✎✎✎✎Feign使用HystrixSrping Cloud默认已经为Feign整合了Hystrix。 1、feign开启hystrix 设置feign.hystrix.enbaled=true 为FeignClient接口创建一个实现类。 然后在FeignClient接口上使用@FeignClient的fallback属性指定实现类，即可实现hystrix的回滚功能。 如果需要知道回退错误类型，则： 实现FallbackFactory&lt;FeignClient&gt;类，复写create方法: 12public FeignClient create(Throwable cause)&#123;&#125; 在FeignClient接口上使用@FeignClient的fallbackFactory属性指定实现类。 2、为指定Feign禁用HystrixFeignClient默认是不开启Hystrix的，只是我们之前在全局加了开启Hystrix配置。所以要为指定Feign禁用Hystrix，只需要为特定的Feign注入一个初始的FeignClient(没开启Hystrix)而不注入全局的FeignClient即可。1234567@Configurationpublic class xxxConfiguration&#123; @Bean public Feign.Builder feignBulider()&#123; Feign.builder(); &#125;&#125; 之后在FeignClient的configuration属性指定这个配置即可。 ✎✎✎✎✎✎Hystrix的监控 只要添加了actuator模块，就能通过/hystrix.stream看到相应的监控信息。 可使用Hystrix Dashborad可视化监控数据。 可使用Turbine聚合监控数据。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"Spring Cloud与Docker微服务架构实战","slug":"学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"06 | 使用Feign实现声明式REST调用","slug":"Spring Cloud与Docker微服务架构实战_06_使用Feign实现声明式REST调用","date":"2019-06-04T08:47:51.000Z","updated":"2020-01-07T08:21:41.439Z","comments":true,"path":"2019/06/04/Spring Cloud与Docker微服务架构实战_06_使用Feign实现声明式REST调用/","link":"","permalink":"http://yoursite.com/2019/06/04/Spring Cloud与Docker微服务架构实战_06_使用Feign实现声明式REST调用/","excerpt":"","text":"✎整合Feign 添加Feign的依赖spring-cloud-starter-openfeign 创建Feign接口 12345@FeignClient(name = \"service-name\")public interface UserFeignClient&#123; @RequestMapping(value = \"/&#123;id&#125;\" , method = RequestMethod.GET) User findById(@PathVariable Long id);&#125; 在启动类添加@EnbaledFeignClients注解。 因为使用了Eureka，所以Ribbon会把service-name解析成注册中心列表里的服务。可以使用service.ribbon.listOfServers属性配置服务列表。也可以通过@FeignClient的url属性配置特定的地址。 ✎✎自定义Feign配置Feign的默认配置是FeignClientsConfiguration。可以通过@FeignClient的configuration属性自定义Feign的配置，自定义配置的优先级比FeignClientsConfiguration高。 1、自定义配置Demo123456public class FeignConfiguration&#123; @Bean public Contract feignContract()&#123; return new feign.Contract.Default(); &#125;&#125; 这个配置不能加@Configuration注解，否则如果被扫描到会被替换成全局配置。 2、基于Http Basic认证的Demo123456public class FeignConfiguration&#123; @Bean public BasicAuthRequestInterceptor basicAuthRequestInterceptor()&#123; return new BasicAuthRequestInterceptor(\"user\" , \"password\"); &#125;&#125; 3、全局配置用@EnableFeignClients的defaultConfiguration属性用来指定默认的配置类。 4、配置指定名称的Feign Client1feign.client.config.feignName.*(各种属性) 5、配置通用的Feign Client1feign.client.config.default.*(各种属性) 属性配置的方式比java配置的优先级更高，如果想让java配置的优先级更高，可以配置如下属性，1feign.client.default-to-properties=false ✎✎✎手动创建一个Feigon FeigonClient接口上的@FeignClient注解以及启动类上的@FeigonClients移除。 Controller Demo1234567891011121314@Import(FeignClientsConfiguration.class)@RestControllerpublic class MovieController&#123; private UserFeignClient userFeignClient; private adminFeignClient adminFeignClient; @Autowired public MovieController(Decoder decoder , Encoder encoder , Client client , Contract contract)&#123; this.userFeignClient = Feign.builder().client(client).encoder(encoder).decoder(decoder).contract(contract) .requestInterceptor(new BasicAuthRequestInterceptor(\"user\" , \"password1\")) .target(UserFeignClient.class , \"http://xxx-service/\"); //adminFeignClient类似上面 &#125;&#125; FeignClientsConfiguration是Spring Cloud为Feign提供的默认配置类。 Feign可以设置为对请求或响应进行压缩，还能对压缩进行一些详细的设置。Feign默认的日志级别是DEBUG，可以通过配置进行一些自定义的日志级别配置，甚至可以对某一特定服务进行单独的日志级别配置。 ✎✎✎构造多参数请求 使用@RequestParam和Map构造get的多参数请求。 使用@RequestBody构造post的多参数请求。 ✎✎✎✎使用Feign上传文件 引入feign-form（需要使用它的Encoder）。 Hystrix的超时时间需要设长一点。不然文件还没上传完就超时了。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"Spring Cloud与Docker微服务架构实战","slug":"学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"05 | 使用Ribbon实现客户端侧的负载均衡","slug":"Spring Cloud与Docker微服务架构实战_05_使用Ribbon实现客户端侧的负载均衡","date":"2019-06-04T08:04:21.000Z","updated":"2020-01-07T08:21:41.438Z","comments":true,"path":"2019/06/04/Spring Cloud与Docker微服务架构实战_05_使用Ribbon实现客户端侧的负载均衡/","link":"","permalink":"http://yoursite.com/2019/06/04/Spring Cloud与Docker微服务架构实战_05_使用Ribbon实现客户端侧的负载均衡/","excerpt":"","text":"✎获得当前选择的服务节点12@Autowiredprivate LoadBlancerClient loadBlancerClient; 12ServiceInstance instance = this.loadBlancerClient.choose(\"service-name\");instance.getHost()/instance.getPort(); ✎✎虚拟主机名称默认情况下，虚拟主机名称即服务名称（也可通过application-name指定服务名称）。也可配置eureka.instance.virtual-host-name或eureka.instance.security-virtual-host-name设置虚拟主机名称。虚拟主机名不能含有“_”这个字符，否则会报异常。不能将restTemplate.getForObject(...)与loadBalanceClient.choose(...)写在同一个方法，会有冲突。 ✎✎✎自定义Ribbon1、使用Java配置方式配置自定义RibbonRibbon默认的配置类是RibbonClientConfiguration。使用自定义配置会覆盖这个默认配置。所以我们在为某一个Ribbon设置一个自定义配置时，不应该让这个自定义配置被@ComponentScan扫描到。 1234567@Configurationpublic class RibbonConfiguration&#123; @Bean public IRule ribbonRule()&#123; return new RandomRule(); &#125;&#125; 123456//为特定service-name的ribbon client指定自定义配置类。@Configuration@RibbonClient(name = \"xxx-service\" , configuration = RibbonConfiguration.class)public class TestConfiguration&#123;&#125; 也可以用@RibbonClients为所有Ribbon Client提供默认配置。（让@RibbonClient的配置被扫描到，不就是全局配置了？） 2、使用属性自定义Ribbon配置 属性的前缀是service-name.ribbon NFLoadBanlancerClassName：配置ILoadBalancer的实现类。 NFLoadBanlancerRuleClassName：配置IRule的实现类。 NFLoadBanlancerPingClassName：配置Iping的实现类。 NIWSServerListClassName：配置ServerList的实现类。 NIWSServerListFilterClassName：配置ServerListFilter的实现类。属性配置的方式比Java配置方式的优先级更高。 3、脱离Eureka使用Ribbon12ribbon.eruka.enabled=falseservice-name.ribbon.listOfServer= xxx,xxx 4、指定名称的Ribbon请求特定URL，其他Ribbon使用Eureka12service-name.ribbon.NIWSServerListClassName = com.netflix.loadbalancer.ConfigurationBasedServerListservice-name.ribbon.listOfServers = xxx,xxx ✎✎✎✎Ribbon的加载Ribbon上下文的加载默认是懒加载的（第一次请求才会加载），可通过如下方式配置成饥饿加载。1234ribbon: eager-load: enabled: true clients: client1,client2","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"Spring Cloud与Docker微服务架构实战","slug":"学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"04 | 微服务注册与发现","slug":"Spring Cloud与Docker微服务架构实战_04_微服务注册与发现","date":"2019-06-04T03:18:43.000Z","updated":"2020-01-07T08:21:41.437Z","comments":true,"path":"2019/06/04/Spring Cloud与Docker微服务架构实战_04_微服务注册与发现/","link":"","permalink":"http://yoursite.com/2019/06/04/Spring Cloud与Docker微服务架构实战_04_微服务注册与发现/","excerpt":"","text":"✎Eureka Server微服务启动后，会周期性(默认为30s)的向Eureka Server发送心跳，以续约自己的租期。Eureka Server在一定时间（默认为90s）没有接收到微服务实例的心跳，将注销该实例。默认情况下Eureka Server也是Eureka Client。Eureka Client会缓存服务注册表中的信息。如果是一个单点的Eureka Server，可以把eureka.client.registerWithEureka设为false，因为不需要同步其他的Eureka Server节点的信息。 ✎✎注册若不配置eureka.instance.prefer-ip-address这个属性或者将其设为false，则表示注册微服务所在操作系统的hostname到Eureka Server。在Spring Cloud Edgware以及更高版本中，只需要添加相关依赖，即可自动注册。若不想将服务注册到Eureka Server，只需设置spring.cloud.service-registry.auto-registration.enabled = false或@EnableDiscoverClient(autoRegister=false)。 ✎✎✎Eureka Server高可用使用yml实现的比较新奇的配置：12345678910111213141516171819202122232425spring: application: name : xxxx---spring: profiles: peer1server: port: 8761eruka: instance: hostname: peer1 client: serviceUrl: defaultZone: http://peer2:8762/eureka/---spring: profiles: peer2server: port: 8762eruka: instance: hostname: peer2 client: serviceUrl: defaultZone: http://peer1:8761/eureka/ 上面使用—将yml文件分为三段，第一段未指定profile，表示是公用的，对所有profile都生效。 ✎✎✎✎为Eureka Server开启认证添加spring-boot-security-starter。 1、通过配置方式开启Basic认证yml添加以下内容：12345678910security: basic: enabled: trueuser: name: user password: password@123 eureka: client: serviceUrl: defaultZone: http://user:password@123localhost:8761/eureka/ 2、通过生命Bean的方式开启Basic认证 12345678@Beanpublic DiscoveryClientOptionalArgs discoveryClientOptionalArgs() &#123; DiscoveryClientOptionalArgs discoveryClientOptionalArgs = new DiscoveryClientOptionalArgs(); List&lt;CilentFilter&gt; additionalFilters = new ArrayList&lt;&gt;(); additionalFilters.add(new HTTPBasicAuthFilter(\"user\" , \"password123\")) discoveryClientOptionalArgs.setAdditionalFilters(additionalFilters); return discoveryClientOptionalArgs;&#125; ✎✎✎✎✎Eureka的元数据Eureka的元数据有两种，分别是标准元数据和自定义元数据。 标准元数据：主机名、IP地址、端口号、状态页和健康检查等信息。 自定义元数据：eureka.instance.metadata-map配置（key-value）。 DiscoveryClient.getInstance(serviceId)可查询指定微服务在Eureka上的实例列表。包括标准元数据和自定义元数据。/eureka/apps可查看Eureka的metadata。 ✎✎✎✎✎✎手动对服务进行操作可通过 /eureka/apps下的端点，进行服务注册，服务查询，服务注销等操作（用xml交互）。 ✎✎✎✎✎✎✎Eureka的自我保护进入自我保护模式后，Eureka Server的首页会显示告警。之前有说到，在一定时间（默认90s）内，如果没收到客户端的心跳，那么server会注销这个客户端，但是如果在短时间丢失过多的客户端（出现网络故障的原因），那么server就会进入自我保护模式，不会删除注册列表里的客户端。当网络故障恢复后，该server会自动退出自我保护模式。禁用自我保护模式。eureka.server.enable-self-perservation = false。 ✎✎✎✎✎✎✎✎指定注册到server上的IP1、忽略指定名称的网卡123456789spring: cloud: inetutils: ignored-interfaces: - docker0 - veth.*eureka: instance: prefer-ip-address: true 2、使用正则表达式，指定使用的网络地址123456789spring: cloud: inetutils: preferredNetworks: - 192.168 - 10.0eureka: instance: prefer-ip-address: true 3、只使用站点本地地址1234567spring: cloud: inetutils: userOnlySiteLocalInterfaces: trueeureka: instance: prefer-ip-address: true 4、手动指定IP地址 eureka: instance: prefer-ip-address: true ip-address: 127.0.0.1 ✎✎✎✎✎✎✎✎✎健康检查1、开启健康检查（不仅仅是心跳保持正常）eureka.client.healthcheck.enbaled: true加了上述配置时，/pause端点无法正常工作。也无法将状态标记为 down。这个bug未修复。 2、实现自己的健康检查实现HealthCheckHandler接口。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"Spring Cloud与Docker微服务架构实战","slug":"学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"03 | 开始使用Spring Cloud实战微服务","slug":"Spring Cloud与Docker微服务架构实战_03_开始使用Spring Cloud实战微服务--Spring Cloud","date":"2019-06-04T02:57:39.000Z","updated":"2020-01-07T08:21:41.436Z","comments":true,"path":"2019/06/04/Spring Cloud与Docker微服务架构实战_03_开始使用Spring Cloud实战微服务--Spring Cloud/","link":"","permalink":"http://yoursite.com/2019/06/04/Spring Cloud与Docker微服务架构实战_03_开始使用Spring Cloud实战微服务--Spring Cloud/","excerpt":"","text":"✎Maven项目转Gradle项目1gradle init --type pom ✎✎注解 @GetMapping相当于@RequestMapping(method = RequestMethod.GET)。类似的还有@PutMapping、@DeleteMapping等。 @SpringBootApplication整合了 @Configuration @EnableAutoConfiguration @ComponentScan ✎✎✎YMLyml有严格的缩进、冒号后的空格不能少。 ✎✎✎✎Actuator要让端点显示详情，可以用以下三种方式之一实现： 添加spring-boot-starter-security这个starter pom。 设置management.security.enabled=false。 设置management.endpoint.health.show-details=always。 可以用info.*属性定义info端点公开的数据。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"Spring Cloud与Docker微服务架构实战","slug":"学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"02 | 微服务开发框架--Spring Cloud","slug":"Spring Cloud与Docker微服务架构实战_02_微服务开发框架--Spring Cloud","date":"2019-06-04T02:52:29.000Z","updated":"2020-01-07T08:21:41.436Z","comments":true,"path":"2019/06/04/Spring Cloud与Docker微服务架构实战_02_微服务开发框架--Spring Cloud/","link":"","permalink":"http://yoursite.com/2019/06/04/Spring Cloud与Docker微服务架构实战_02_微服务开发框架--Spring Cloud/","excerpt":"","text":"✎Spring Cloud版本介绍M表示里程碑版本。SR表示“Service Base”。一般表示bug修复。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"Spring Cloud与Docker微服务架构实战","slug":"学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"01 | 微服务架构概述","slug":"Spring Cloud与Docker微服务架构实战_01_微服务架构概述","date":"2019-06-04T02:45:53.000Z","updated":"2020-01-07T08:21:41.434Z","comments":true,"path":"2019/06/04/Spring Cloud与Docker微服务架构实战_01_微服务架构概述/","link":"","permalink":"http://yoursite.com/2019/06/04/Spring Cloud与Docker微服务架构实战_01_微服务架构概述/","excerpt":"","text":"","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"Spring Cloud与Docker微服务架构实战","slug":"学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/Spring-Cloud与Docker微服务架构实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"03 | 服务治理 ：Spring Cloud Eureka","slug":"SpringCloud微服务实战_03_服务治理","date":"2019-05-05T02:43:35.000Z","updated":"2020-01-07T08:21:41.448Z","comments":true,"path":"2019/05/05/SpringCloud微服务实战_03_服务治理/","link":"","permalink":"http://yoursite.com/2019/05/05/SpringCloud微服务实战_03_服务治理/","excerpt":"","text":"Spring Cloud Eureka是Spring Cloud Netfix的一部分，基于Netfix Eureka做了二次封装。 ✎服务治理服务治理包含了两部分的内容：服务注册与服务发现。1、什么叫做服务注册？服务注册就是服务单元向注册中心注册自己的服务。其中注册中心维护一个服务清单（一个服务可能有多个实例），还需要以心跳的方式去监测清单中的服务是否可用。 2、什么叫做服务发现？服务调用方不会直接调用服务提供方，而是向注册中心请求这个服务的实例列表，之后通过某种策略从这列表中选出一个实例进行调用。 ✎✎Eureka服务器端(服务注册中心)Eureka服务器端可以以集群方式部署，并且服务注册中心之间以异步模式互相复制各自的状态。当某个分片（注册中心）故障时，继续提供服务的发现和注册。当故障分片恢复运行时，集群中的其他分片会把他们的状态同步回故障分片。 ✎✎✎搭建服务注册中心1、maven配置在第二章maven配置的基础上，加上如下配置： 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Greenwich.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 2、注解在Application上加上@EnableEurekaServer 3、配置 12345678910#服务器端口，默认为8761server.port=1111#是否向注册中心注册自己，默认为trueeureka.client.register-with-eureka = false#是否去检索服务（服务发现），默认为trueeureka.client.fetch-registry = false#默认为http://localhost:8761/eureka/eureka.client.serviceUrl.defaultZone = http://127.0.0.1:1111/eureka/#应用名spring.application.name=center1 4、访问注册中心页面http://127.0.0.1:1111/ ✎✎✎✎搭建服务提供者1、注解在Application上加上@EnableEurekaClient 2、配置123#如有多个则以逗号隔开eureka.client.serviceUrl.defaultZone = http://localhost:1111/eureka/spring.application.name = hello.server 3、查看是否生效可在服务中心的Instances currently registered with Eureka一栏看到服务的信息。 ✎✎✎✎✎高可用注册中心1、配置只需要理解eureka.client.serviceUrl.defaultZone这个参数的意义即可，它相当于把注册中心用一条线连起来。只要N个注册中心可以用一条线连起来（线路可达），那么就形成了高可用集群。当超过2个注册中心时，集群中的节点需要相互关联，否则会导致某个注册中心不可达。 有个问题：当服务注册到注册中心后，再停掉服务，从注册中心页面并不能看出这个服务已经下线。 ✎✎✎✎✎服务发现与消费1、maven配置1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 2、代码1234567891011121314@SpringBootApplication@EnableDiscoveryClientpublic class Application &#123; @Bean @LoadBalanced RestTemplate restTemplate()&#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(Application.class , args); &#125;&#125; 1234567891011@Servicepublic class UserServiceImpl implements UserSerivce &#123; @Autowired private RestTemplate restTemplate; @Override public String say() &#123; return restTemplate.getForEntity(\"http://HELLO.SERVER/hello\",String.class).getBody(); &#125;&#125; 需要注意的是上述的HELLO.SERVER是服务提供者模块的spring.application.name属性名。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"SpringCloud微服务实战","slug":"学习笔记/Java/Spring/SpringCloud微服务实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/SpringCloud微服务实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"01 | 基础知识","slug":"SpringCloud微服务实战_01_基础知识","date":"2019-04-16T03:28:12.000Z","updated":"2020-01-07T08:21:41.443Z","comments":true,"path":"2019/04/16/SpringCloud微服务实战_01_基础知识/","link":"","permalink":"http://yoursite.com/2019/04/16/SpringCloud微服务实战_01_基础知识/","excerpt":"","text":"✎基础概念1、服务组件化微服务其实就是将服务组件化的过程，那么服务组件化有什么好处呢？ 系统的各个服务可以独立更换升级而不影响其他单元。 各个服务可以根据自身的情况进行水平扩展。 2、微服务之间的通信微服务之间的通信有两种方式： 基于Http的RESTful API进行通信。 通过轻量级消息总件（比如RabbitMQ）传递消息。 3、去中心化去中心化就是让每一个服务来管理其自有的数据库。但是去中心化也有缺点，那就是不能很好地解决数据一致性问题。所以各服务之间应该要进行无事务的调用，若过程有错误，则通过补偿机制进行处理，只要求数据在最后的处理状态是一致的即可。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"SpringCloud微服务实战","slug":"学习笔记/Java/Spring/SpringCloud微服务实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/SpringCloud微服务实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"02 | 微服务构建","slug":"SpringCloud微服务实战_02_微服务构建","date":"2019-04-16T03:28:12.000Z","updated":"2020-01-07T08:21:41.443Z","comments":true,"path":"2019/04/16/SpringCloud微服务实战_02_微服务构建/","link":"","permalink":"http://yoursite.com/2019/04/16/SpringCloud微服务实战_02_微服务构建/","excerpt":"","text":"✎SpringBoot的Maven配置构建SpringBoot工程，只需要引入spring-boot-starter-parent与若干Starter POM，并且只需要指定spring-boot-starter-parent的版本，而不需要指定Starter POM的版本。因为spring-boot-starter-parent已经定义了Spring Boot版本的基础依赖以及一些默认配置内容（如配置文件application.properties的位置等）。Starter POM采用spring-boot-starter-*的命名方式。 ✎✎用MockMvc进行单元测试12345678910111213141516@RunWith(SpringJUnit4ClassRunner.class)@SpringJUnitWebConfig(classes = Application.class)public class HelloControllerTest &#123; private MockMvc mockMvc; @Before public void setUp()&#123; mockMvc = MockMvcBuilders.standaloneSetup(new HelloController()).build(); &#125; @Test public void hello() throws Exception &#123; mockMvc.perform(MockMvcRequestBuilders.get(\"/hello\").accept(MediaType.APPLICATION_JSON)) .andExpect(status().isOk()).andExpect(content().string((\"Hello World\"))); &#125;&#125; ✎✎✎配置文件详解1、配置文件SpringBoot的默认配置文件路径：src/main/resources/application.properties 2、YAML配置文件1234567environments: dev: url : http://dev.bar.com name : Developer Setup prod: url : http://foo.bar.com name : My Cool App YAML配置文件有以下优缺点： 优点：将属性加载到内存中保存的时候是有序的。 缺点：无法通过@PropertySource注解来加载配置。 ✎✎✎✎属性详解1、属性说明指定端口：server.port指定应用名：spring.application.name定义多个不同的环境配置：spring.profiles.active 2、用@Value加载属性@Value的两种加载配置方式 PlaceHolder方式：${...} SpEL表达式：#{...} 3、参数引用123book.name = SpringCloudbook.author = hjlbook.desc = $&#123;book.author&#125; is writing《$&#123;book.name&#125;》 4、用${random}设置随机数12345678910#随机字符串com.didispace.blog.value=$&#123;random.value&#125;#随机intcom.didispace.blog.value=$&#123;random.int&#125;#随机longcom.didispace.blog.value=$&#123;random.long&#125;#10以内的随机数com.didispace.blog.value=$&#123;random.int(10)&#125;#10~20的随机数com.didispace.blog.value=$&#123;random.int[10,20]&#125; 可使用随机数生成随机端口避免端口冲突。 5、使用命令行参数指定属性java -jar xxx.jar --server.port=8888 ✎✎✎✎✎多环境配置多环境配置的文件名需要满足application-{profile}.properties的格式。可以通过spring.profiles.active参数指定不同的配置文件。若不指定，则默认的profile是dev。 多环境配置思路 将通用的配置内容放到application.properties。 将特定的内容放到application-{profile}.properties。 通过spring.profiles.active加载不同环境的配置文件。 ✎✎✎✎✎✎配置文件加载顺序123456789101112命令行参数SPRING_APPLICATION_JSON中的属性来自java:comp/env的JNDI属性Java系统属性（System.getProperties()）操作系统环境变量RandomValuePropertySource配置的random.*属性值jar包外部的application-&#123;profile&#125;.properties或application.yml（带spring.profile）配置文件jar包内部的application-&#123;profile&#125;.properties或application.ym（带spring.profile）配置文件jar包外部的application.properties或application.yml（不带spring.profile）配置文件jar包内部的application.properties或application.yml（不带spring.profile）配置文件@Configuration注解类上的@PropertySource通过SpringApplication.setDefaultProperties指定的默认属性 ✎✎✎✎✎✎✎监控与管理首先需要引入引入actuator的starter pom。默认情况下，只有/health和/info这两个端点通过http暴露了出来。所以当我们在访问http://localhost:8080/actuator这个接口时，会得到如下json： 以下是Spring官网给出的所有端点描述：spring官网关于Endpoints的资料 可以通过这个设置management.endpoints.web.exposure.include = *，将其他端口也通过http暴露出来。/shutdown这个端点默认是不开启的，还需要再加上配置management.endpoint.shutdown.enabled=true开启这个端点。当我们访问/health这个端点的时候，加上management.endpoint.health.show-details=always会将更详细的检验器信息打印出来。Spring内置了许多校验器，具体的可以去spring官网查一下。我们也可以实现自己的校验器，如下 12345678910111213@Componentpublic class MyServiceHealthIndicator implements HealthIndicator &#123; private boolean flag = false; @Override public Health health() &#123; if(flag)&#123; //模拟校验成功 return Health.up().build(); &#125; //模拟校验失败 return Health.down().withDetail(\"status\" , \"500\").withDetail(\"message\" , \"服务器错误\").build(); &#125;&#125;","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"SpringCloud微服务实战","slug":"学习笔记/Java/Spring/SpringCloud微服务实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/SpringCloud微服务实战/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://yoursite.com/tags/Spring-Cloud/"}]},{"title":"05 | 构建块","slug":"Java并发编程实战_05_构建块","date":"2019-04-15T11:26:35.000Z","updated":"2020-03-16T12:32:21.368Z","comments":true,"path":"2019/04/15/Java并发编程实战_05_构建块/","link":"","permalink":"http://yoursite.com/2019/04/15/Java并发编程实战_05_构建块/","excerpt":"","text":"✎在并发中迭代Iterator与for-each在循环的过程中，会监听一个计数器，如果计数器被修改（集合被修改），则会抛出ConcurrentModificationException。值得一提的是修改计数器并不是一个线程安全的操作，所以有可能线程A在迭代，线程B修改了集合，但是线程A没抛出ConcurrentModificationException。12345678910111213141516171819public class HiddenIterator &#123; private final Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); public synchronized void add(Integer i)&#123; set.add(i); &#125; public synchronized void remove(Integer i)&#123; set.remove(i); &#125; public void addThenThings()&#123; Random random = new Random(); for(int i = 0 ; i &lt; 10 ; i ++)&#123; add(random.nextInt()); &#125; System.out.println(set); &#125;&#125;上面的代码中，由于迭代（println会打印toString的内容，而hashSet的toString方法就是使用Iterator拼接Set的所有元素）与容器内元素的改变（HiddenIterator#get/set）没有使用同一个锁，所以在迭代时候有可能会出现ConcurrentModificationException。解决的方法很简单，保持这两者的锁一致即可。 ✎✎常用的并发类 1、Map ConcurrentHashMap：非独占锁，在并发情况下用来代替HashMap。提供不抛出ConcurrentModificationException的迭代器，这个迭代器拥有“弱一致性”而不是“及时失败”，允许并发修改。它的size()方法与empty()方法是估算值，并不完全准确。 这个迭代器是怎么实现的？ ConcurrentSkipListMap：在并发情况下用来代替SortedMap。 SortedMap是什么形式的Map？ Hashtable：独占锁。 Collections.synchronizedMap：独占锁。 2、List CopyOnWriteList：在并发情况下用来代替List。容器的迭代器保留一个底层基础数组，这个数组的元素永远不会被修改，所以在迭代进行读取时，不需要加锁。迭代时，也不会抛出ConcurrentModificationException。当需要修改元素时，会复制一个数组并对这个数组进行修改，然后直接替换基础数组。 3、Set ConcurrentSkipListSet：在并发情况下用来代替SortedSet。 CopyOnWriteArraySet：在并发情况下用来代替Set。 ✎✎✎Queue 1、Queue的框架图 实现了BlockingQueue的都是阻塞队列（支持并发）。阻塞队列需要catch InterruptionException。带有Priority的都是优先级队列。ConcurrentLinkedQueue、LinkedBlockingQueue、ArrayListBlockingQueue是FIFO队列。 2、BlockingQueue可以是有界的也可以是无界的。非定时阻塞的方法：put、take。可定时阻塞的方法：offer、poll。 3、SynchronousQueueSynchronousQueue没有存储功能，因此put和take会一直阻塞，直到有另一个线程已经准备好参与到交付过程中。仅当有足够多的消费者，并且总是有一个消费者准备好获取交付的工作时，才适合使用同步队列。 生产者-消费者模式中，如果一个是I/O密集型，另一个是CPU密集型，那么并发执行的吞吐率要高于串行执行的吞吐率。如果生产者和消费者的并行度不同，那么将它们紧密耦合在一起会把整体并行度降低为二者中更小的并行度。 4、用双端队列实现工作密取。如果一个消费者完成了自己双端队列中的全部工作，那么它可以从其他消费者双端队列末尾秘密地获取工作。 ✎✎✎✎中断 中断并不是强制另外一个线程立刻停下来，只能要求另外一个线程在可以暂停的地方停止正在执行的工作。（当然被中断的线程也可以恢复中断，继续执行） 其实就是try catch Interruption的应用。 ✎✎✎✎✎缓存方案 在做缓存时，计算value可能会需要很长的时间。通常的逻辑是：12345678910public String getValue(int key)&#123; 同步块保护&#123; //根据key get value if(value 不存在)&#123; //根据key 计算value， //push 进map &#125; &#125; //返回value &#125; 当然，还可能再优化成分段锁(根据key分段)，或者优化成DCL双锁去保护value的计算，避免在读已存在缓存时进入同步块。但是终究会有弊端： 同步开销大。 不同的key可能会使用同一个锁。（不可能为每一个key都生成一个锁，一般都会采用对key进行hash后取得相应的锁这种策略） 可用futureTask来代替上述逻辑，将计算放到一个线程任务中：123456789101112public String getValue(int key)&#123; /**新建计算value的futureTask A**/ //如果map已存在此future，则返回此future，此时抛弃futureTask A。否则将futureTask A push进去 currentFutureTask = map.putIfAbsent(key , future); if(currentFutureTask == null)&#123; //如果purIfAbsent为null，则表示push进去的是futureTask A，需要submit futureTask A进行计算 /**submit future任务**/ /**currentFutureTask = futureTask A**/ &#125; return currentFutureTask.get();&#125; 使用这种方式可以避免上述过程中所论述的弊端。 需要整理一下，JDK提供的各种线程安全类。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"04 | 组合对象","slug":"Java并发编程实战_04_组合对象","date":"2019-04-03T09:49:12.000Z","updated":"2020-01-13T05:04:22.863Z","comments":true,"path":"2019/04/03/Java并发编程实战_04_组合对象/","link":"","permalink":"http://yoursite.com/2019/04/03/Java并发编程实战_04_组合对象/","excerpt":"","text":"✎私有锁与对象锁 对象锁会暴露给外部，而私有锁不会。 对Collections.unmodifiableMap的一些探讨 1234567891011121314151617181920212223242526272829303132333435public class Test7 &#123; public static void main(String[] args) &#123; Map&lt;Integer , Location&gt; map = new HashMap&lt;&gt;(); map.put(1 , new Location(1 ,1)); Map&lt;Integer , Location&gt; otherMap = Collections.unmodifiableMap(map); System.out.println(\"map \"+map.get(1)); //输出 map 1,1 System.out.println(\"othermap \"+otherMap.get(1)); //输出 othermap 1,1 map.get(1).setX(11); System.out.println(\"othermap \"+otherMap.get(1)); //输出 othermap 11,1 otherMap.get(1).setX(12); System.out.println(\"othermap \"+otherMap.get(1)); //输出 othermap 12,1 otherMap.put(2 , new Location(1 ,1)); //抛出java.lang.UnsupportedOperationException &#125; public static class Location&#123; private int x; private int y; public Location(int x , int y)&#123; this.x = x; this.y = y; &#125; public String toString()&#123; return x+\",\"+y; &#125; //getter and setter ... &#125;&#125; 由上面的输出可知，unmodifiableMap的value执行的是深层复制，而且可以对value对象里面的属性进行更改。但是不能对引用进行更改。 任何的线程问题都可以从这个角度出发：内存是否一致。 ✎✎由于锁不一样导致的问题 1234567891011public class ListHelper&lt;E&gt; &#123; public List&lt;E&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;()); public synchronized boolean putIfAbsent(E x)&#123; boolean absent = !list.contains(x); if(absent)&#123; list.add(x); &#125; return absent; &#125;&#125; synchronizedList这个方法提供了同步的方法，但是锁的对象是内置的一个obejct。由于以下两点原因： list的get/set的锁与putIfAbsent的锁不是同一个锁。 list是由public修饰的，所以可以直接被访问。 导致putIfAbsent其实是线程不安全的。 解决这个问题也很简单：将list修改为private修饰，不让外界访问它的get/set方法，或者将它的get/set用ListHelper这个对象锁保护，保证与putIfAbsent使用的是同一个锁。（当然，这样就没必要用synchronizedList了）以下Demo中，让putIfAbsent使用synchronizedList所使用的锁，（本质上也是保持使用锁的一致）： 12345678910111213public class ListHelper&lt;E&gt; &#123; public List&lt;E&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;()); public boolean putIfAbsent(E x)&#123; synchronized (list)&#123; boolean absent = !list.contains(x); if(absent)&#123; list.add(x); &#125; return absent; &#125; &#125;&#125; synchronizedList的构造方法中，如果没有传锁对象，则会把本对象(list)，作为锁对象。123456789SynchronizedCollection(Collection&lt;E&gt; c) &#123; this.c = Objects.requireNonNull(c); mutex = this;&#125;SynchronizedCollection(Collection&lt;E&gt; c, Object mutex) &#123; this.c = Objects.requireNonNull(c); this.mutex = Objects.requireNonNull(mutex);&#125; 是否会存在这种情况：对象创建时引用已经赋值给变量了，但是对象方法还未被初始化？答：如果不是final类型或volatile类型的对象初始化，确实会有这样的情况。 ListHelper应该也是会有线程安全问题？ 使用装饰器方法保护非线程安全的类： e.g 使用Collections.synchronizedList保护ArrayList。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"02 | 线程安全性","slug":"Java并发编程实战_02_线程安全性","date":"2019-03-22T02:49:43.000Z","updated":"2020-01-13T04:37:35.241Z","comments":true,"path":"2019/03/22/Java并发编程实战_02_线程安全性/","link":"","permalink":"http://yoursite.com/2019/03/22/Java并发编程实战_02_线程安全性/","excerpt":"","text":"1、什么时候需要同步？ 该变量是共享且可变的。 2、实现同步的4种方法 volatile synchronized 显示锁Lock 原子类Atomic 3、不变性的定义 无论在单线程还是多线程，结果永远不变。 4、其他知识点 Servlet是单例的，如果在某个Servlet类添加可变的局部变量，则要考虑此变量是否需要同步访问。 加锁与解锁都需要消耗资源，对于同一块代码，应该尽可能地少用同步块（能用一个同步块解决的，就不要用两个同步块）。 可以用FindBugs插件检查代码是否会有bug。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"03 | 对象的共享","slug":"Java并发编程实战_03_对象的共享","date":"2019-03-22T02:49:43.000Z","updated":"2020-01-21T03:15:53.407Z","comments":true,"path":"2019/03/22/Java并发编程实战_03_对象的共享/","link":"","permalink":"http://yoursite.com/2019/03/22/Java并发编程实战_03_对象的共享/","excerpt":"","text":"✎未同步的情况下使用共享变量带来的问题 12345678910111213141516171819public class NoVisibility &#123; private static boolean ready; private static int value; public static class ReaderThread extends Thread&#123; public void run() &#123; while(!ready)&#123; Thread.yield(); &#125; System.out.println(value); &#125; &#125; public static void main(String[] args)&#123; new ReaderThread().start(); value = 10; ready = true; &#125;&#125; 可能会有三种情况出现 程序正常结束，输出10 程序正常结束，输出0 正确无法结束，一直在无限循环。 涉及到的知识点: volatile与Java线程模型 重排序的概念 多线程的环境下重排序导致的问题(可以将两个线程变成一个流程，串行去理解) volatile防止重排序 ✎✎volatile与synchronized 12345678910111213public class Score &#123; public int value; //强制从主存拿value public synchronized int getValue() &#123; return value; &#125; //强制把value刷到主存 public synchronized void setValue(int value) &#123; this.value = value; &#125;&#125; 12345public class Score &#123; public volatile int value; //getter and setter&#125; 上面的两种方式的效果大体相同，但是前者可见性更强（16章会讲）。 volatile不会执行加锁操作，所以开销会比synchronized更小。 ✎✎内部类导致的线程不安全（this引用逸出） 123456789101112public class ThisEscape&#123; public ThisEscape(EventSource source)&#123; source.registerListener( new EventListener()&#123; public void onEvent(Event e)&#123; //doSomething属于ThisEscape doSomething(e); &#125; &#125; ); &#125;&#125; 上述例子中，ThisEscape有可能还没被创建完成，doSomething方法就被调用了。可以使用工厂方法避免这种的错误，如下： 1234567891011121314151617public class SafeListener&#123; private final EventListener listener; private SafeListener()&#123; listener = new EventListener()&#123; public void onEvent(Event e)&#123; //doSomething属于ThisEscape doSomething(e); &#125; &#125;; &#125; public static SafeListener newInstance(EventSource source)&#123; SafeListener safe = new SafeListener(); source.registerListener(safe.listener); return safe; &#125;&#125; 总的思路就是，在构造完对象之前,不能让this逸出。 如果listener对象不是final类型或者volatile类型的，也是属于不安全发布的。 ✎✎✎使用ThreadLocal保证线程安全 12345678910public static ThreadLocal&lt;Integer&gt; value = new ThreadLocal&lt;Integer&gt;()&#123; @Override protected Integer initialValue() &#123; return 0; &#125;&#125;;public static Integer getValue()&#123; return value.get();&#125; ThreadLocal内部用Map结构保存了当前线程（Thread.currentThread()）对应的值。所以每一个线程都有属于自己的value。ThreadLocal变量类似于全局变量，它能降低代码的可重用性。例如将某个全局变量作为ThreadLocal对象。 ✎✎✎✎final final能保证初始化过程中的安全性（如果this引用逸出还能保证安全性吗）。volatile不仅能保证初始化过程中的安全性，还能保证可见性。 final的重排序规则 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。 总的来说就是final在写之前不会被读。 ✎✎✎✎✎对“使用不可变类来实现线程安全”的分析 1234567891011121314151617public static class Cache&#123; private final Integer value; private final Integer[] factors; public Cache(Integer value , Integer[] factors)&#123; this.value = value; this.factors = factors; &#125; public Integer getValue() &#123; return value; &#125; public Integer[] getFactors() &#123; return Arrays.copyOf(factors , factors.length); &#125;&#125; 12345678910111213public static class CacheUtil&#123; private volatile Cache cache = new Cache(null , null); public Integer[] getFactors(Integer i)&#123; Integer[] factors = cache.getFactors(i); if(factors == null)&#123; //因式分解得到factors cache = new Cache(i , factors);//volatile类型的初始化是线程安全的 &#125; return factors; &#125;&#125; 在这个Demo里，线程安全是指Cache类里的value变量与factors变量要保持同步一致，也就是说这两者要能同步初始化，同步更新。由于没有使用DCL，所以可能会出现初始化两次的情况，但是这没关系，因为逻辑就是只保存最新的因式分解结果。CacheUtil的cache变量使用了volatile。volatile保证cache不会失效，以及保证cache的初始化是线程安全的。 ✎✎✎✎✎安全发布一个对象的四种模式 在静态初始化函数中初始化一个对象引用。 将对象的引用保存到volatile或AtomicReferance对象中。 用final修饰对象的引用。 将对象的引用保存到一个由锁保护的域中。 即使this引用逸出，volatile、Atomic、final也会是线程安全的吗？答：逸出绝对是线程不安全的。线程安全的容器类也属于锁保护的域。在构造函数内对一个变量（属于上面4种模式模之一）的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 疑惑 NoVisibilityDemo实际运行的时候，如果加上Thread.yield()，其他线程ready会拿到最新值，而如果去掉Thread.yield()让while无限循环，那么ready则不会取到最新值，这是为什么？ volatile类型能保证long、double的get/set是原子的吗？ 禁止volatile的重排序意义是什么？因为其他类型应该都不是共享的。 ✎✎✎✎✎✎锁假设有锁M，那么在M上调用unlock之前的所有操作结果，对于在M上调用lock之后的线程都是可见的。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Java并发编程实战","slug":"学习笔记/Java/Java并发编程实战","permalink":"http://yoursite.com/categories/学习笔记/Java/Java并发编程实战/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"数据结构Tree的基本应用","slug":"数据结构Tree以及基本应用","date":"2019-02-05T09:55:43.000Z","updated":"2020-01-07T08:21:41.487Z","comments":true,"path":"2019/02/05/数据结构Tree以及基本应用/","link":"","permalink":"http://yoursite.com/2019/02/05/数据结构Tree以及基本应用/","excerpt":"","text":"✎树的基本知识1、树的定义从大体上来说，树可以分为二叉树与N叉树。这两者的区别可以从字面上就能理解出来。二叉树的所有孩子节点小于等于2，而N叉树的所有孩子节点中至少有一个是大于2的。2、树的实现12345678910public class Tree &#123; //根节点 private Node head;&#125;public class Node &#123; public int element; public Node left; public Node right;&#125;3、相关专业术语- 叶子节点：没有子节点（孩子节点）的节点。- 高度/深度：树的最大层次。4、树的遍历：先序/中序/后序遍历后序遍历Demo12345678910public void orderTraverse(Node t)&#123; if(t == null)&#123; return ; &#125; //System.out.println(t.element); 如果在这里（前面）访问元素则是先序遍历 orderTraverse(t.left); //System.out.println(t.element); 如果在这里（中间）访问元素则是中序遍历 orderTraverse(t.right); System.out.println(t.element);&#125; ✎✎哈夫曼树 ✎✎✎二叉搜索树1、定义若其左子树存在，则其左子树中每个节点的值都不大于该节点值；若其右子树存在，则其右子树中每个节点的值都不小于该节点值。2、复杂度二叉搜索树的搜索复杂度与树的深度有关，范围是O(n) ~ O(log n)之间。3、遍历算法可使用中序遍历输出一组有序的值。4、插入算法（假设将元素a插入树B中）- 如果B为空树，则将元素a作为树的根节点。- 否则，比较根节点与a的值，a若比较小则往左子树走，否则往右子树走，递归重复此节点比较过程，直至将a以叶子节点的形式插入到B（a与节点相等时可根据实际情况看作是小于或大于或者直接丢弃都可）5、删除算法（假设删除节点p）- 若p是子节点，则直接删除。- 若p只有一个孩子节点，则删除p，让孩子节点顶替p的位置。- 若p有两个孩子节点，那么删除p，并寻找p的后继顶替p。（p的后继是p的右子树的最左节点。） &gt; 寻找p的前继应该也可以？p的前继是p的左节点，或是p的左节点的右节点。6、查找算法（假设根节点为p，需要查找的元素为a）- 若p = a，则直接返回p。- 若p &lt; a，则往左子树走，否则往右子树走，递归调用此流程。 ✎✎✎平衡二叉树(AVL Tree)1、定义任意一节点的左子树与右子树高度相差不超过1。2、查找、删除、遍历算法平衡二叉树的查找、删除、遍历算法都与二叉搜索树的步骤一样，只是在树结构变化了之后（增加节点或删除节点），需要递归判断是否需要再平衡。3、再平衡当结构处于失衡状态时，就需要再均衡。判断是否处于失衡状态的逻辑是：判断此节点的左右子树高度是否相差超过1，如果是，则处于失衡状态，此节点为失衡点。之后需要判断是处于哪种失衡结构：- LL失衡。需要对结构进行右旋操作。 伪代码实现的实现的简单逻辑为： 12345678910 /** * @param h h为失衡点 */private Node rotateRight(Node h) &#123; Node x = h.left; h.left = x.right; x.right = h; //省略更新高度、更新父节点等。 return x; &#125; 如下图所示： 节点3为失衡点。- RR失衡。需要进行左旋操作。与右旋操作类似，只是操作的“方向”是反的。 伪代码实现的实现的简单逻辑为： 1234567private Node rotateLeft(Node h) &#123; Node x = h.right; h.right = x.left; x.left = h; //省略更新高度、更新父节点等。 return x; &#125;- LR失衡。先执行左旋再执行右旋。 伪代码实现的实现的简单逻辑为： 1234private Node rotateLeftRight(Node h) &#123; h.left = rotateLeft(h.left); return rotateRight(h);&#125; &gt;对平衡点的左节点进行左旋，再对平衡点进行右旋。 如下图示： - RL失衡。先执行右旋再执行左旋。&gt; 第一个字母表示高度较高的子树位置，第二个字母表示锁挂载节点所处于的子树位置。 ✎✎✎2-3树1、定义&gt; 假设父节点为P，左节点为L，中间节点为M，右节点为R。- 所有叶子节点都在同一层。- 2节点：父节点存储一个值，最多有左右两个子树。且L&lt; P &lt; R。- 3节点：父节点存储两个值，最多有左中右三个子树。且L &lt; P1 &lt; M &lt; P2 &lt; R。- 子节点要么为0个，要么大于等于2个。2、插入永远都是在叶子节点处新增节点，插入过程如下图3、删除如果是删除非叶子节点时，那么可以找到它的后继节点（一定会是叶子节点），将后继节点与之交换，再删除（此时就是删除叶子节点了），所以2-3树的删除总归还是会演变成删除叶子节点。删除叶子节点时，如果并没有造成叶子节点在不同层的情况（譬如说删除一个3-节点时），那就直接删除即可。否则就需要用调整树的结构，平衡树保持平衡的做法是，如果是左边比较“矮”，那么就可以把右边的元素往左边挪，反之一样。2-3树的做法以合并父节点的方式、右旋、左旋的方式保持各节点在同一层。以下是几个例子。 ✎✎✎B树 ✎✎✎B+树 ✎✎✎红黑树","categories":[{"name":"个人分享","slug":"个人分享","permalink":"http://yoursite.com/categories/个人分享/"},{"name":"数据结构","slug":"个人分享/数据结构","permalink":"http://yoursite.com/categories/个人分享/数据结构/"},{"name":"树","slug":"个人分享/数据结构/树","permalink":"http://yoursite.com/categories/个人分享/数据结构/树/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://yoursite.com/tags/数据结构/"}]},{"title":"01 | 计算机系统漫游","slug":"深入理解计算机系统_01_计算机系统漫游","date":"2019-01-22T07:44:58.000Z","updated":"2020-01-07T08:21:41.523Z","comments":true,"path":"2019/01/22/深入理解计算机系统_01_计算机系统漫游/","link":"","permalink":"http://yoursite.com/2019/01/22/深入理解计算机系统_01_计算机系统漫游/","excerpt":"","text":"ASCII码字符构成的文件称为文本文件，所有其他文件都称为二进制文件。 源文件翻译成目标文件 #include&lt;stdio.h&gt; int main(){ printf(“hello , world\\n”); return 0;} gcc -o hello hello.c GCC翻译过程可以分为4个阶段图预处理阶段编译阶段汇编阶段链接阶段","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"操作系统","slug":"学习笔记/操作系统","permalink":"http://yoursite.com/categories/学习笔记/操作系统/"},{"name":"深入理解计算机系统","slug":"学习笔记/操作系统/深入理解计算机系统","permalink":"http://yoursite.com/categories/学习笔记/操作系统/深入理解计算机系统/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"07 | 行锁功过：怎么减少行锁对性能的影响","slug":"MySQL实战45讲_07_行锁功过：怎么减少行锁对性能的影响","date":"2019-01-22T06:33:43.000Z","updated":"2020-03-16T12:32:21.398Z","comments":true,"path":"2019/01/22/MySQL实战45讲_07_行锁功过：怎么减少行锁对性能的影响/","link":"","permalink":"http://yoursite.com/2019/01/22/MySQL实战45讲_07_行锁功过：怎么减少行锁对性能的影响/","excerpt":"","text":"MySQL 的行锁是在引擎层由各个引擎自己实现的，不是所有引擎都支持行锁，MyIASM就不支持行锁。 ✎两阶段锁 在InnoDB事务中，行锁是在需要的时候才加上的，但要等到事务结束后才释放。这个就是两阶段锁协议。 innodb行级锁是通过锁索引记录实现的。如果update的列没建索引，即使只update一条记录也会锁定整张表。 比如说update t set t.name=&#39;abc&#39; where t.name=&#39;cde&#39;;这条语句，就会造成表锁，防止update的同时又新插入name为’cde’的记录。但是update t set t.name=&#39;abc&#39; where t.name=&#39;cde&#39; limit 1;这样就变成行锁了。 如果事务中需要锁多个行，要把最可能引起锁冲突、最可能影响并发度的锁尽量往后放。 总的来说就是尽量减少持有行锁的时间。 ✎✎死锁与死锁检测 1、死锁解决策略 设置innodb_lock_wait_timeout。（锁等待最长时间，默认为50S） 设置innodb_deadlock_detect为on（默认为on），开启死锁检测逻辑：发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。 死锁检测过程：每当一个事务被锁的时候，需要看看它锁依赖的线程有无被别人锁住，如此循环，最后判断是否有出现循环等待。假设有1000个线程同时更新同一行时，死锁检测就是100万这个量级的。 ✎✎✎如何解决热点行更新导致的性能问题 确保这个业务一定不会出现死锁，可以临时把死锁关掉（有一定风险）。 控制并发度： 从客户端上控制并发度，比如说设置10个并发，但这样需要确保客户端不能有很多。 从服务端上控制并发度，这个比较困难。要修改MYSQL源码，或者在中间件实现。 从设计上优化这个问题：比如说剩余数量这一行，可以分为10行。统计的时候去统计这10行的和，写的时候随机写入其中一行，这样可以把冲突降低为原来的10分之1。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"MySQL","slug":"学习笔记/MySQL","permalink":"http://yoursite.com/categories/学习笔记/MySQL/"},{"name":"MySQL实战45讲","slug":"学习笔记/MySQL/MySQL实战45讲","permalink":"http://yoursite.com/categories/学习笔记/MySQL/MySQL实战45讲/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"01 | Java代码是怎么运行的？","slug":"深入拆解Java虚拟机_01_Java代码是怎么运行的？","date":"2019-01-09T08:43:43.000Z","updated":"2020-01-07T08:21:41.490Z","comments":true,"path":"2019/01/09/深入拆解Java虚拟机_01_Java代码是怎么运行的？/","link":"","permalink":"http://yoursite.com/2019/01/09/深入拆解Java虚拟机_01_Java代码是怎么运行的？/","excerpt":"","text":"JRE就是Java运行时环境。JRE包括了Java虚拟机以及Java核心类库。 Java虚拟机内存划分本地方法是用C++写的native方法。PC寄存器存放各个线程的执行位置。 Java 虚拟机具体是怎样运行Java字节码的？虚拟机视角：执行Java代码首先需要将它编译而成的class文件加载到Java虚拟机中，加载后的Java类会被存放于方法区（Method Area）中。在运行过程中，每当调用进入一个Java方法，Java虚拟机会在当前线程的Java方法栈中生成一个栈帧，用以存放局部变量以及字节码的操作数。这个栈帧的大小是提前计算好的，而且Java虚拟机不要求栈帧在内存空间里连续分布。当退出当前执行的方法时，不管是正常返回还是异常返回，Java虚拟机均会弹出当前线程的当前栈帧，并将之舍弃。硬件视角：HotSpot默认采用混合模式，综合了解释执行和即时编译两者的优点。它会先解释执行字节码，而后将其中反复执行的热点代码，以方法为单位进行即时编译。 使用asmtools.jar在查看在虚拟机中boolean类型的表示方式public class Test3 { public static void main(String[] args) { boolean flag = true; if(flag) System.out.println(&quot;Hello , Java&quot;); if(flag == true) System.out.println(&quot;Hello ,Jvm&quot;); } }在idea中生成这段java代码的class文件Test3.class。 生成jasm文件java -jar asmtools.jar jdis Test3.class &gt;&gt;Test.jasm super public class Test3 version 49:0{ public Method ““:”()V” stack 1 locals 1{ aload_0; invokespecial Method java/lang/Object.”“:”()V”; return; } public static Method main:”([Ljava/lang/String;)V” stack 2 locals 2{ iconst_1;//改为iconst_2 istore_1; iload_1; ifeq L14; getstatic Field java/lang/System.out:”Ljava/io/PrintStream;”; ldc String “Hello , Java”; invokevirtual Method java/io/PrintStream.println:”(Ljava/lang/String;)V”; L14: iload_1; iconst_1; if_icmpne L27; getstatic Field java/lang/System.out:”Ljava/io/PrintStream;”; ldc String “Hello ,Jvm”; invokevirtual Method java/io/PrintStream.println:”(Ljava/lang/String;)V”; L27: return; } } // end Class Test3将iconst_1改为iconst_2，如上注释所示。 执行如下命令重新自动生成Test3.classjava -jar asmtools.jar jasm Test.jasm 在idea打开重新生成的Test3.class，可以很清楚的看到虚拟机是把boolean当做int来处理的。public class Test3 { public Test3() { } public static void main(String[] var0) { byte var1 = 2; if (var1 != 0) { System.out.println(&quot;Hello , Java&quot;); } if (var1 == 1) { System.out.println(&quot;Hello ,Jvm&quot;); } } }","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java虚拟机","slug":"学习笔记/Java虚拟机","permalink":"http://yoursite.com/categories/学习笔记/Java虚拟机/"},{"name":"深入拆解Java虚拟机","slug":"学习笔记/Java虚拟机/深入拆解Java虚拟机","permalink":"http://yoursite.com/categories/学习笔记/Java虚拟机/深入拆解Java虚拟机/"}],"tags":[{"name":"Java虚拟机","slug":"Java虚拟机","permalink":"http://yoursite.com/tags/Java虚拟机/"}]},{"title":"06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？","slug":"MySQL实战45讲_06_全局锁和表锁 ：给表加个字段怎么有这么多阻碍？","date":"2019-01-09T06:43:43.000Z","updated":"2020-01-07T08:21:41.432Z","comments":true,"path":"2019/01/09/MySQL实战45讲_06_全局锁和表锁 ：给表加个字段怎么有这么多阻碍？/","link":"","permalink":"http://yoursite.com/2019/01/09/MySQL实战45讲_06_全局锁和表锁 ：给表加个字段怎么有这么多阻碍？/","excerpt":"","text":"Mysql锁类型 全局锁 表级锁 行锁 全局锁 加全局表锁（让整个数据库处于只读状态）的方法：Flush tables with read lock (FTWRL)，其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。使用场景：做全库备份时。 其他的设置只读的方法： 利用mysqldump工具的-single-transaction参数。导数据之前就会开启一个事务，确保拿到一个一致性视图（类似RR隔离级别的实现原理）。缺点就是有些引擎是不支持事务的。 set global readonly = true。这样也可以让全库进入只读状态，但是有如下缺点： 有些系统中，readonly会被用来作其他逻辑。比如判断一个库是主库还是从库。 如果在执行FTWRL时，客户端发生异常，锁会被释放。但set global readonly = true是不会释放锁的。 表级锁表级锁的类型 表锁。 元数据锁（meta data lock,MDL）。 表锁12#锁表lock tables ... read/write 12#释放锁unlock tables 如果一个线程对表A加了read lock，那么所有线程都只能读表A而不能写入表A。如果一个线程对表A加了write lock，那么只能这个线程能写、读表A。其他线程对表A的写、读都会被阻塞。 MDL不需要显示使用，对一个表做增删改查操作时，自动加MDL读锁。对表做结构变更操作时，加MDL写锁。读/读不互斥，读/写，写/写互斥。（也就是我们平常认知里的读写锁）","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"MySQL","slug":"学习笔记/MySQL","permalink":"http://yoursite.com/categories/学习笔记/MySQL/"},{"name":"MySQL实战45讲","slug":"学习笔记/MySQL/MySQL实战45讲","permalink":"http://yoursite.com/categories/学习笔记/MySQL/MySQL实战45讲/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"05 | 深入浅出索引（下）","slug":"MySQL实战45讲_05_深入浅出索引（下）","date":"2019-01-08T08:43:43.000Z","updated":"2020-01-07T08:21:41.429Z","comments":true,"path":"2019/01/08/MySQL实战45讲_05_深入浅出索引（下）/","link":"","permalink":"http://yoursite.com/2019/01/08/MySQL实战45讲_05_深入浅出索引（下）/","excerpt":"","text":"覆盖索引假设现在t_person表如下： 主键 索引 普通字段 普通字段 id name age ismale 12#以下语句会导致回表select * from t_person where name = 'a'; 12#以下将不会导致回表,这就叫做覆盖索引select id from t_person where name = 'a'; 如果有很高频的通过name来找age这样的请求，我们也可以为name与age作联合索引，这样也可以避免回表。 索引下推假设现在给加了索引(name , age)那么下面语句将会先过滤，减少回表次数 1select * from t_user where name like '张%' and age = 10 and ismale = 1 ;","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"MySQL","slug":"学习笔记/MySQL","permalink":"http://yoursite.com/categories/学习笔记/MySQL/"},{"name":"MySQL实战45讲","slug":"学习笔记/MySQL/MySQL实战45讲","permalink":"http://yoursite.com/categories/学习笔记/MySQL/MySQL实战45讲/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"04 | 深入浅出索引（上）","slug":"MySQL实战45讲_04_深入浅出索引（上）","date":"2019-01-08T06:22:43.000Z","updated":"2020-01-07T08:21:41.427Z","comments":true,"path":"2019/01/08/MySQL实战45讲_04_深入浅出索引（上）/","link":"","permalink":"http://yoursite.com/2019/01/08/MySQL实战45讲_04_深入浅出索引（上）/","excerpt":"","text":"索引的常见模型 哈希表。适合插入数据与做等值查询，不适合做区间查询。 有序数组。适合做等值查询与区间查询（使用二分法），不适合插入数据。所以这种适合做静态存储引擎。 搜索树。二叉搜索树-&gt;平衡二叉树-&gt;N叉树（B+树） 二叉搜索树：左孩子节点 &lt; 父节点 &lt; 右孩子节点 平衡二叉树：左右两棵子树的高度差绝对值不超过1，并且左右两棵子树都是平衡二叉树。（维持 O(log(N)) 的查询复杂度） N叉树：（为了查询尽量少地读磁盘）。 InnoDB的索引模型 索引类型分为主键索引与非主键索引。 主键索引的叶子节点存的是整行数据。在Innodb中，主键索引也称为聚簇索引。 非主键索引叶子节点存的是主键的值。非主键索引也称为二级索引。 主键索引与非主键索引查询的区别 主键索引只用扫描一棵树就可以查询到行的数据。 非主键索引比主键索引要多扫描一棵树。（回表） 没有主键的表，innodb会给默认创建一个Rowid做主键。 索引的维护B+树的插入可能会引起数据页的分裂，删除可能会引起数据页的合并，二者都是比较重的IO消耗，所以比较好的方式是顺序插入数据，这也是我们一般使用自增主键的原因之一。 主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以不适合用业务字段（如身份证）做主键。但是如果一张表只有一个唯一索引，那么可以用业务字段作主键。 MyISAM的索引结构是“堆组织表”，非主键索引上叶子节点存的是行的地址而不是主键。这样使用非主键索引进行查询时，就不需要回表。但是如果行数据的位置被修改了，就会很麻烦。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"MySQL","slug":"学习笔记/MySQL","permalink":"http://yoursite.com/categories/学习笔记/MySQL/"},{"name":"MySQL实战45讲","slug":"学习笔记/MySQL/MySQL实战45讲","permalink":"http://yoursite.com/categories/学习笔记/MySQL/MySQL实战45讲/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"记于12月19日","slug":"记于12月19日","date":"2018-12-19T14:43:41.000Z","updated":"2020-01-07T08:21:41.535Z","comments":true,"path":"2018/12/19/记于12月19日/","link":"","permalink":"http://yoursite.com/2018/12/19/记于12月19日/","excerpt":"","text":"由于年底比较忙，所以提前写个年终小总结吧。 今年对于我来讲是非常黑暗的一年，感谢自己竟然挺了过来，虽然2018年快过去了，还没找回自己最好的状态，但是比年初好多了。 从个人技术规划来说，年初定的是5本技术书籍的读书笔记，但今年一整年已经完成15本了，所以这方面，完成的还是比较好的。然而，越读越觉得自己太渺小了，犹如浩瀚宇宙，只窥了一角。 但是其他方面确实完成的不尽人意， 定的500KM跑步总量，结果只坚持了几天就没坚持了。 音乐方面，本来目标是自学完乐理然后写一首歌，现在乐理也仅仅过了一遍，连入门都还不到，遑论写歌了。 之前有个目标，想在25岁前自己独立完成一款游戏，包括音乐、程序 、美术。然而越接触越觉得自己是多么渺小啊。人生多么渺小啊。这段游戏路程，我才走了一半还不到。 音乐、程序、美术任一方面要达到可以拿出来的水准，每一方面可能都要花很长的时间，何况我还经常偷懒。有时候我还在想，是不是我的游戏到50岁都出不来[笑]。但人生有梦，应该可以让我以后的墓志铭写得更精彩吧。","categories":[{"name":"心情杂文","slug":"心情杂文","permalink":"http://yoursite.com/categories/心情杂文/"}],"tags":[]},{"title":"03 | 事务隔离：为什么你改了我还看不见？","slug":"MySQL实战45讲_03_事务隔离：为什么你改了我还看不见？","date":"2018-12-08T15:25:43.000Z","updated":"2020-01-07T08:21:41.423Z","comments":true,"path":"2018/12/08/MySQL实战45讲_03_事务隔离：为什么你改了我还看不见？/","link":"","permalink":"http://yoursite.com/2018/12/08/MySQL实战45讲_03_事务隔离：为什么你改了我还看不见？/","excerpt":"","text":"概要：主要介绍了四种隔离级别。 ✎事务1、事务的四大特性（ACID） 原子性（Atomicity） 一致性（Consistency） 隔离性（Isolation） 持久性（Durability） 2、多个事务可能会导致的问题： 脏读(dirty read)。事务A读到了事务B未提交的数据。 不可重复读(non-repeatable read)。事务A第一次查询得到一行记录row1，事务B提交修改后，事务A第二次查询得到row1，但列内容发生了变化。 幻读(phantom read)。事务A第一次查询得到一行记录row1，事务B增加一条记录row2并提交修改后，事务A第二次查询得到两行记录row1和row2。 ✎✎隔离级别1、隔离级别的分类 读未提交(read uncommitted)：一个事务还没提交时，它锁做的变更能被别的事务看到。 读提交(read committed)：一个事务提交后，它做的变更才能被其他事务看到。 可重复读(repeatable read)：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。且未提交变更对其他事务不可见。 串行化(serializable)：对同一行记录，会加读写锁。 2、隔离级别的区别 v1 v2 v3 读未提交 2 2 2 读提交 1 2 2 可重复读 1 1 2 串行化 1 1 2 这样来看串行化更像是读写都是同一把锁，但是后面作者在评论上又说读读不互斥。 3、隔离级别的实现 读未提交：直接返回记录上的最新值。（这个最新值从InnoDB buffer pool读取） 读提交：每个SQL语句开始执行时创建一个视图。 可重复读：事务启动时创建一个视图，整个事务存在期间都使用此视图。 串行化：加锁的方式。 4、数据库默认的隔离级别Oracle：读提交(read committed)。Mysql：可重复读(repeatable read)。 5、设置Mysql的隔离级别 全局修改。修改mysql.ini配置文件： 12#可选参数有:READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLE.transaction-isolation = REPEATABLE-READ 当前session修改。 1set session transaction isolation level read uncommitted; 6、查看全局与当前session隔离级别12SELECT @@global.tx_isolation; SELECT @@session.tx_isolation; 7、可重复读隔离级别的实现每个事务在启动时都会创建一个视图，每条记录在更新时都会记录一条回滚操作，事务A将1改成2,事务B将2改成3，事务C将3改成4。此时为了保证事务前后读取都是一致的，就得保存回滚段。所以如果使用长事务，回滚段就会变得非常长。当事务A提交或回滚后，回滚段会被相应删除一部分。所以尽量别使用长事务，否则会吃内存。因为长事务会在内存保存许多回滚记录。 8、事务提交方式 显示启动事务语句。begin或start transaction，配套的提交语句时commit，回滚语句时rollback。(事务并不是在beain就启动的，而是在之后的第一个DML语句才启动。) set autocommit=0。意味着在只执行一个select语句的时候，这个事务就启动了，且不会自动提交，直到主动执行commit或rollback语句，或者断开连接。（自动提交的意思是“在没有begin或start transaction 的时候”，自动提交。） commit work and chain语句可以在提交commit后，立刻执行begin,减少客户端与Mysql的交互次数。 9、查询长事务1select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60 疑问： rr隔离如何利用gap锁防止幻读。 rr隔离与串行化隔离的优劣。 rr隔离、mvcc、快照、视图这几个之间的关系。 可重复读实现原理https://www.jianshu.com/p/17967b72139a","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"MySQL","slug":"学习笔记/MySQL","permalink":"http://yoursite.com/categories/学习笔记/MySQL/"},{"name":"MySQL实战45讲","slug":"学习笔记/MySQL/MySQL实战45讲","permalink":"http://yoursite.com/categories/学习笔记/MySQL/MySQL实战45讲/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"02 | 日志系统：一条SQL更新语句是如何执行的？","slug":"MySQL实战45讲_02_日志系统：一条SQL更新语句是如何执行的？","date":"2018-12-08T14:30:46.000Z","updated":"2020-01-07T08:21:41.417Z","comments":true,"path":"2018/12/08/MySQL实战45讲_02_日志系统：一条SQL更新语句是如何执行的？/","link":"","permalink":"http://yoursite.com/2018/12/08/MySQL实战45讲_02_日志系统：一条SQL更新语句是如何执行的？/","excerpt":"","text":"概要：主要介绍了redolog与Binlog的机制与区别 ✎Redo Log1、原理redo log是InnoDB引擎特有的日志，它使用了 WAL（Write-Ahead Logging）技术，即先写日志，再写磁盘。 2、更新过程当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面。 3、redo log的日志文件InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB： write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。write pos和checkpoint之间空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。 ✎✎BinLogbinlog（归档日志）是属于Server层的日志，只能用于归档，没有crash-safe的能力。1、Binlog的两种模式 statement 格式：是记sql语句。 row格式：记录行的内容。 思考：为什么Binlog不具备crash-safe的能力，该怎么从数据层面去理解。 ✎✎✎两种日志的不同点 redo log是InnoDB引擎特有的，而binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”，binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1”。 redo log是循环写的，空间color =固定会用完。binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 ✎✎✎✎Update时的执行流程 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 ✎✎✎✎✎两阶段提交将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是”两阶段提交”。 两阶段提交是为了让redo log与binlog的数据状态保持一致。 ✎✎✎✎✎✎参数设置innodb_flush_log_at_trx_commit： 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。（建议设置为1）sync_binlog ：这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。（建议设置为1）","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"MySQL","slug":"学习笔记/MySQL","permalink":"http://yoursite.com/categories/学习笔记/MySQL/"},{"name":"MySQL实战45讲","slug":"学习笔记/MySQL/MySQL实战45讲","permalink":"http://yoursite.com/categories/学习笔记/MySQL/MySQL实战45讲/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"01 | 基础架构：一条SQL查询语句是如何执行的？","slug":"MySQL实战45讲_01_基础架构：一条SQL查询语句是如何执行的？","date":"2018-12-02T16:15:46.000Z","updated":"2020-01-07T08:21:41.410Z","comments":true,"path":"2018/12/03/MySQL实战45讲_01_基础架构：一条SQL查询语句是如何执行的？/","link":"","permalink":"http://yoursite.com/2018/12/03/MySQL实战45讲_01_基础架构：一条SQL查询语句是如何执行的？/","excerpt":"","text":"✎MySQL的逻辑架构图 MySQL 可以分为 Server 层和存储引擎层两部分。 存储引擎是插件式的，MySQL5.5.5版本之后默认的存储引擎是InnoDB。 ✎✎连接器用以下命令可以登录Mysql。 1mysql -h 127.0.0.1 -P 3306 -u root -p database_name 之后需要输入你的密码即可。 一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。 以下命令查看有哪些空闲连接： 1show processlist; 长时间没操作时，连接会断开，这个时间默认为8小时，是由wait_timeout控制的。 ✎✎✎长连接1、弊端 但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。 2、解决方案 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 思考：客户端每次查询用的是不同的连接吗？什么情况下的操作占用内存比较大？怎么查看MYSQL占用的内存，以及内存上限？怎么reset connection？ ✎✎✎✎查询缓存8.0版本后就没有这个功能了。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"MySQL","slug":"学习笔记/MySQL","permalink":"http://yoursite.com/categories/学习笔记/MySQL/"},{"name":"MySQL实战45讲","slug":"学习笔记/MySQL/MySQL实战45讲","permalink":"http://yoursite.com/categories/学习笔记/MySQL/MySQL实战45讲/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"深入浅出Spring Boot 2.x（三）","slug":"深入浅出Spring Boot 2.x（三）","date":"2018-12-02T15:58:46.000Z","updated":"2020-01-07T08:21:41.493Z","comments":true,"path":"2018/12/02/深入浅出Spring Boot 2.x（三）/","link":"","permalink":"http://yoursite.com/2018/12/02/深入浅出Spring Boot 2.x（三）/","excerpt":"","text":"@Configuration12345678910@Configurationpublic class AppConfig &#123; @Bean(name = \"user\") public User initUser()&#123; User user = new User(); user.setName(\"hjl\"); return user; &#125;&#125; @Configuration代表这是一个Java配置文件。如果没有配置@Bean的name属性，那么方法名”initUser”将作为Bean的名称保存到IOC容器。UnitTest 12345public static void main(String[] args) &#123; ApplicationContext ctx = new AnnotationConfigApplicationContext(AppConfig.class); User user = ctx.getBean(User.class); System.out.println(user.getName());&#125; @ComponentScan12345@Configuration@ComponentScanpublic class AppConfig &#123; &#125; 默认情况下只会扫描AppConfig所在的当前包和子包。也可以自定义扫描的范围： 12345@Configuration(&quot;com.hjl.demo.springboot.*&quot;)@Configuration(basePackges = &#123;&quot;com.hjl.demo.springboot.pojo&quot;&#125;)@Configuration(basePackageClasses = &#123;User.class&#125;)","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"深入浅出Spring Boot 2.x","slug":"学习笔记/Java/Spring/深入浅出Spring-Boot-2-x","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/深入浅出Spring-Boot-2-x/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://yoursite.com/tags/Spring-Boot/"}]},{"title":"深入浅出Spring Boot 2.x（二）","slug":"深入浅出Spring Boot 2.x（二）","date":"2018-11-27T17:28:46.000Z","updated":"2020-01-07T08:21:41.494Z","comments":true,"path":"2018/11/28/深入浅出Spring Boot 2.x（二）/","link":"","permalink":"http://yoursite.com/2018/11/28/深入浅出Spring Boot 2.x（二）/","excerpt":"","text":"概要： SpringBoot参数的相关说明 与配置有关的注解的关系说明 SpringBoot的默认配置文件是classpath下的application.properties。 如果要改服务器端口，只需要在application.properties加上以下配置即可。 1server.port = 8090 加载参数的优先级顺序 命令行参数 来自java:comp/env的JNDI属性 Java系统属性（System.getProperties()） 操作系统环境变量 RandomValuePropertySource配置的random.*属性值 jar包外部的application-{profile}.properties或application.yml（带spring.profile）配置文件 jar包内部的application-{profile}.properties或application.ym（带spring.profile）配置文件 jar包外部的application.properties或application.yml（不带spring.profile）配置文件 jar包内部的application.properties或application.ym（不带spring.profile）配置文件 @Configuration注解类上的@PropertySource 通过SpringApplication.setDefaultProperties指定的默认属性 常见配置注解的关系@SpringBootApplication包含了以下三个注解： @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan 而@SpringBootConfiguration又包含了@Configuration注解。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"深入浅出Spring Boot 2.x","slug":"学习笔记/Java/Spring/深入浅出Spring-Boot-2-x","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/深入浅出Spring-Boot-2-x/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://yoursite.com/tags/Spring-Boot/"}]},{"title":"深入浅出Spring Boot 2.x（一）","slug":"深入浅出Spring Boot 2.x（一）","date":"2018-11-26T05:45:46.000Z","updated":"2020-01-07T08:21:41.493Z","comments":true,"path":"2018/11/26/深入浅出Spring Boot 2.x（一）/","link":"","permalink":"http://yoursite.com/2018/11/26/深入浅出Spring Boot 2.x（一）/","excerpt":"","text":"概要：SpringBoot的快速搭建运行Demo。 Servlet3.0后，Web容器可以脱离web.xml的部署，可以完全基于注解开发。 Spring Boot运行Demo maven结构 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--测试包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--web开发包，包含spring mvc，且内嵌tomcat--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--aop包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;!--引入插件--&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; java代码 123456789101112131415161718@Controller@EnableAutoConfigurationpublic class Application &#123; @RequestMapping(\"/test\") @ResponseBody public Map&lt;String,String&gt; test()&#123; Map&lt;String,String&gt; map = new HashMap&lt;String,String&gt;(); map.put(\"name\",\"joke\"); return map; &#125; public static void main(String[] args) &#123; SpringApplication.run(Application.class,args); &#125;&#125; 之后访问 1http://localhost:8080/test 就可以看到返回参数了，非常之简单。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Java","slug":"学习笔记/Java","permalink":"http://yoursite.com/categories/学习笔记/Java/"},{"name":"Spring","slug":"学习笔记/Java/Spring","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/"},{"name":"深入浅出Spring Boot 2.x","slug":"学习笔记/Java/Spring/深入浅出Spring-Boot-2-x","permalink":"http://yoursite.com/categories/学习笔记/Java/Spring/深入浅出Spring-Boot-2-x/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://yoursite.com/tags/Spring-Boot/"}]},{"title":"鸟哥的Linux私房菜基础学习篇（六）学习笔记","slug":"鸟哥的Linux私房菜基础学习篇（六）","date":"2018-11-17T13:13:46.000Z","updated":"2020-01-07T08:21:41.539Z","comments":true,"path":"2018/11/17/鸟哥的Linux私房菜基础学习篇（六）/","link":"","permalink":"http://yoursite.com/2018/11/17/鸟哥的Linux私房菜基础学习篇（六）/","excerpt":"","text":"概要： 文件所有者、用户组、其他人的相关概念 权限的相关操作 权限对于目录与文件的意义 文件所有者（User）、用户组（Group）、其他人（Others） 账号记录在/etc/passwd 组名记录在/etc/group 密码记录在/ect/shadow ls -al 可以查看所有文件的权限与属性（包括隐藏文件）执行命令后的结果如下(部分) 1234567huangjunlong@ubuntu:~$ ls -altotal 84drwxr-xr-x 14 huangjunlong huangjunlong 4096 Nov 18 05:03 .drwxr-xr-x 3 root root 4096 Nov 15 08:54 ..-rw-r--r-- 1 huangjunlong huangjunlong 220 Nov 15 08:54 .bash_logout-rw-r--r-- 1 huangjunlong huangjunlong 3771 Nov 15 08:54 .bashrcdrwx------ 13 huangjunlong huangjunlong 4096 Nov 17 06:27 .cache 我们以.cache为例对属性的结构进行分析： 属性 含义 drwx—— 文件类型与权限 13 连接数 huangjunlong 文件所有者 huangjunlong 文件所属组 4096 文件大小（默认单位为B） Nov 17 06:27 文件最后被修改的时间（如果距离太久，就仅显示年份） .cache 文件名（文件名前面多一个“.”则代表这个文件是隐藏文件） 我们需要重点关注的是文件类型与权限这一块，它由10个字符组成，其中： 第1个字符表示文件类型，具体的代号表示如下 代号 含义 d 目录 - 文件 l 连接文件（linkfile） b 设备文件里面的可供存储的接口设备 c 设备文件里面的串行端口设备 接下来的9个字符表示文件权限，可以分为3组，依次是 文件所有者的权限 同用户组的权限 其他非本用户组的权限 权限由rwx的组合构成，分别表示 可读 可写 可执行 浏览时如果想要显示完整的时间格式可以加上full-time参数，如下 123huangjunlong@ubuntu:~/Desktop$ ls -l --full-timetotal 4drwxr-xr-- 2 root root 4096 2018-11-18 06:08:22.190687227 -0800 hello 改变文件属性与权限chgrp：改变文件所属用户组 切换到root用户，将test.txt这个文件的用户组改为root，如下 1root@ubuntu:/home/huangjunlong/Desktop# chgrp root test.txt chown：改变文件所有者，也可以改变文件所属用户组。 将test.txt这个文件的用户组与文件所有者都改为huangjunlong，如下 1root@ubuntu:/home/huangjunlong/Desktop# chown huangjunlong:huangjunlong test.txt 单纯的将test.txt这个文件的用户组改为root，如下 1root@ubuntu:/home/huangjunlong/Desktop# chown :root test.txt chmod：改变文件权限。 注意：复制文件时，会把文件的属性也一起复制，所以要关注权限是否需要更改的问题。 如果改变的是目录，加上-R选项可以递归修改子目录下的所有文件、目录。 设置权限的方法有两种： 数字类型其中4代表r，2代表w，1代表x。 将hello.txt文件的权限全部开启，也就是设置为rwxrwxrwx： 1huangjunlong@ubuntu:~$ chmod 777 hello.txt 符号类型u代表user，g代表group，o代表others，a代表全部。可以用+、-、=这三个符号来赋值： 利用“=”将hello.text的文件设置为rwxr-xr-x： 1huangjunlong@ubuntu:~$ chmod u=rwx,go=rx hello.txt 利用“+”给hello.text加上w权限，对所有人生效： 1huangjunlong@ubuntu:~$ chmod a+x hello.txt 利用“-”给hello.text减去x权限，对所有人生效： 1huangjunlong@ubuntu:~$ chmod a-x hello.txt 权限对目录与文件的意义从文件的角度上来说，理解rwx不难。 但从目录的角度来说还是有点区别的： r代表可以用ls浏览目录下的内容。 w代表对该目录下的文件/目录有增删改的权限。 x代表可以进入该目录。 其中x是执行rw的前提。上面的知识可以得到一个很重要的知识点，如果要删除一个文件，设置文件本身的权限是没有用的，需要设置它所在目录的权限为wx才行。 文件长度限制单一文件或者目录的最长文件名为255个字符。 包含完整路径名的文件或目录的最长文件名为4096个字符。 目录的表示 .代表当前目录，也可以用./来表示。 ..代表上一层目录，也可以用../来表示。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Linux","slug":"学习笔记/Linux","permalink":"http://yoursite.com/categories/学习笔记/Linux/"},{"name":"鸟哥的Linux私房菜基础学习篇","slug":"学习笔记/Linux/鸟哥的Linux私房菜基础学习篇","permalink":"http://yoursite.com/categories/学习笔记/Linux/鸟哥的Linux私房菜基础学习篇/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"鸟哥的Linux私房菜基础学习篇（五）学习笔记","slug":"鸟哥的Linux私房菜基础学习篇（五）","date":"2018-11-14T16:41:46.000Z","updated":"2020-01-07T08:21:41.535Z","comments":true,"path":"2018/11/15/鸟哥的Linux私房菜基础学习篇（五）/","link":"","permalink":"http://yoursite.com/2018/11/15/鸟哥的Linux私房菜基础学习篇（五）/","excerpt":"","text":"前言：由于第一章到第四章主要是在介绍Linux以及如何装Linux，所以先暂时略过，直接跳到第五章。 概要：本章主要介绍了关于man、info查找命令的技巧。倡导大家不需要背命令，而是利用Linux的man、Info命令去寻找自己所需要的命令。除此之外，还介绍了关于关机与重启的命令以及Linux的几个Run Level。 特别说明：本章读书笔记（以及接下来的章节）的Demo运行在Ubuntu18.04.1（截至2018.11.12为止是最新版本）上，username为huangjunlong。 ~ 、$、 #的区别Linux用户可以分为root（超级用户）与一般用户。 当用一般用户登录时，命令行会显示$，如下： 1huangjunlong@ubuntu:~$ 如果是root登录则会显示#，如下： 1root@ubuntu:/home/huangjunlong# ~则表示当前用户的主目录，它是一个“变量”。每个Linux用户都有自己的主文件夹，huangjunlong这个账户的主文件夹就是 1/home/huangjunlong cd到这个路径，当我们用huangjunlong这个账户登录时，它会显示~，此时我们也可以通过以下命令进入主目录。 1cd ~ Run Levellinux一共有7个level，分别是0~6。 在/etc这个目录下，以下目录分别存放了0~6七个运行级别的初始化文件。 1rc0.d/ rc1.d/ rc2.d/ rc3.d/ rc4.d/ rc5.d/ rc6.d/ run level的部分含义如下： run level 含义 0 关机 3 纯命令行模式 5 含有图形界面模式 6 重启 可以使用runlevel命令查询当前的runlevel，如下： 12root@ubuntu:/etc# runlevelN 5 也可以使用init命令切换runlevel，如下： 1root@ubuntu:/etc# init 0 //表示关机 其他命令注销命令 1huangjunlong@ubuntu:~$ exit 显示目前的语言 12root@ubuntu:/etc# echo $LANGen_US.UTF-8 修改语言 1huangjunlong@ubuntu:~$ LANG=en_US //只对这次登录有效 显示日期与时间 123456huangjunlong@ubuntu:~$ dateMon Nov 12 01:54:29 PST 2018huangjunlong@ubuntu:~$ date +%Y/%m/%d2018/11/12huangjunlong@ubuntu:~$ date +%H:%M01:57 显示日历 计算器 123456789huangjunlong@ubuntu:~$ bcbc 1.07.1Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006, 2008, 2012-2017 Free Software Foundation, Inc.This is free software with ABSOLUTELY NO WARRANTY.For details type `warranty&apos;. 1+2310%31 manman的作用是查看某个命令的详细说明，如下： 123huangjunlong@ubuntu:~$ man lsLS(1) User Commands LS(1)....&lt;内容太长，省略参数的描述，具体可以看下表&gt; 代号 内容说明 NAME 简短的命令、数据名称说明 SYNOPSIS 简短的命令执行语法（syntax）简介 DESCRIPTION 较为完整的说明 OPTIONS 针对SYNOPSIS部分中，有列举的所有可用的选项说明 COMMADS 当这个程序在执行时，可以在此程序执行的命令 FILES 这个程序或数据所使用或参考或连接到的某些文件 SEEALSO 这个命令有关的其他说明 EXAMPLE 一些可以参考的例子 BUGS 是否有相关错误 上面LS(1)中的“1”有特殊的意义。比较重要的几个数字的意义如下： 代号 代表内容 1 用户在shell环境中可以操作的命令或可执行文件 5 配置文件或者某些文件的格式 8 系统管理员可用的管理命令 进入man界面后，按“空格”可以浏览下一页，也可以按“q”离开man环境。 查询与某个命令相关的信息，如下： 123huangjunlong@ubuntu:~$ man -f manman (1) - an interface to the on-line reference manualsman (7) - macros to format man pages 此时man有两个命令，如果用 1man man 那么会显示man(1)这个命令的相关信息，因为先查询到的说明文件会被先显示出来。如果用 1man 7 man 则会显示man(7)这个命令的相关信息 如果希望某个关键字存在(无论是命令还是说明)就被查出来，就加上-k参数，如下 12345huangjunlong@ubuntu:~$ man -k manHEAD (1p) - Simple command line user agentUPower (7) - System-wide Power Managementaccessdb (8) - dumps the content of a man-db database in a human rea...&lt;省略...&gt; 另外，whatis命令相当于man -f，apropos命令相当于man -k原书上说使用这两个命令需要通过以下命令创建whatis数据库 1makewhatis 但是经过试验，在Ubuntu18.04.1版本中不需要创建数据库也可以直接用这两个命令。 nanonano命令可以浏览文件，如下 1huangjunlong@ubuntu:~/Desktop$ nano test.txt 打开文件后的底部有如下信息 其中^表示[ctrl]。 关机与重启关机与重启前，最好先查看一下系统的一些状态看下是否需要做一些应对的措施，以免发生一些不必要的错误。 who命令可以查看有谁在线： 123huangjunlong@ubuntu:~/Desktop$ whohuangjunlong :0 2018-11-12 01:27 (:0)huangjunlong pts/1 2018-11-12 01:46 (192.168.220.1) nestat -a 可以查看网络的联机状态： 12huangjunlong@ubuntu:~/Desktop$ netstat -a | grep 8080 //把与8080有关的端口显示出来unix 3 [ ] STREAM CONNECTED 28080 /var/run/dbus/system_bus_socket ps -aux 可以查看后台执行的程序： 12huangjunlong@ubuntu:~/Desktop$ ps -aux | grep tomcat //把与tomcat有关的程序显示出来huangju+ 3877 0.0 0.1 21536 1028 pts/0 S+ 04:36 0:00 grep --color=auto tomcat sync可以强制将数据写回硬盘如果数据从硬盘加载到内存中，操作完了立刻写回硬盘去，那么在读写很频繁的时候，性能会大大降低。所以加载到内存的数据不会立刻写回硬盘中。但这样也有风险，万一系统意外关机了，那么数据有可能会丢失。而sync命令就是强制将内存中尚未更新的数据写回硬盘。在执行关机操作时，最好先调用此命令。 实现关机或重启的基础命令有3个 命令 含义 reboot 重新启动 halt 关机，但并不关闭电源 powerff 关机，并关闭电源 通过--help参数查看上面三个命令，发现这三个命令通过参数是可以相互转换的。举个例子，我们看一下halt的帮助文档来证实上面的言论： 同样的，我们根据shutdown --help可知，shutdown命令可以通过不同的参数调用上面的3个命令实现关机或重启，那shutdown与它们之间有什么区别与联系呢？ shutdown会关闭系统各项服务后再执行reboot/halt/poweroff，可以理解为“安全关机”。 reboot/halt/poweroff在没有加参数--force的情况下，会调用shutdown关闭各项服务，有点意思的是shutdown又会再调用reboot/halt/poweroff。（形成一个相互调用链）。当然如果加上--force，就不调用shutdown直接关闭了，这样是有风险的，和拔电源这种行为没什么区别。 shutdown还能选择在未来某个时间点执行shutdown，并且还可以给在线的用户发送相应的消息。到了这个时间点的前 5 分钟，会创建/run/nologin文件，确保没有人可以再登录。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Linux","slug":"学习笔记/Linux","permalink":"http://yoursite.com/categories/学习笔记/Linux/"},{"name":"鸟哥的Linux私房菜基础学习篇","slug":"学习笔记/Linux/鸟哥的Linux私房菜基础学习篇","permalink":"http://yoursite.com/categories/学习笔记/Linux/鸟哥的Linux私房菜基础学习篇/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"鸟哥的Linux私房菜基础学习篇（零）学习笔记","slug":"鸟哥的Linux私房菜基础学习篇（零）","date":"2018-11-10T16:48:46.000Z","updated":"2020-01-07T08:21:41.540Z","comments":true,"path":"2018/11/11/鸟哥的Linux私房菜基础学习篇（零）/","link":"","permalink":"http://yoursite.com/2018/11/11/鸟哥的Linux私房菜基础学习篇（零）/","excerpt":"","text":"概要：第0章的内容是介绍一些关于计算机硬件上的基础知识，时间充足的话了解一下还是很有必要的，其中很多日常碰到的问题在这章都可以得到相应的解答。这些内容其实在大学里的课程里都有学过，只是当时不知道有什么用罢了。比如说，如果你知道CPU高速缓存的相关知识的话，那么当你在看到Java的线程模型的时候，就能知其所以然，从而能更好地理解线程。作者的设计并不是凭空产生的，必然是基于一些基础的知识构建的。 计算机硬件的五大单元 数据传输过程 从上图可知，内存是所有数据交互的中心，这点必须切记。 主板主板最重要的部分就是芯片组。而芯片组又分为两个部分： 北桥：负责连接速度较快的CPU、内存与显卡等。 南桥：负责连接速度较慢的硬盘、USB、网卡等。 Intel与AMD的不同之处在于，AMD的内存是直接与CPU通信而不通过北桥。 主板上的CMOS记录了BIOS的重要参数，比如说系统时间，CPU电压与频率等等。记录这些是需要花费电力的，所以主板上才会有电池。而BIOS则会在开机的时候加载CMOS的参数。 CPUCPU分类根据设计理念，CPU分为两种指令集： 精简指令集：每个指令比较简单，执行时间短，执行性能较佳，但是要做复杂的工作时，就需要多个指令来完成。常见的有PowerPC系列与ARM系列。 复杂指令集：与精简指令集相反，复杂指令集多而复杂，每条指令的长度并不相同，因为复杂所以花费的时间也较长，但是个别指令可以处理复杂的工作。常见的有Intel、AMD等x86架构的CPU。 CPU等级 32位CPU：i386、i586、i686。 64位CPU：x86_64。 频率我们通常看到的CPU频率，比如说3.0GHz，表示这个CPU在一秒内可以进行$3.0×10^9$次工作。 CPU与外部组件进行数据传输/运算的速度叫做外频，而 $$CPU频率 = 倍频×外频$$ 我们经常听说的超频，通常这个“频”指的是外频。 CPU的性能不能单纯的以CPU频率来判断，因为每款CPU的微指令集都不相同，频率仅仅可以用来判断同款CPU的性能。 总线我们前面说道，主板的芯片组分为南桥与北桥。北桥的总线称为系统总线，主要用于内存传输。南桥的总线就是所谓的输入输出（I/O）总线，主要用于硬盘、USB等接口设备。 北桥的频率我们称为前端总线速度（Front Side Bus，FSB），每次传送的位数则是总线宽度（32/64bit），因此$$总线频宽 = FSB × 总线宽度$$ 总线频宽即每秒钟传送的最大数据量。而CPU每次能够处理的数据量称为字组大小。字组大小有32bit与64bit，我们平常所说的32位系统与64位系统就是根据这个来的。需要注意的是字组大小与总线宽度可以不相同。 内存内存种类 动态随机访问内存（Dynamic Random Access Memory ,DRAM）：DRAM分为SDRAM与DDR SDRAM，后者是双倍数据传送速度。 静态随机访问内存（Static Random Access Memory ,SRAM）：SDRAM的晶体管数量多，速度快，不易做成大容量，且价钱比较高，一般作为CPU的第二层缓存（L2 Cache）。 只读存储器（Read Only Memory，ROM）：也就是我们前面提到的主板上的CMOS。 内存的双通道设计传送内存的数据宽度一般为64位，但是如果加多一条内存，就可以达到128位了，这就是双通道设计理念。也就是说，同为16G的内存，双条的性能会比单条的高。 理论上，CPU与与内存的外频要相同比较好。 显卡（VGA）由于每个图像显示的颜色会占用内存，因此显卡上会装有内存。还嵌入了一个3D加速的芯片，也就是我们称的GPU。 磁盘磁盘主要由盘片、机械手臂、磁头与主轴马达4个部分组成。磁盘运行的时候，马达让盘片转动，机械手臂伸展让磁头进行读写操作。（有点像留声机的感觉） 盘片又分为2个部分，柱面与扇区（如下），其中每个扇区大小为512Bytes。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/学习笔记/"},{"name":"Linux","slug":"学习笔记/Linux","permalink":"http://yoursite.com/categories/学习笔记/Linux/"},{"name":"鸟哥的Linux私房菜基础学习篇","slug":"学习笔记/Linux/鸟哥的Linux私房菜基础学习篇","permalink":"http://yoursite.com/categories/学习笔记/Linux/鸟哥的Linux私房菜基础学习篇/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"开篇博文","slug":"开篇博文","date":"2018-11-10T06:58:37.000Z","updated":"2020-01-07T08:21:41.471Z","comments":true,"path":"2018/11/10/开篇博文/","link":"","permalink":"http://yoursite.com/2018/11/10/开篇博文/","excerpt":"","text":"&#160; &#160; &#160; &#160;这算是在github上的第一篇博客吧，也决定从印象笔记转到github上的博客来了。原因有以下几点： 最近印象笔记团队疯狂打折，让我感到了有隐隐的危机感，就像ofo一样。要是万一哪天这家公司倒了，我这几年所积累的笔记就真的欲哭无泪了，而相比之下github还是十分之稳定的。 github的强大开源精神让我对Hexo这个博客框架以及相应的Next主题充满信心，相信未来一定会越来越好。 老生常谈的话题，只有输入是不行的，必须要有所输出。 记笔记与写博客的一个最重要的不同点在于，博客是让大家看的，笔记是让自己看的。把自己所读所思放在博客上，在某种程度可以迫切自己输出得更完美。 同时也当做一个新的起点，学习用MarkDown来写博文，不得不说它的排版真的是挺惊艳的。 最后一点就是，也希望打造自己的一张名片。（其实就是为了在简历上可以写点东西，哈哈） &#160; &#160; &#160; &#160;昨晚折腾了一晚上，看了十多个主题，最后还是选了next这个主题，相对于我来说还是比较合胃口的，不亏是有一万多个star的项目。但是看了READ-ME，发现没有更换背景色这一配置，希望后续能加上。总体来说，还没完全吃透Next的特色，也许还有我没有发现的惊艳之处也说不定。","categories":[{"name":"心情杂文","slug":"心情杂文","permalink":"http://yoursite.com/categories/心情杂文/"}],"tags":[]}]}